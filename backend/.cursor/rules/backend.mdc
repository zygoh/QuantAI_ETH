---
description: åç«¯å¼€å‘è§„åˆ™ - Python/FastAPI/æœºå™¨å­¦ä¹ 
globs:
  - "backend/**/*.py"
alwaysApply: true
---

# åç«¯å¼€å‘è§„åˆ™

## ğŸ Pythonç‰¹å®šè§„èŒƒ

### ä»£ç é£æ ¼

```python
# 1. ä½¿ç”¨ Type Hintsï¼ˆå¿…é¡»ï¼‰
from typing import Dict, List, Any, Optional
import pandas as pd

def process_data(
    df: pd.DataFrame,
    timeframe: str,
    config: Optional[Dict[str, Any]] = None
) -> pd.DataFrame:
    """å¤„ç†Kçº¿æ•°æ®"""
    pass

# 2. å¼‚æ­¥å‡½æ•°è§„èŒƒ
async def fetch_data(symbol: str) -> List[Dict[str, Any]]:
    """I/Oæ“ä½œå¿…é¡»å¼‚æ­¥"""
    return await binance_client.get_klines(symbol)

# 3. é”™è¯¯å¤„ç†ï¼ˆå¼ºåˆ¶ï¼‰
try:
    result = await critical_operation()
except SpecificError as e:
    logger.error(f"å…·ä½“é”™è¯¯: {e}")
    raise
except Exception as e:
    logger.error(f"æœªçŸ¥é”™è¯¯: {e}")
    return default_value

# 4. æ—¥å¿—ä½¿ç”¨emojiæé«˜å¯è¯»æ€§
logger.info("ğŸš€ å¼€å§‹è®­ç»ƒ...")
logger.info("ğŸ“Š æ•°æ®è·å–æˆåŠŸ")
logger.error("âŒ è®­ç»ƒå¤±è´¥")
```

---

## ğŸ—ï¸ æ ¸å¿ƒæ¶æ„è§„èŒƒ

### ä¿¡å·ç”Ÿæˆæ¶æ„ï¼ˆé‡è¦æ›´æ–°ï¼‰

**æ­£ç¡®çš„æµç¨‹**ï¼š
```python
# âœ… å„æ—¶é—´æ¡†æ¶ç‹¬ç«‹é¢„æµ‹å¹¶ç¼“å­˜
async def _on_new_data(self, kline_data: KlineData):
    """å¤„ç†æ–°Kçº¿æ•°æ®"""
    
    # 1. æ›´æ–°ç¼“å†²åŒº
    await self._update_kline_buffer(kline_data)
    
    # 2. é¢„æµ‹è¯¥æ—¶é—´æ¡†æ¶å¹¶ç¼“å­˜
    timeframe = kline_data.interval
    prediction = await self._predict_single_timeframe(symbol, timeframe)
    self.cached_predictions[timeframe] = prediction
    
    # 3. åªæœ‰15mè§¦å‘åˆæˆ
    if timeframe != '15m':
        logger.debug(f"{timeframe} ä¿¡å·å·²ç¼“å­˜ï¼Œç­‰å¾…15mè§¦å‘åˆæˆ")
        return
    
    # 4. åˆæˆæ‰€æœ‰ç¼“å­˜çš„ä¿¡å·
    signal = await self._try_synthesize_cached_signals(symbol)

# âŒ é”™è¯¯ï¼šæ¯æ¬¡15méƒ½é‡æ–°é¢„æµ‹æ‰€æœ‰æ—¶é—´æ¡†æ¶
async def generate_signal(self, symbol: str):
    # åŒæ—¶é¢„æµ‹3ä¸ªæ—¶é—´æ¡†æ¶  # âŒ ä½æ•ˆä¸”é‡å¤
    predictions = await self._get_multi_timeframe_predictions(symbol)
```

### é¦–æ¬¡å¯åŠ¨é¢„æµ‹

```python
# âœ… å¯åŠ¨æ—¶ç«‹å³é¢„æµ‹æ‰€æœ‰æ—¶é—´æ¡†æ¶
async def start(self):
    # åˆå§‹åŒ–ç¼“å†²åŒº
    await self._initialize_kline_buffers()
    
    # ğŸ†• é¦–æ¬¡é¢„æµ‹å¡«å……ç¼“å­˜
    await self._initial_predictions()

async def _initial_predictions(self):
    """é¦–æ¬¡å¯åŠ¨æ—¶é¢„æµ‹æ‰€æœ‰æ—¶é—´æ¡†æ¶å¹¶å¡«å……ç¼“å­˜"""
    for timeframe in settings.TIMEFRAMES:
        prediction = await self._predict_single_timeframe(symbol, timeframe)
        if prediction:
            self.cached_predictions[timeframe] = prediction
```

### é¢„çƒ­ä¿¡å·ä¿æŠ¤

```python
# ğŸ”’ å®‰å…¨ä¿æŠ¤ï¼šå‰5ä¸ªä¿¡å·ä»…è®°å½•ï¼Œä¸äº¤æ˜“
self.signal_counter = 0
self.warmup_signals = 5

async def _process_signal(self, signal: TradingSignal):
    """å¤„ç†ç”Ÿæˆçš„ä¿¡å·"""
    self.signal_counter += 1
    
    # ğŸ”’ é¢„çƒ­æœŸï¼šåªä¿å­˜ä¸äº¤æ˜“
    if self.signal_counter <= self.warmup_signals:
        logger.warning(f"âš ï¸ é¢„çƒ­ä¿¡å· [{self.signal_counter}/{self.warmup_signals}]ï¼šä»…è®°å½•ï¼Œä¸æ‰§è¡Œäº¤æ˜“")
        await self._save_signal(signal)
        return  # ä¸å‘é€ç»™äº¤æ˜“å¼•æ“
    
    # âœ… é¢„çƒ­å®Œæˆï¼šæ­£å¼äº¤æ˜“
    logger.info(f"ğŸš€ æ­£å¼äº¤æ˜“ä¿¡å· (ç¬¬{self.signal_counter}ä¸ª)")
    # ... å‘é€ç»™äº¤æ˜“å¼•æ“
```

---

## ğŸ¤– æœºå™¨å­¦ä¹ è§„èŒƒ

### è®­ç»ƒæµç¨‹ï¼ˆä¸¥æ ¼é¡ºåºï¼‰

```python
async def _train_single_timeframe(self, timeframe: str):
    """å•ä¸ªæ—¶é—´æ¡†æ¶è®­ç»ƒæµç¨‹"""
    
    # 1ï¸âƒ£ è·å–æ•°æ®ï¼ˆAPIï¼Œè‡ªåŠ¨åˆ†æ‰¹>1500æ¡ï¼‰
    data = await self._prepare_training_data_for_timeframe(timeframe)
    
    # 2ï¸âƒ£ ç‰¹å¾å·¥ç¨‹
    data = self.feature_engineer.create_features(data)
    
    # 3ï¸âƒ£ åˆ›å»ºæ ‡ç­¾ï¼ˆå¿…é¡»ä¼ å…¥timeframeï¼ï¼‰
    data = self._create_labels(data, timeframe=timeframe)
    
    # 4ï¸âƒ£ å‡†å¤‡ç‰¹å¾ï¼ˆå¿…é¡»ä¼ å…¥timeframeï¼ï¼‰
    X, y = self._prepare_features_labels(data, timeframe)
    
    # 5ï¸âƒ£ ç¼©æ”¾ï¼ˆå¿…é¡»ä¼ å…¥timeframeï¼ï¼‰
    X_scaled = self._scale_features(X, timeframe, fit=True)
    
    # 6ï¸âƒ£ æ—¶é—´åºåˆ—åˆ†å‰²ï¼ˆä¸æ˜¯éšæœºï¼ï¼‰
    split_idx = int(len(X) * 0.8)
    X_train, X_val = X[:split_idx], X[split_idx:]
    
    # 7ï¸âƒ£ è®­ç»ƒ
    model = self._train_lightgbm(..., timeframe=timeframe)
    
    # 8ï¸âƒ£ ä¿å­˜åˆ°å­—å…¸
    self.models[timeframe] = model
```

### æ•°æ®è·å–ä¸æ’åºï¼ˆä¸‰é‡ä¿è¯ï¼‰

```python
# æ–¹æ³•: _prepare_training_data_for_timeframe

# åˆ†æ‰¹è·å–ï¼ˆ>1500æ¡æ—¶ï¼‰
for batch in range(batches_needed):
    klines = binance_client.get_klines(
        symbol=symbol,
        interval=timeframe,
        limit=min(1500, remaining),
        end_time=end_time  # ä»æœ€æ–°å¾€å‰è¿½æº¯
    )
    all_klines.extend(klines)
    end_time = klines[0]['timestamp'] - 1

# ä¸‰é‡æ’åºä¿è¯ï¼ˆç”Ÿäº§ç¯å¢ƒå¿…é¡»ï¼‰
# 1ï¸âƒ£ åè½¬æ‰¹æ¬¡é¡ºåº
all_klines.reverse()  # [æ–°â†’æ—§] å˜ä¸º [æ—§â†’æ–°]

# 2ï¸âƒ£ è½¬æ¢å¹¶å»é‡
df = pd.DataFrame(all_klines)
df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
df = df.drop_duplicates(subset=['timestamp'], keep='last')

# 3ï¸âƒ£ æ˜¾å¼æ’åºï¼ˆæœ€ç»ˆä¿é™©ï¼‰
df = df.sort_values('timestamp')  # 100%ç¡®ä¿ä»æ—§åˆ°æ–°

# 4ï¸âƒ£ è®¾ç½®ç´¢å¼•
df = df.set_index('timestamp')
```

### æ ‡ç­¾é˜ˆå€¼é…ç½®ï¼ˆå·²ä¼˜åŒ–ï¼‰

```python
# âœ… å½“å‰ç”Ÿäº§é…ç½®ï¼ˆä¸­é¢‘äº¤æ˜“ï¼šçµæ•ç­–ç•¥ï¼‰
threshold_config = {
    '15m': {
        'up': 0.001,      # Â±0.1% â† ä¸­é¢‘äº¤æ˜“ï¼šæåº¦çµæ•ï¼ŒHOLD<30%
        'down': -0.001
    },
    '2h': {
        'up': 0.0035,     # Â±0.35% â† ä¸­æœŸè¾…åŠ©ï¼šHOLD<40%
        'down': -0.0035
    },
    '4h': {
        'up': 0.005,      # Â±0.5% â† é•¿æœŸç¡®è®¤ï¼šHOLD<45%
        'down': -0.005
    }
}

# é¢„æœŸæ ‡ç­¾åˆ†å¸ƒï¼ˆä¸­é¢‘äº¤æ˜“ï¼‰
# 15m: SHORT 32-38%, HOLD 24-32%, LONG 32-38%  â† çµæ•
# 2h:  SHORT 28-32%, HOLD 36-40%, LONG 28-32%  â† å¹³è¡¡
# 4h:  SHORT 26-30%, HOLD 42-46%, LONG 26-30%  â† ç¨³å¥

# âŒ è¿‡æ—¶é…ç½®ï¼ˆå¯¼è‡´ä¿¡å·è¿‡å°‘ï¼‰
# '15m': Â±0.15% â†’ HOLD 45% âŒ å¯¹ä¸­é¢‘äº¤æ˜“å¤ªä¿å®ˆ
# '15m': Â±0.3%  â†’ HOLD 74% âŒ å‡ ä¹æ— ä¿¡å·
```

### å·®å¼‚åŒ–é…ç½®ï¼ˆå¿…é¡»ï¼‰

```python
# âœ… è®­ç»ƒå¤©æ•°å·®å¼‚åŒ–
training_days_config = {
    '15m': 180,  # çŸ­æœŸå……è¶³
    '2h': 360,   # ä¸­æœŸéœ€è¦æ›´å¤š
    '4h': 540    # é•¿æœŸéœ€è¦æœ€å¤š
}

# âœ… é¢„æµ‹å¤©æ•°å·®å¼‚åŒ–
prediction_days_config = {
    '15m': 15,   # å¿«é€Ÿå“åº”
    '2h': 20,    # ä¸­æœŸå¹³è¡¡
    '4h': 35     # é•¿æœŸç¨³å®š
}

# âœ… æ¨¡å‹å¤æ‚åº¦å·®å¼‚åŒ–
lgb_params_by_timeframe = {
    '15m': {'num_leaves': 63},  # æ•°æ®å¤šï¼Œæ›´å¤æ‚
    '2h': {'num_leaves': 47},   # ä¸­ç­‰
    '4h': {'num_leaves': 31}    # æ•°æ®å°‘ï¼Œç®€å•
}
```

---

## ğŸ—„ï¸ æ•°æ®åº“è§„èŒƒ

### PostgreSQLæ“ä½œ

```python
# âœ… æ­£ç¡®ï¼šæ‰¹é‡å†™å…¥
async def write_kline_data(self, data: List[Dict[str, Any]]):
    """æ‰¹é‡å†™å…¥Kçº¿æ•°æ®"""
    stmt = text("""
        INSERT INTO klines (...) VALUES (...)
        ON CONFLICT (symbol, interval, time) DO NOTHING
    """)
    await conn.execute(stmt, data)

# âŒ é”™è¯¯ï¼šé€æ¡å†™å…¥
for item in data:
    await self.write_kline_data([item])  # âŒ å¤ªæ…¢
```

### Redisç¼“å­˜

```python
# âœ… å…³é”®æ•°æ®ä¸è¿‡æœŸ
await cache_manager.set_model_metrics(symbol, metrics, expire=None)
await cache_manager.set_trading_signal(symbol, signal, expire=None)

# âœ… ä¸´æ—¶æ•°æ®è®¾ç½®è¿‡æœŸ
await cache_manager.set_market_data(key, data, expire=300)  # 5åˆ†é’Ÿ
```

---

## ğŸ“Š ä¿¡å·ç”Ÿæˆè§„èŒƒ

### å¤šæ—¶é—´æ¡†æ¶åˆæˆ

```python
async def _synthesize_signal(
    self,
    predictions: Dict[str, Dict[str, Any]],
    current_price: float
) -> Optional[TradingSignal]:
    """åˆæˆå¤šä¸ªæ—¶é—´æ¡†æ¶çš„ç¼“å­˜ä¿¡å·"""
    
    # 1ï¸âƒ£ åŠ æƒåˆæˆï¼ˆçŸ­çº¿ç­–ç•¥ï¼‰
    weights = {
        '15m': 0.60,  # ä¸»å¯¼
        '2h': 0.25,   # è¾…åŠ©
        '4h': 0.15    # ç¡®è®¤
    }
    
    # 2ï¸âƒ£ è®¡ç®—åŠ æƒç½®ä¿¡åº¦
    weighted_confidences = {
        'LONG': 0.0,
        'SHORT': 0.0,
        'HOLD': 0.0
    }
    for tf, pred in predictions.items():
        signal_type = pred['signal_type']
        confidence = pred['confidence']
        weighted_confidences[signal_type] += confidence * weights[tf]
    
    # 3ï¸âƒ£ é€‰æ‹©æœ€é«˜ç½®ä¿¡åº¦çš„ä¿¡å·ç±»å‹
    final_type = max(weighted_confidences, key=weighted_confidences.get)
    final_confidence = weighted_confidences[final_type]
    
    # 4ï¸âƒ£ ç½®ä¿¡åº¦è¿‡æ»¤
    if final_confidence < settings.CONFIDENCE_THRESHOLD:
        return None
    
    # 5ï¸âƒ£ æ„å»ºæœ€ç»ˆä¿¡å·ï¼ˆåŒ…å«é¢„æµ‹è¯¦æƒ…ï¼‰
    return TradingSignal(
        signal_type=final_type,
        confidence=final_confidence,
        metadata={
            'timeframe_predictions': predictions
        }
    )
```

---

## ğŸŒ WebSocketè§„èŒƒ

### è®¢é˜…æ ¼å¼ï¼ˆå¿…é¡»å°å†™ï¼‰

```python
# âœ… æ­£ç¡®ï¼šäº¤æ˜“å¯¹å¿…é¡»å°å†™
def subscribe_kline(self, symbol: str, interval: str):
    stream_name = f"{symbol.lower()}@kline_{interval}"  # ethusdt@kline_15m
    self.callbacks[stream_name] = callback

# âŒ é”™è¯¯ï¼šå¤§å†™ä¼šå¯¼è‡´è®¢é˜…å¤±è´¥
stream_name = f"{symbol}@kline_{interval}"  # ETHUSDT@kline_15m âŒ
```

### æ•°æ®å¤„ç†æµç¨‹

```python
def _on_kline_data(self, data: Dict[str, Any]):
    """å¤„ç†Kçº¿æ•°æ®"""
    # è·å–æ•°æ®
    k = data.get('k', {})
    symbol = k.get('s', 'UNKNOWN')
    interval = k.get('i', 'UNKNOWN')
    is_closed = k.get('x', False)
    
    # ğŸ†• å¢å¼ºæ—¥å¿—
    logger.info(f"ğŸ“¥ æ”¶åˆ°WebSocket Kçº¿: {symbol} {interval} å·²å®Œæˆ={is_closed}")
    
    # åªå¤„ç†å·²å®Œæˆçš„Kçº¿
    if not is_closed:
        logger.debug(f"â³ Kçº¿æœªå®Œæˆï¼Œè·³è¿‡å¤„ç†")
        return
    
    logger.info(f"âœ… å¤„ç†å·²å®ŒæˆKçº¿: {symbol} {interval}")
    
    # åˆ›å»ºKçº¿å¯¹è±¡å¹¶å¤„ç†
    kline = KlineData(...)
    asyncio.create_task(self._process_kline_data(kline))
```

---

## â° å®šæ—¶ä»»åŠ¡è§„èŒƒ

```python
# æ–‡ä»¶: backend/app/services/scheduler.py

tasks = {
    'model_training': {
        'func': self._run_model_training,
        'scheduled_time': time(0, 1),  # æ¯å¤©00:01
        'description': 'é‡è®­ç»ƒ3ä¸ªæ—¶é—´æ¡†æ¶æ¨¡å‹'
    },
    'data_update': {
        'func': self._run_data_update,
        'interval_hours': 1,
        'description': 'æ›´æ–°PostgreSQLæ•°æ®ï¼ˆä¸æ›´æ–°ç¼“å†²åŒºï¼‰'
    },
    'data_integrity_check': {
        'func': self._run_data_integrity_check,
        'interval_hours': 6,
        'description': 'æ£€æŸ¥å¹¶ä¿®å¤PostgreSQLæ•°æ®'
    }
}
```

---

## ğŸ” å®‰å…¨è§„èŒƒ

```python
# âœ… ç¯å¢ƒå˜é‡ç®¡ç†
import os
from dotenv import load_dotenv

load_dotenv()
BINANCE_API_KEY = os.getenv('BINANCE_API_KEY')
BINANCE_SECRET_KEY = os.getenv('BINANCE_SECRET_KEY')

# âœ… recvWindowå‚æ•°ï¼ˆæ—¶é—´å®¹é”™ï¼‰
self.recv_window = 60000  # 60ç§’

# åœ¨æ‰€æœ‰ç­¾åAPIè°ƒç”¨ä¸­ä¼ é€’
account = self.client.account(recvWindow=self.recv_window)

# âŒ ç¦æ­¢ï¼šç¡¬ç¼–ç å¯†é’¥
API_KEY = "pEnCcceHaD72..."  # âŒ å®‰å…¨é£é™©
```

---

## ğŸ¯ æ€§èƒ½ä¼˜åŒ–

### å¼‚æ­¥å¤„ç†

```python
# âœ… I/Oæ“ä½œå¼‚æ­¥
async def fetch_multiple_timeframes(self, symbol: str):
    """å¹¶å‘è·å–å¤šä¸ªæ—¶é—´æ¡†æ¶æ•°æ®"""
    tasks = [
        self._fetch_timeframe_data(symbol, '15m'),
        self._fetch_timeframe_data(symbol, '2h'),
        self._fetch_timeframe_data(symbol, '4h')
    ]
    results = await asyncio.gather(*tasks)
    return results

# âš ï¸ CPUå¯†é›†å‹å¯ä»¥åŒæ­¥
def train_model(self, X, y):
    """LightGBMè®­ç»ƒå¯ä»¥åŒæ­¥"""
    model = lgb.train(params, train_set)
    return model
```

### ç¼“å­˜ç­–ç•¥

```python
# âœ… ä¼˜å…ˆä½¿ç”¨ç¼“å­˜
cached = await cache_manager.get_model_metrics(symbol)
if cached:
    return cached

# æ²¡æœ‰ç¼“å­˜æ‰è®¡ç®—
result = expensive_calculation()
await cache_manager.set_model_metrics(symbol, result, expire=None)
```

---

## ğŸš« åç«¯ç¦æ­¢äº‹é¡¹

```python
# âŒ ç¦æ­¢ï¼šåœ¨è®­ç»ƒ/é¢„æµ‹ä¸­ä½¿ç”¨æ•°æ®åº“æ•°æ®
data = await postgresql_manager.query_klines()  # âŒ

# âŒ ç¦æ­¢ï¼šå¾ªç¯ä¾èµ–
# ml_service imports signal_generator
# signal_generator imports ml_service  # âŒ

# âŒ ç¦æ­¢ï¼šæ²¡æœ‰æ—¶åŒºçš„datetime
now = datetime.now()  # âŒ
# åº”è¯¥ï¼š
now = datetime.now(shanghai_tz)  # âœ…

# âŒ ç¦æ­¢ï¼šåŒæ­¥I/Oæ“ä½œé˜»å¡
def fetch_data():  # âŒ åº”è¯¥æ˜¯async
    response = requests.get(url)  # âŒ åŒæ­¥è¯·æ±‚
    
# âœ… åº”è¯¥ï¼š
async def fetch_data():
    async with aiohttp.ClientSession() as session:
        async with session.get(url) as response:
            return await response.json()

# âŒ ç¦æ­¢ï¼šWebSocketè®¢é˜…ä½¿ç”¨å¤§å†™
subscribe(f"{symbol}@kline_{interval}")  # âŒ
# åº”è¯¥ï¼š
subscribe(f"{symbol.lower()}@kline_{interval}")  # âœ…

# âŒ ç¦æ­¢ï¼šå…³é—­å…¨å±€æ•°æ®åº“è¿æ¥
async def check_something():
    # ... æ£€æŸ¥é€»è¾‘ ...
    await postgresql_manager.close()  # âŒ ä¼šæ–­å¼€å…¨å±€è¿æ¥ï¼

# âœ… åº”è¯¥ï¼šä½¿ç”¨health_checkæ£€æŸ¥ï¼Œä¸å…³é—­è¿æ¥
async def check_something():
    connected = await postgresql_manager.health_check()  # âœ…
    # ä¸å…³é—­è¿æ¥ï¼Œè®©è¿æ¥æ± ç®¡ç†
```

---

## ğŸ“ æ—¥å¿—è§„èŒƒ

```python
# âœ… å…³é”®ä¸šåŠ¡æµç¨‹å¿…é¡»è®°å½•
logger.info("ğŸš€ å¼€å§‹æ¨¡å‹è®­ç»ƒ...")
logger.info(f"ğŸ“Š {timeframe} æ•°æ®è·å–æˆåŠŸ: {len(df)}æ¡")
logger.info(f"âœ… {timeframe} æ¨¡å‹è®­ç»ƒå®Œæˆ - å‡†ç¡®ç‡: {accuracy:.4f}")

# âœ… æ ‡ç­¾åˆ†å¸ƒå¿…é¡»è®°å½•ï¼ˆç”Ÿäº§ç¯å¢ƒå…³é”®æŒ‡æ ‡ï¼‰
logger.info(f"ğŸ“Š {timeframe} æ ‡ç­¾åˆ†å¸ƒï¼ˆé˜ˆå€¼: Â±{threshold*100:.1f}%ï¼‰:")
logger.info(f"  SHORT: {short_pct:.1f}%")
logger.info(f"  HOLD:  {hold_pct:.1f}%")
logger.info(f"  LONG:  {long_pct:.1f}%")

# âœ… ä¿¡å·ç”Ÿæˆå…¨é“¾è·¯è¿½è¸ª
logger.info(f"ğŸ“¥ æ”¶åˆ°WebSocket Kçº¿: {symbol} {interval} å·²å®Œæˆ={is_closed}")
logger.info(f"ğŸ¯ {timeframe} Kçº¿å®Œæˆï¼Œå¼€å§‹é¢„æµ‹è¯¥æ—¶é—´æ¡†æ¶...")
logger.info(f"âœ… {timeframe} é¢„æµ‹å®Œæˆå¹¶ç¼“å­˜: {signal_type} (ç½®ä¿¡åº¦={confidence:.4f})")
logger.info(f"ğŸ”„ 15mä¿¡å·æ›´æ–°ï¼Œè§¦å‘åˆæˆ (å½“å‰å·²ç¼“å­˜: {list(cached_predictions.keys())})")

# âœ… é¢„çƒ­ä¿¡å·æ ‡æ³¨æ¸…æ™°
logger.warning(f"âš ï¸ é¢„çƒ­ä¿¡å· [{count}/{warmup}]ï¼šä»…è®°å½•ï¼Œä¸æ‰§è¡Œäº¤æ˜“")
logger.info(f"ğŸš€ æ­£å¼äº¤æ˜“ä¿¡å· (ç¬¬{count}ä¸ª): {signal_type} ç½®ä¿¡åº¦={confidence:.4f}")

# âš ï¸ è­¦å‘Šæ¡ä»¶
if hold_pct > 60:
    logger.warning("âš ï¸ HOLDå æ¯”è¿‡é«˜ï¼Œé˜ˆå€¼å¯èƒ½å¤ªå°")

if accuracy < 0.65:
    logger.warning("âš ï¸ å‡†ç¡®ç‡è¿‡ä½ï¼Œéœ€è¦ä¼˜åŒ–")
```

---

## ğŸ§ª æµ‹è¯•è¦ç‚¹

```python
# 1. æ¨¡å‹è®­ç»ƒæµ‹è¯•
- æ•°æ®è·å–æ˜¯å¦æˆåŠŸ
- æ•°æ®æ’åºæ˜¯å¦æ­£ç¡®ï¼ˆæ—§â†’æ–°ï¼‰
- æ ‡ç­¾åˆ†å¸ƒæ˜¯å¦å¹³è¡¡ï¼ˆ30-35%æ¯ç±»ï¼‰
- å‡†ç¡®ç‡æ˜¯å¦è¾¾æ ‡ï¼ˆ15mâ‰¥0.65, 2hâ‰¥0.65, 4hâ‰¥0.60ï¼‰
- æ¨¡å‹æ–‡ä»¶æ˜¯å¦ä¿å­˜

# 2. ä¿¡å·ç”Ÿæˆæµ‹è¯•
- é¦–æ¬¡å¯åŠ¨æ˜¯å¦é¢„æµ‹æ‰€æœ‰æ—¶é—´æ¡†æ¶
- å„æ—¶é—´æ¡†æ¶æ˜¯å¦ç‹¬ç«‹é¢„æµ‹å¹¶ç¼“å­˜
- åªæœ‰15mè§¦å‘åˆæˆæ˜¯å¦æ­£å¸¸
- åŠ æƒåˆæˆæ˜¯å¦æ­£ç¡®
- ç½®ä¿¡åº¦è¿‡æ»¤æ˜¯å¦ç”Ÿæ•ˆ
- ä¿¡å·å»é‡æ˜¯å¦ç”Ÿæ•ˆ

# 3. é¢„çƒ­ä¿¡å·æµ‹è¯•
- å‰5ä¸ªä¿¡å·æ˜¯å¦åªä¿å­˜ä¸äº¤æ˜“
- ç¬¬6ä¸ªä¿¡å·æ˜¯å¦æ­£å¸¸äº¤æ˜“
- æ—¥å¿—æ˜¯å¦æ¸…æ™°æ ‡æ³¨é¢„çƒ­/æ­£å¼çŠ¶æ€

# 4. WebSocketæ•°æ®æµæµ‹è¯•
- WebSocketè®¢é˜…æ ¼å¼æ˜¯å¦æ­£ç¡®ï¼ˆå°å†™ï¼‰
- æ•°æ®æ˜¯å¦å®æ—¶æ¥æ”¶
- å·²å®ŒæˆKçº¿æ˜¯å¦æ­£ç¡®å¤„ç†
- ç¼“å†²åŒºæ˜¯å¦æ­£å¸¸æ›´æ–°

# 5. æ•°æ®å®Œæ•´æ€§æµ‹è¯•
- åˆ†æ‰¹è·å–æ•°æ®æ˜¯å¦æ­£ç¡®æ’åº
- å»é‡æ˜¯å¦ç”Ÿæ•ˆ
- PostgreSQLå†™å…¥æ˜¯å¦å¹‚ç­‰
```

---

## ğŸš€ Phase 1 ä¼˜åŒ–å®æ–½è§„èŒƒï¼ˆ2025-10-16æ–°å¢ï¼‰

### æ™ºèƒ½ç‰¹å¾é€‰æ‹©ï¼ˆå¼ºåˆ¶ä½¿ç”¨ï¼‰

```python
# ml_service.py - _select_features_intelligent

# ä¸¤é˜¶æ®µç‰¹å¾é€‰æ‹©ï¼š
# é˜¶æ®µ1: Filterè¿‡æ»¤ä½é‡è¦æ€§ç‰¹å¾ï¼ˆå¿«é€Ÿï¼‰
lgb_filter = LGBMClassifier(n_estimators=100, max_depth=6, random_state=42)
lgb_filter.fit(X, y)
imp_threshold = imp.mean() * 0.1  # ğŸ”‘ å‡å€¼çš„10%ï¼Œè¿‡æ»¤å™ªéŸ³
valid_features = features[importance > imp_threshold]
del lgb_filter; gc.collect()  # ğŸ”‘ é‡Šæ”¾å†…å­˜

# é˜¶æ®µ2: åµŒå…¥å¼é€‰æ‹©ï¼ˆç²¾ç»†ï¼‰
selector = SelectFromModel(
    LGBMClassifier(
        n_estimators=300,
        learning_rate=0.05,
        reg_alpha=0.1,
        reg_lambda=0.1,
        subsample=0.8,
        colsample_bytree=0.8,
        random_state=42
    ),
    max_features=budget,
    threshold=-np.inf,
    prefit=False  # ğŸ”‘ æ˜¾å¼å£°æ˜
)
selector.fit(X[valid_features], y)
del selector; gc.collect()  # ğŸ”‘ é‡Šæ”¾å†…å­˜

# åŠ¨æ€é¢„ç®—è®¡ç®—
ratio_map = {'15m': 200, '2h': 150, '4h': 100}
budget = max(8, min(n_samples / k, 150))  # ğŸ”‘ ä¿åº•8ï¼Œå°é¡¶150

# ğŸ”‘ è¿‡æ‹Ÿåˆè­¦æˆ’çº¿
if æ ·æœ¬/ç‰¹å¾æ¯” < 50: logger.warning("ä¸¥é‡è­¦å‘Š")
elif æ ·æœ¬/ç‰¹å¾æ¯” < 100: logger.warning("æ³¨æ„ç›‘æ§")
```

**ä¼˜åŠ¿**:
- âœ… åŸºäºæ¨¡å‹é‡è¦æ€§ï¼ˆä¸æ ‡ç­¾ç›´æ¥ç›¸å…³ï¼‰
- âœ… åŠ¨æ€é¢„ç®—ï¼ˆè‡ªé€‚åº”æ ·æœ¬æ•°ï¼Œé˜²è¿‡æ‹Ÿåˆï¼‰
- âœ… å·®å¼‚åŒ–é…ç½®ï¼ˆ15m~150ä¸ª, 2h~20ä¸ª, 4h~19ä¸ªï¼‰
- âœ… æ ·æœ¬/ç‰¹å¾æ¯”>100:1ï¼ˆå®‰å…¨èŒƒå›´ï¼‰

**ç¦æ­¢**:
- âŒ åŸºäºæ–¹å·®é€‰æ‹©ï¼ˆç›¸å…³æ€§å·®ï¼‰
- âŒ å›ºå®šç‰¹å¾æ•°é‡ï¼ˆä¸è€ƒè™‘æ ·æœ¬æ•°ï¼‰
- âŒ æ ·æœ¬/ç‰¹å¾æ¯”<50:1ï¼ˆè¿‡æ‹Ÿåˆé£é™©ï¼‰

---

### æ ·æœ¬åŠ æƒè®­ç»ƒï¼ˆå¿…é¡»å¯ç”¨ï¼‰

```python
# ml_service.py - _train_lightgbmæ–¹æ³•

from sklearn.utils.class_weight import compute_sample_weight

# 1. ç±»åˆ«æƒé‡ï¼ˆå¹³è¡¡å„ç±»åˆ«ï¼‰
class_weights = compute_sample_weight('balanced', y_train)

# 2. æ—¶é—´è¡°å‡æƒé‡ï¼ˆæ›´é‡è§†æœ€è¿‘æ•°æ®ï¼‰
time_decay = np.exp(-np.arange(len(X_train)) / (len(X_train) * 0.1))[::-1]

# 3. ç»„åˆæƒé‡
sample_weights = class_weights * time_decay

# 4. åº”ç”¨åˆ°è®­ç»ƒ
model.fit(X_train, y_train, sample_weight=sample_weights, ...)

# âœ… å¿…é¡»è®°å½•æ—¥å¿—
logger.info(f"âœ… æ ·æœ¬åŠ æƒå·²å¯ç”¨ï¼šç±»åˆ«å¹³è¡¡ Ã— æ—¶é—´è¡°å‡")
```

**ç›®çš„**: è§£å†³ç±»åˆ«ä¸å¹³è¡¡ï¼ˆHOLDæ¯”ä¾‹ä½ï¼‰ã€æå‡å¯¹æœ€è¿‘æ•°æ®çš„å­¦ä¹ 

---

### å¸‚åœºå¾®è§‚ç»“æ„ç‰¹å¾ï¼ˆå·²å¢å¼ºï¼‰

**æ–°å¢ç‰¹å¾ç±»åˆ«**:
1. **ä»·æ ¼ä½ç½®** - `price_position_{5,20,50}`, `overbought_*`, `oversold_*`
2. **Kçº¿å½¢æ€** - `body_range`, `upper_shadow`, `lower_shadow`, `doji`
3. **Kçº¿å¼ºåº¦** - `bullish_candle`, `strong_bullish`, `strong_bearish`
4. **è¶‹åŠ¿å»¶ç»­** - `consecutive_bull`, `consecutive_bear`
5. **ä»·æ ¼åŠ¨æ€** - `price_acceleration`, `price_jerk`
6. **æ³¢åŠ¨èŒƒå›´** - `range_to_atr`, `body_to_atr`

**ç¦æ­¢äº‹é¡¹**:
- âŒ ä½¿ç”¨æœªæ¥æ•°æ®ï¼ˆshiftè´Ÿæ•°ï¼‰
- âŒ æ·»åŠ é«˜ç¼ºå¤±ç‡ç‰¹å¾ï¼ˆ>20%ï¼‰
- âŒ é‡å¤å·²æœ‰ç‰¹å¾

---

### å¸‚åœºæƒ…ç»ªç‰¹å¾ï¼ˆå·²æ·»åŠ ï¼‰

**æ–°å¢ç‰¹å¾**:
1. **ææ…ŒæŒ‡æ•°** - `fear_index`
2. **è¶‹åŠ¿ç–²åŠ³** - `consecutive_up`, `consecutive_down`
3. **RSIæƒ…ç»ª** - `extreme_overbought`, `extreme_oversold`, `rsi_momentum`
4. **ä»·é‡å…³ç³»** - `volume_surge`, `volume_dry`, `price_volume_divergence`
5. **ç»¼åˆæƒ…ç»ª** - `sentiment_composite`

---

### ä»“ä½ç®¡ç†ç­–ç•¥ï¼ˆé»˜è®¤å…¨ä»“ï¼‰

```python
# position_manager.py - calculate_position_size

# âœ… é»˜è®¤ç­–ç•¥ï¼šå…¨ä»“äº¤æ˜“ï¼ˆuse_full_position=Trueï¼‰
position_value = å…¨éƒ¨å¯ç”¨ä½™é¢ Ã— æ æ†

logger.info(f"ğŸ’° å…¨ä»“ä»“ä½è®¡ç®—: {symbol} {position_value:.2f} USDT")
logger.info(f"  ä½™é¢: {balance:.2f} USDT | æ æ†: {leverage}x | ç­–ç•¥: å…¨ä»“")

# ğŸ”§ å¯é€‰ï¼šåŠ¨æ€ä»“ä½ç®¡ç†ï¼ˆuse_full_position=Falseï¼‰
# ä»…åœ¨éœ€è¦é™ä½é£é™©æ—¶ä½¿ç”¨
final_ratio = base_ratio Ã— volatility_adj Ã— exposure_adj Ã— loss_adj
final_ratio = clip(final_ratio, 0.02, 0.15)  # é™åˆ¶2%-15%

# åŠ¨æ€è°ƒæ•´å› å­è§„åˆ™ï¼ˆä»…åŠ¨æ€æ¨¡å¼ï¼‰
volatility_adj:
  - æ—¥æ³¢åŠ¨>8%: 0.5xï¼ˆå‡åŠï¼‰
  - æ—¥æ³¢åŠ¨>5%: 0.7x
  - æ—¥æ³¢åŠ¨<2%: 1.3xï¼ˆå¢åŠ ï¼‰
  
exposure_adj:
  - æŒä»“>50%: 0.5x
  - æŒä»“>30%: 0.75x
  
loss_adj:
  - 3è¿äº: 0.5x
  - 2è¿äº: 0.75x
```

**é»˜è®¤è¡Œä¸º**: å…¨ä»“äº¤æ˜“ï¼ˆé€‚åˆä¸­é¢‘ç­–ç•¥ï¼‰  
**æ•°æ®æº**: Binance APIï¼ˆä»…åŠ¨æ€æ¨¡å¼éœ€è¦ï¼‰
- `binance_client.get_ticker_24h()` - æ³¢åŠ¨ç‡
- `binance_client.get_position_info()` - æŒä»“
- `cache_manager.get('recent_trades:*')` - å†å²äº¤æ˜“

---

### åŠ¨æ€æ­¢æŸæ­¢ç›ˆï¼ˆå¼ºåˆ¶ä½¿ç”¨ï¼‰

```python
# risk_service.py - calculate_dynamic_stop_levels

# 1. ä»Binance APIè·å–50æ ¹Kçº¿è®¡ç®—ATR
klines = binance_client.get_klines(symbol, '15m', limit=50)
current_atr = AverageTrueRange(14å‘¨æœŸ)

# 2. æ­¢æŸä½ï¼ˆå›ºå®š1.5å€ATRï¼‰
stop_loss = entry_price Â± (atr Ã— 1.5)

# 3. æ­¢ç›ˆä½ï¼ˆæ ¹æ®ç½®ä¿¡åº¦ï¼‰
if confidence > 0.7:
    take_profit = entry_price Â± (atr Ã— 4.0)  # ç›ˆäºæ¯”1:2.67
elif confidence > 0.5:
    take_profit = entry_price Â± (atr Ã— 3.5)  # ç›ˆäºæ¯”1:2.33
else:
    take_profit = entry_price Â± (atr Ã— 3.0)  # ç›ˆäºæ¯”1:2.0

# 4. è·Ÿè¸ªæ­¢æŸ
trailing_stop_distance = atr Ã— 1.0

# âœ… å¿…é¡»è®°å½•è¯¦ç»†ä¿¡æ¯
logger.info(f"ğŸ¯ åŠ¨æ€æ­¢æŸæ­¢ç›ˆå·²è®¡ç®—:")
logger.info(f"  å…¥åœºä»·: {entry_price:.2f}")
logger.info(f"  æ­¢æŸä»·: {stop_loss:.2f} (é£é™©: {risk_pct:.2f}%)")
logger.info(f"  æ­¢ç›ˆä»·: {take_profit:.2f} (æ”¶ç›Š: {reward_pct:.2f}%)")
logger.info(f"  ç›ˆäºæ¯”: 1:{risk_reward_ratio:.2f}")
```

**æ•°æ®æº**: Binance APIï¼ˆå¿…é¡»å®æ—¶è·å–ï¼‰
**é™çº§æ–¹æ¡ˆ**: å›ºå®šç™¾åˆ†æ¯”æ­¢æŸï¼ˆÂ±1.5%/Â±3-4%ï¼‰

**é›†æˆç‚¹**: `signal_generator.py:691-712`

---

## ğŸ” Phase 1 ä¼˜åŒ–éªŒè¯æ¸…å•

### è®­ç»ƒé˜¶æ®µéªŒè¯

- [ ] æ ·æœ¬æƒé‡æ—¥å¿—æ˜¾ç¤º: "âœ… æ ·æœ¬åŠ æƒå·²å¯ç”¨"
- [ ] æ ‡ç­¾åˆ†å¸ƒç¬¦åˆé¢„æœŸï¼ˆHOLD 28-45%ï¼‰
- [ ] å¾®è§‚ç»“æ„ç‰¹å¾è®¡ç®—æˆåŠŸï¼ˆ30+ç‰¹å¾ï¼‰
- [ ] æƒ…ç»ªç‰¹å¾è®¡ç®—æˆåŠŸï¼ˆ15+ç‰¹å¾ï¼‰
- [ ] æ¨¡å‹å‡†ç¡®ç‡ â‰¥48%

### ä¿¡å·ç”ŸæˆéªŒè¯

- [ ] åŠ¨æ€ä»“ä½æ—¥å¿—æ˜¾ç¤ºæ‰€æœ‰è°ƒæ•´å› å­
- [ ] ATRæ­¢æŸè®¡ç®—æ—¥å¿—å®Œæ•´
- [ ] ç›ˆäºæ¯” â‰¥1.8:1
- [ ] ä¿¡å·æ•°é‡å¢åŠ 

### æ€§èƒ½éªŒè¯

- [ ] å®é™…ä¿¡å·å‡†ç¡®ç‡ â‰¥50%ï¼ˆè§‚å¯Ÿ20+ä¿¡å·ï¼‰
- [ ] æ— è¿‡åº¦äº¤æ˜“ï¼ˆæ—¥å‡<10ä¸ªä¿¡å·ï¼‰
- [ ] è™šæ‹Ÿäº¤æ˜“ç›ˆåˆ©ï¼ˆæ‰£é™¤æ‰‹ç»­è´¹åï¼‰

---

**ç‰ˆæœ¬**: v5.0  
**æ›´æ–°æ—¥æœŸ**: 2025-10-16  
**æ›´æ–°å†…å®¹**:
- æ·»åŠ Phase 1ä¼˜åŒ–å®æ–½è§„èŒƒ
- æ ·æœ¬åŠ æƒè®­ç»ƒè§„èŒƒ
- å¸‚åœºå¾®è§‚ç»“æ„ç‰¹å¾å¢å¼ºï¼ˆ30+æ–°ç‰¹å¾ï¼‰
- å¸‚åœºæƒ…ç»ªç‰¹å¾æ·»åŠ ï¼ˆ15+æ–°ç‰¹å¾ï¼‰
- åŠ¨æ€ä»“ä½ç®¡ç†è§„èŒƒï¼ˆ4å› å­è°ƒæ•´ï¼‰
- åŠ¨æ€æ­¢æŸæ­¢ç›ˆè§„èŒƒï¼ˆåŸºäºATRï¼‰
- æ•°æ®æºä¸¥æ ¼æ€§è¦æ±‚ï¼ˆä»…Binance APIï¼‰
- ä¼˜åŒ–éªŒè¯æ¸…å•
**é€‚ç”¨èŒƒå›´**: backend/**/*.py
