"""
äº¤æ˜“ä¿¡å·ç”Ÿæˆå™¨

èŒè´£ï¼š
1. ğŸ¯ å¤šæ—¶é—´æ¡†æ¶ä¿¡å·ç”Ÿæˆï¼ˆ3m/5m/15mï¼‰
2. ğŸ”„ ä¿¡å·ç¼“å­˜ä¸åˆæˆ
3. ğŸ”’ é¢„çƒ­ä¿¡å·ä¿æŠ¤ï¼ˆå‰5ä¸ªä¿¡å·ä»…è®°å½•ï¼‰
4. ğŸ“Š WebSocketå®æ—¶æ•°æ®å¤„ç†

æ³¨æ„ï¼š
- ä»“ä½è®¡ç®—å·²å§”æ‰˜ç»™ position_managerï¼ˆé¿å…é‡å¤ä»£ç ï¼‰
- ä¿¡å·ç”ŸæˆåŸºäºç¼“å­˜çš„é¢„æµ‹ç»“æœï¼Œé¿å…é‡å¤é¢„æµ‹
"""
import asyncio
import logging
import time
from typing import Dict, List, Any, Optional
from datetime import datetime, timedelta
from dataclasses import dataclass
import pandas as pd
import numpy as np

from app.core.config import settings
from app.core.database import postgresql_manager
from app.core.cache import cache_manager
from app.model.ml_service import MLService
from app.services.data_service import DataService, KlineData
from app.exchange.exchange_factory import ExchangeFactory
from app.utils.helpers import format_signal_type
from app.services.risk_service import RiskService
from app.trading.position_manager import position_manager
import pytz

logger = logging.getLogger(__name__)

@dataclass
class TradingSignal:
    """äº¤æ˜“ä¿¡å·æ•°æ®ç±»"""
    timestamp: datetime
    symbol: str
    signal_type: str  # LONG, SHORT, CLOSE
    confidence: float
    entry_price: float
    stop_loss: float
    take_profit: float
    position_size: float
    timeframe: str
    model_version: str
    metadata: Dict[str, Any]

class SignalGenerator:
    """äº¤æ˜“ä¿¡å·ç”Ÿæˆå™¨"""
    
    def __init__(self, ml_service: MLService, data_service: DataService):
        self.ml_service = ml_service
        self.data_service = data_service
        self.is_running = False
        
        # ğŸ”‘ è·å–äº¤æ˜“æ‰€å®¢æˆ·ç«¯ï¼ˆä½¿ç”¨å·¥å‚æ¨¡å¼ï¼‰
        self.exchange_client = ExchangeFactory.get_current_client()
        self.signal_callbacks: List[callable] = []
        self.last_signals: Dict[str, TradingSignal] = {}
        
        # ä¿¡å·ç”Ÿæˆå‚æ•°
        self.confidence_threshold = settings.CONFIDENCE_THRESHOLD
        self.min_signal_interval = 180  # çŸ­çº¿ç­–ç•¥ï¼š3åˆ†é’Ÿæœ€å°ä¿¡å·é—´éš”ï¼ˆ180ç§’ï¼Œä¸3m Kçº¿å‘¨æœŸä¸€è‡´ï¼‰
        # ğŸ”¥ ç§»é™¤é¢„æµ‹é—´éš”é™åˆ¶ï¼šKçº¿å®Œæˆæ—¶ç«‹å³é¢„æµ‹ï¼ˆå®æ—¶å“åº”ï¼‰
        # åŸè®¾è®¡ï¼šmin_prediction_interval = 30ç§’ï¼ˆé˜²æŠ–ï¼‰
        # æ–°è®¾è®¡ï¼šKçº¿å®Œæˆæ˜¯æ˜ç¡®äº‹ä»¶ï¼Œåº”è¯¥ç«‹å³å“åº”ï¼Œä¸éœ€è¦é˜²æŠ–
        
        # ğŸ”‘ é¢„æµ‹é¢‘ç‡æ§åˆ¶ï¼ˆæ–°å¢ï¼‰
        self.last_prediction_time: Dict[str, float] = {}  # {timeframe: timestamp}
        
        # ğŸ”‘ ç‰¹å¾ç¼“å­˜ï¼ˆæ–°å¢ï¼‰
        self.feature_cache: Dict[str, pd.DataFrame] = {}  # {cache_key: features}
        self.feature_cache_time: Dict[str, float] = {}  # {cache_key: timestamp}
        self.feature_cache_ttl = 300  # ç‰¹å¾ç¼“å­˜5åˆ†é’Ÿ
        
        # æ­¢æŸæ­¢ç›ˆå‚æ•°ï¼ˆä¸­é¢‘äº¤æ˜“ç­–ç•¥ï¼šæ›´ç´§çš„æ­¢æŸï¼Œä¿æŒæ­¢ç›ˆï¼‰
        self.stop_loss_pct = 0.015  # 1.5%æ­¢æŸï¼ˆä¸­é¢‘å¿«é€Ÿæ­¢æŸï¼Œå‡å°‘é£é™©ï¼‰
        self.take_profit_pct = 0.04   # 4%æ­¢ç›ˆï¼ˆè®©åˆ©æ¶¦å¥”è·‘ï¼‰
        
        # WebSocket æ•°æ®ç¼“å†²åŒºï¼ˆå­˜å‚¨å®æ—¶Kçº¿æ•°æ®ï¼‰
        self.kline_buffers: Dict[str, pd.DataFrame] = {}  # {timeframe: DataFrame}
        
        # ğŸ”¥ ä¿¡å·ç¼“å­˜ï¼šæ¯ä¸ªæ—¶é—´æ¡†æ¶ç‹¬ç«‹ç¼“å­˜é¢„æµ‹ç»“æœ
        self.cached_predictions: Dict[str, Dict[str, Any]] = {}  # {timeframe: prediction}
        
        # ğŸ”’ å®‰å…¨ä¿æŠ¤ï¼šå‰5ä¸ªä¿¡å·ä»…è®°å½•ï¼Œä¸äº¤æ˜“ï¼ˆä»…é¦–æ¬¡éƒ¨ç½²æ—¶å¯ç”¨ï¼‰
        self.warmup_signals = 5  # é¢„çƒ­ä¿¡å·æ•°é‡
        self.signal_counter = 0  # ä¿¡å·è®¡æ•°å™¨ï¼ˆå¯åŠ¨æ—¶ä¼šä»RedisåŠ è½½ï¼‰
        
        # ç¼“å†²åŒºè®¾è®¡ï¼šæŒ‰å¤©æ•°ç»Ÿä¸€ï¼ˆæ‰€æœ‰æ—¶é—´æ¡†æ¶è¦†ç›–ç›¸åŒå¤©æ•°ï¼‰
        self.buffer_days = 30  # ç»Ÿä¸€30å¤©è¦†ç›–èŒƒå›´ï¼ˆè¶…çŸ­çº¿ç­–ç•¥ï¼Œè¾ƒçŸ­ç¼“å†²ï¼‰
        
        # æ ¹æ®æ—¶é—´æ¡†æ¶è®¡ç®—å®é™…éœ€è¦çš„Kçº¿æ•°é‡
        self.buffer_sizes = {
            '3m': int(self.buffer_days * 24 * 20),   # 30å¤© = 14400æ¡ï¼ˆ3åˆ†é’Ÿï¼‰
            '5m': int(self.buffer_days * 24 * 12),   # 30å¤© = 8640æ¡ï¼ˆ5åˆ†é’Ÿï¼‰
            '15m': int(self.buffer_days * 24 * 4)    # 30å¤© = 2880æ¡ï¼ˆ15åˆ†é’Ÿï¼‰
        }
        
        # æ³¨å†Œæ•°æ®å›è°ƒ
        self.data_service.add_data_callback(self._on_new_data)
        
        # æ³¨å†ŒWebSocketé‡è¿å›è°ƒ
        self.data_service.add_reconnect_callback(self._on_websocket_reconnect)
    
    async def start(self):
        """å¯åŠ¨ä¿¡å·ç”Ÿæˆå™¨"""
        try:
            logger.info("å¯åŠ¨äº¤æ˜“ä¿¡å·ç”Ÿæˆå™¨...")
            
            # åˆå§‹åŒ–WebSocketæ•°æ®ç¼“å†²åŒº
            await self._initialize_kline_buffers()
            
            self.is_running = True
            
            # ğŸ”’ ä»RedisåŠ è½½é¢„çƒ­çŠ¶æ€ï¼ˆæŒä¹…åŒ–ï¼Œé¿å…é‡å¯åé‡æ–°é¢„çƒ­ï¼‰
            await self._load_warmup_state()
            
            # ğŸ”’ å¯åŠ¨å®‰å…¨ä¿æŠ¤æç¤º
            if self.signal_counter < self.warmup_signals:
                logger.warning(f"ğŸ”’ å®‰å…¨ä¿æŠ¤å·²å¯ç”¨ï¼šå‰ {self.warmup_signals} ä¸ªä¿¡å·ä»…è®°å½•ï¼Œä¸æ‰§è¡Œäº¤æ˜“")
                logger.info(f"   å½“å‰å·²å®Œæˆ: {self.signal_counter}/{self.warmup_signals} ä¸ªä¿¡å·")
                logger.info(f"   ç›®çš„ï¼šè§‚å¯Ÿæ¨¡å‹ç¨³å®šæ€§ï¼Œç¡®ä¿èµ„é‡‘å®‰å…¨")
            else:
                logger.info(f"âœ… é¢„çƒ­å·²å®Œæˆï¼ˆ{self.signal_counter}ä¸ªä¿¡å·ï¼‰ï¼Œç³»ç»Ÿå¤„äºæ­£å¸¸äº¤æ˜“æ¨¡å¼")
            
            # ğŸ”¥ é¦–æ¬¡å¯åŠ¨ï¼šç«‹å³å¯¹æ‰€æœ‰æ—¶é—´æ¡†æ¶è¿›è¡Œé¢„æµ‹ï¼Œå¡«å……ä¿¡å·ç¼“å­˜
            await self._initial_predictions()
            
            logger.info("âœ… äº¤æ˜“ä¿¡å·ç”Ÿæˆå™¨å¯åŠ¨å®Œæˆ")
        except Exception as e:
            logger.error(f"å¯åŠ¨ä¿¡å·ç”Ÿæˆå™¨å¤±è´¥: {e}")
            raise
    
    async def _initialize_kline_buffers(self):
        """åˆå§‹åŒ–Kçº¿æ•°æ®ç¼“å†²åŒº - ä»APIè·å–åˆå§‹æ•°æ®"""
        try:
            symbol = settings.SYMBOL
            logger.info(f"åˆå§‹åŒ–WebSocketæ•°æ®ç¼“å†²åŒº: {symbol}")
            
            for timeframe in settings.TIMEFRAMES:
                try:
                    # è·å–è¯¥æ—¶é—´æ¡†æ¶éœ€è¦çš„Kçº¿æ•°é‡
                    buffer_size = self.buffer_sizes.get(timeframe, 500)
                    
                    # Binance API limit æœ€å¤§1500æ¡ï¼Œéœ€è¦åˆ†æ‰¹è·å–
                    max_limit = 1500
                    all_klines = []
                    
                    # âœ… ç»Ÿä¸€ä½¿ç”¨åˆ†é¡µæ–¹æ³•ï¼ˆè‡ªåŠ¨å¤„ç†è¶…è¿‡1500çš„æƒ…å†µï¼‰
                    logger.info(f"è·å– {timeframe} åˆå§‹æ•°æ®ï¼ˆ{buffer_size}æ¡ï¼Œè¦†ç›–{self.buffer_days}å¤©ï¼‰...")
                    all_klines = self.exchange_client.get_klines_paginated(
                            symbol=symbol,
                            interval=timeframe,
                        limit=buffer_size,
                        rate_limit_delay=0.2
                    )
                    
                    if all_klines:
                        # åˆå§‹åŒ–ç¼“å†²åŒº
                        df = pd.DataFrame(all_klines)
                        
                        # âœ… timestamp ä¿æŒä¸ºæ•´æ•°ï¼ˆæ¯«ç§’æ—¶é—´æˆ³ï¼‰ï¼Œä¸è½¬æ¢
                        # ä¸ WebSocket æ–°æ•°æ®ä¿æŒä¸€è‡´ï¼ˆKlineData.open_time ç°åœ¨æ˜¯ int ç±»å‹ï¼‰
                        
                        self.kline_buffers[timeframe] = df
                        days_covered = len(all_klines) / self.buffer_sizes.get(timeframe, 1) * self.buffer_days
                        logger.info(f"âœ“ {timeframe} ç¼“å†²åŒºåˆå§‹åŒ–å®Œæˆ: {len(all_klines)}æ¡æ•°æ®ï¼ˆçº¦{days_covered:.1f}å¤©ï¼‰")
                    else:
                        logger.warning(f"âš ï¸ {timeframe} åˆå§‹æ•°æ®è·å–å¤±è´¥")
                    
                    # APIé™æµå»¶è¿Ÿ
                    await asyncio.sleep(0.1)
                    
                except Exception as e:
                    logger.error(f"åˆå§‹åŒ– {timeframe} ç¼“å†²åŒºå¤±è´¥: {e}")
            
            logger.info(f"WebSocketæ•°æ®ç¼“å†²åŒºåˆå§‹åŒ–å®Œæˆ: {len(self.kline_buffers)}ä¸ªæ—¶é—´æ¡†æ¶")
            
        except Exception as e:
            logger.error(f"åˆå§‹åŒ–Kçº¿ç¼“å†²åŒºå¤±è´¥: {e}")
    
    async def stop(self):
        """åœæ­¢ä¿¡å·ç”Ÿæˆå™¨"""
        try:
            logger.info("åœæ­¢äº¤æ˜“ä¿¡å·ç”Ÿæˆå™¨...")
            self.is_running = False
            logger.info("äº¤æ˜“ä¿¡å·ç”Ÿæˆå™¨å·²åœæ­¢")
        except Exception as e:
            logger.error(f"åœæ­¢ä¿¡å·ç”Ÿæˆå™¨å¤±è´¥: {e}")
    
    async def _on_websocket_reconnect(self):
        """WebSocketé‡è¿å›è°ƒ - é‡ç½®ç¼“å†²åŒº"""
        try:
            logger.warning("âš ï¸ WebSocketå·²é‡è¿ï¼Œå¼€å§‹é‡ç½®ç¼“å†²åŒº...")
            logger.info("ğŸ”„ åŸå› ï¼šé‡è¿æœŸé—´æ•°æ®å¯èƒ½æœ‰ç¼ºå£ï¼Œé‡æ–°è·å–å®Œæ•´æ•°æ®ä»¥ç¡®ä¿è´¨é‡")
            
            # æ¸…ç©ºç°æœ‰ç¼“å†²åŒº
            self.kline_buffers.clear()
            logger.info("âœ“ å·²æ¸…ç©ºæ—§ç¼“å†²åŒºæ•°æ®")
            
            # é‡æ–°åˆå§‹åŒ–ç¼“å†²åŒºï¼ˆä»APIè·å–æœ€æ–°çš„å®Œæ•´æ•°æ®ï¼‰
            await self._initialize_kline_buffers()
            
            logger.info("âœ… ç¼“å†²åŒºé‡ç½®å®Œæˆï¼Œæ•°æ®è´¨é‡å·²æ¢å¤")
            
        except Exception as e:
            logger.error(f"WebSocketé‡è¿å›è°ƒå¤±è´¥: {e}")
    
    async def _on_new_data(self, kline_data: KlineData):
        """å¤„ç†æ–°çš„Kçº¿æ•°æ® - æ›´æ–°ç¼“å†²åŒºå¹¶é¢„æµ‹è¯¥æ—¶é—´æ¡†æ¶"""
        try:
            logger.info(f"ğŸ“Š ä¿¡å·ç”Ÿæˆå™¨æ”¶åˆ°æ–°Kçº¿: {kline_data.symbol} {kline_data.interval} is_closed={kline_data.is_closed}")
            
            if not self.is_running:
                logger.warning("âš ï¸ ä¿¡å·ç”Ÿæˆå™¨æœªè¿è¡Œï¼Œè·³è¿‡å¤„ç†")
                return
            
            # 1. å°†WebSocketæ•°æ®æ·»åŠ åˆ°ç¼“å†²åŒº
            await self._update_kline_buffer(kline_data)
            
            # 2. ğŸ”¥ å®æ—¶é¢„æµ‹ï¼šKçº¿å®Œæˆæ—¶ç«‹å³é¢„æµ‹ï¼ˆç§»é™¤æ—¶é—´é—´éš”é™åˆ¶ï¼‰
            timeframe = kline_data.interval
            logger.info(f"ğŸ¯ {timeframe} Kçº¿å®Œæˆï¼Œç«‹å³è§¦å‘é¢„æµ‹")
            
            # 3. å¯¹è¯¥æ—¶é—´æ¡†æ¶è¿›è¡Œé¢„æµ‹å¹¶ç¼“å­˜ï¼ˆæ¯ä¸ªæ—¶é—´æ¡†æ¶ç‹¬ç«‹é¢„æµ‹ï¼‰
            prediction = await self._predict_single_timeframe(kline_data.symbol, timeframe)
            
            if prediction:
                # ç¼“å­˜è¯¥æ—¶é—´æ¡†æ¶çš„é¢„æµ‹ç»“æœ
                self.cached_predictions[timeframe] = prediction
                
                # æ›´æ–°æœ€åé¢„æµ‹æ—¶é—´ï¼ˆç”¨äºç»Ÿè®¡ï¼‰
                self.last_prediction_time[timeframe] = time.time()
                
                logger.info(f"âœ… {timeframe} é¢„æµ‹å®Œæˆå¹¶ç¼“å­˜: {prediction.get('signal_type')} (ç½®ä¿¡åº¦={prediction.get('confidence'):.4f})")
            else:
                # é¢„æµ‹å¤±è´¥æˆ–æ¨¡å‹è®­ç»ƒä¸­ï¼ˆè¯¦ç»†ä¿¡æ¯å·²åœ¨ml_serviceå±‚è®°å½•ï¼‰
                logger.warning(f"â¸ï¸ {timeframe} é¢„æµ‹æš‚ä¸å¯ç”¨ï¼ˆæ¨¡å‹å¯èƒ½æ­£åœ¨è®­ç»ƒä¸­ï¼‰")
                return
            
            # 4. ğŸ”¥ åªæœ‰5mä¿¡å·æ›´æ–°æ—¶æ‰è§¦å‘åˆæˆï¼ˆ5mä½œä¸ºä¸»æ—¶é—´æ¡†æ¶ï¼‰
            if timeframe != '5m':
                logger.debug(f"â­ï¸ {timeframe} ä¿¡å·å·²ç¼“å­˜ï¼Œç­‰å¾…5mè§¦å‘åˆæˆ")
                return
            
            logger.info(f"ğŸ”„ 5mä¿¡å·æ›´æ–°ï¼Œè§¦å‘åˆæˆ (å½“å‰å·²ç¼“å­˜: {list(self.cached_predictions.keys())})")
            
            # ğŸ”¥ é¢„çƒ­è®¡æ•°åº”è¯¥åœ¨å°è¯•åˆæˆå‰å°±+1ï¼ˆä¸ç®¡æ˜¯å¦HOLDï¼‰
            self.signal_counter += 1
            # ğŸ’¾ ä¿å­˜é¢„çƒ­çŠ¶æ€åˆ°Redisï¼ˆæŒä¹…åŒ–ï¼‰
            await self._save_warmup_state()
            
            signal = await self._try_synthesize_cached_signals(kline_data.symbol)
            
            if signal:
                logger.info(f"âœ… ç”Ÿæˆåˆæˆä¿¡å·: {format_signal_type(signal.signal_type)} ç½®ä¿¡åº¦={signal.confidence:.4f} å…¥åœº={signal.entry_price:.2f}")
                await self._process_signal(signal)
            else:
                # HOLDæˆ–ç½®ä¿¡åº¦ä¸è¶³
                logger.info(f"â¸ï¸ æœªç”Ÿæˆäº¤æ˜“ä¿¡å·ï¼ˆå¯èƒ½æ˜¯HOLDæˆ–ç½®ä¿¡åº¦ä¸è¶³ï¼‰")
                
                # å¦‚æœåœ¨é¢„çƒ­æœŸï¼Œä¹Ÿåº”è¯¥è®°å½•
                if self.signal_counter <= self.warmup_signals:
                    logger.info(f"â„¹ï¸ é¢„çƒ­æœŸè§‚æœ› [{self.signal_counter}/{self.warmup_signals}]ï¼ˆä¿¡å·ä¸ºHOLDæˆ–ä½ç½®ä¿¡åº¦ï¼‰")
                    logger.info(f"   å‰©ä½™{self.warmup_signals - self.signal_counter}ä¸ªé¢„çƒ­ä¿¡å·")
                
        except Exception as e:
            logger.error(f"âŒ å¤„ç†æ–°æ•°æ®å¤±è´¥: {e}", exc_info=True)
    
    async def _update_kline_buffer(self, kline_data: KlineData):
        """æ›´æ–°Kçº¿æ•°æ®ç¼“å†²åŒºï¼ˆåŒæ—¶å†™å…¥æ•°æ®åº“æŒä¹…åŒ–ï¼‰"""
        try:
            timeframe = kline_data.interval
            
            # è½¬æ¢ä¸ºDataFrameè¡Œ
            new_row = pd.DataFrame([{
                'timestamp': kline_data.open_time,
                'open': kline_data.open_price,
                'high': kline_data.high_price,
                'low': kline_data.low_price,
                'close': kline_data.close_price,
                'volume': kline_data.volume,
                'quote_volume': kline_data.quote_volume
            }])
            
            # å¦‚æœç¼“å†²åŒºä¸å­˜åœ¨ï¼Œåˆå§‹åŒ–
            if timeframe not in self.kline_buffers:
                logger.info(f"åˆå§‹åŒ– {timeframe} æ•°æ®ç¼“å†²åŒº")
                self.kline_buffers[timeframe] = new_row
            else:
                # è®°å½•è¿½åŠ å‰çš„ç¼“å†²åŒºå¤§å°
                old_size = len(self.kline_buffers[timeframe])
                old_last_close = self.kline_buffers[timeframe]['close'].iloc[-1]
                
                # è¿½åŠ æ–°æ•°æ®
                self.kline_buffers[timeframe] = pd.concat(
                    [self.kline_buffers[timeframe], new_row],
                    ignore_index=True
                )
                
                # é™åˆ¶ç¼“å†²åŒºå¤§å°ï¼ˆæ ¹æ®æ—¶é—´æ¡†æ¶ä¿æŒç»Ÿä¸€å¤©æ•°ï¼‰
                buffer_size = self.buffer_sizes.get(timeframe, 500)
                if len(self.kline_buffers[timeframe]) > buffer_size:
                    self.kline_buffers[timeframe] = self.kline_buffers[timeframe].tail(buffer_size)
                
                # âœ… è°ƒè¯•æ—¥å¿—ï¼šéªŒè¯ç¼“å†²åŒºæ›´æ–°
                new_size = len(self.kline_buffers[timeframe])
                new_last_close = self.kline_buffers[timeframe]['close'].iloc[-1]
                logger.debug(f"ğŸ“ˆ {timeframe} ç¼“å†²åŒºæ›´æ–°: {old_size}â†’{new_size}æ¡, æœ€æ–°æ”¶ç›˜ä»·: {old_last_close:.2f}â†’{new_last_close:.2f}")
            
            # âœ… å†™å…¥æ•°æ®åº“æŒä¹…åŒ–ï¼ˆPostgreSQL + TimescaleDBï¼‰
            try:
                # ç›´æ¥ä½¿ç”¨ Binance çš„æ—¶é—´æˆ³ï¼ˆæ¯«ç§’ï¼‰ï¼Œä¸åšä»»ä½•è½¬æ¢
                kline_dict = {
                    'symbol': kline_data.symbol,
                    'interval': timeframe,
                    'timestamp': kline_data.open_time,  # âœ… BinanceåŸå§‹æ—¶é—´æˆ³ï¼ˆæ¯«ç§’ï¼‰
                    'open': kline_data.open_price,
                    'high': kline_data.high_price,
                    'low': kline_data.low_price,
                    'close': kline_data.close_price,
                    'volume': kline_data.volume,
                    'close_time': kline_data.close_time,  # âœ… BinanceåŸå§‹æ—¶é—´æˆ³ï¼ˆæ¯«ç§’ï¼‰
                    'quote_volume': kline_data.quote_volume,
                    'trades': kline_data.trades,  # âœ… ä½¿ç”¨çœŸå®çš„tradesæ•°æ®
                    'taker_buy_base_volume': kline_data.taker_buy_base_volume,  # âœ… ä¸»åŠ¨ä¹°å…¥é‡
                    'taker_buy_quote_volume': kline_data.taker_buy_quote_volume  # âœ… ä¸»åŠ¨ä¹°å…¥é¢
                }
                
                # ğŸš€ å¼‚æ­¥å†™å…¥æ•°æ®åº“ï¼ˆä¸ç­‰å¾…å®Œæˆï¼Œé¿å…é˜»å¡ä¿¡å·ç”Ÿæˆï¼‰
                asyncio.create_task(postgresql_manager.write_kline_data([kline_dict]))
                
                # âœ… ç®€åŒ–æ—¥å¿—è¾“å‡ºï¼ˆæ”¹ä¸ºDEBUGçº§åˆ«ï¼Œå‡å°‘æ—¥å¿—é‡ï¼‰
                logger.debug(f"ğŸ’¾ WebSocketæ•°æ®å·²æäº¤å†™å…¥: {timeframe} | trades={kline_data.trades}")
            except Exception as db_error:
                logger.error(f"âŒ å†™å…¥æ•°æ®åº“å¤±è´¥: {db_error}")
                logger.error(f"   Kçº¿è¯¦æƒ…: symbol={kline_dict.get('symbol')} interval={kline_dict.get('interval')} timestamp={kline_dict.get('timestamp')}")
            
            logger.debug(f"ğŸ“ˆ æ›´æ–° {timeframe} ç¼“å†²åŒºå®Œæˆ: å½“å‰{len(self.kline_buffers[timeframe])}æ¡æ•°æ®")
            
        except Exception as e:
            logger.error(f"æ›´æ–°Kçº¿ç¼“å†²åŒºå¤±è´¥: {e}")
    
    async def _initial_predictions(self):
        """é¦–æ¬¡å¯åŠ¨æ—¶é¢„æµ‹æ‰€æœ‰æ—¶é—´æ¡†æ¶å¹¶å¡«å……ç¼“å­˜ï¼ˆå¦‚æœæ¨¡å‹å¯ç”¨ï¼‰"""
        try:
            symbol = settings.SYMBOL
            
            # ğŸ”’ æ£€æŸ¥æ¨¡å‹æ˜¯å¦å¯ç”¨ï¼ˆå¯èƒ½æ­£åœ¨è®­ç»ƒä¸­ï¼‰
            # å…¼å®¹EnsembleMLServiceï¼ˆä½¿ç”¨ensemble_modelsï¼‰å’ŒMLServiceï¼ˆä½¿ç”¨modelsï¼‰
            models_dict = getattr(self.ml_service, 'ensemble_models', None) or getattr(self.ml_service, 'models', None)
            
            if not models_dict or len(models_dict) == 0:
                logger.warning("âš ï¸ æ¨¡å‹å°šæœªè®­ç»ƒå®Œæˆï¼Œè·³è¿‡é¦–æ¬¡é¢„æµ‹ï¼ˆç­‰å¾…æ¨¡å‹è®­ç»ƒå®Œæˆåé¦–æ¬¡WebSocketè§¦å‘ï¼‰")
                return
            
            logger.info(f"ğŸ¯ å¼€å§‹é¦–æ¬¡é¢„æµ‹æ‰€æœ‰æ—¶é—´æ¡†æ¶: {settings.TIMEFRAMES}")
            
            for timeframe in settings.TIMEFRAMES:
                try:
                    # å†æ¬¡ç¡®è®¤è¯¥æ—¶é—´æ¡†æ¶çš„æ¨¡å‹å­˜åœ¨
                    if timeframe not in models_dict:
                        logger.warning(f"âš ï¸ {timeframe} æ¨¡å‹ä¸å¯ç”¨ï¼Œè·³è¿‡é¦–æ¬¡é¢„æµ‹")
                        continue
                    
                    prediction = await self._predict_single_timeframe(symbol, timeframe)
                    if prediction:
                        self.cached_predictions[timeframe] = prediction
                        logger.info(f"âœ… {timeframe} é¦–æ¬¡é¢„æµ‹å®Œæˆ: {format_signal_type(prediction.get('signal_type'))} (ç½®ä¿¡åº¦={prediction.get('confidence'):.4f})")
                    else:
                        logger.warning(f"âš ï¸ {timeframe} é¦–æ¬¡é¢„æµ‹è¿”å›ç©ºç»“æœ")
                except Exception as e:
                    logger.warning(f"âš ï¸ {timeframe} é¦–æ¬¡é¢„æµ‹å¼‚å¸¸ï¼ˆä¸å½±å“ç³»ç»Ÿè¿è¡Œï¼‰: {e}")
            
            logger.info(f"âœ… é¦–æ¬¡é¢„æµ‹å®Œæˆï¼Œå·²ç¼“å­˜ {len(self.cached_predictions)}/{len(settings.TIMEFRAMES)} ä¸ªæ—¶é—´æ¡†æ¶")
            
            # å°è¯•ç«‹å³ç”Ÿæˆä¸€ä¸ªä¿¡å·ï¼ˆå¦‚æœæ‰€æœ‰æ—¶é—´æ¡†æ¶éƒ½é¢„æµ‹æˆåŠŸï¼‰
            if len(self.cached_predictions) == len(settings.TIMEFRAMES):
                logger.info("ğŸ”„ å°è¯•åŸºäºé¦–æ¬¡é¢„æµ‹ç”Ÿæˆåˆå§‹ä¿¡å·...")
                
                # ğŸ”¥ é¦–æ¬¡é¢„æµ‹ä¸è®¡å…¥é¢„çƒ­ä¿¡å·ï¼ˆåªæ˜¯åˆå§‹åŒ–ç¼“å­˜ï¼‰
                # é¢„çƒ­ä¿¡å·åº”è¯¥ä»å®æ—¶WebSocketä¿¡å·å¼€å§‹è®¡æ•°
                signal = await self._try_synthesize_cached_signals(symbol)
                if signal:
                    logger.info(f"âœ… ç”Ÿæˆåˆå§‹ä¿¡å·: {format_signal_type(signal.signal_type)} ç½®ä¿¡åº¦={signal.confidence:.4f}")
                    logger.info(f"ğŸ’¡ é¦–æ¬¡ä¿¡å·ä¸è®¡å…¥é¢„çƒ­ï¼ˆé¢„çƒ­ä»å®æ—¶WebSocketä¿¡å·å¼€å§‹ï¼‰")
                else:
                    logger.info(f"â„¹ï¸ åˆå§‹ä¿¡å·ä¸ºHOLDæˆ–ä½ç½®ä¿¡åº¦ï¼Œç­‰å¾…å®æ—¶ä¿¡å·")
            else:
                logger.info(f"â¸ï¸ é¦–æ¬¡é¢„æµ‹æœªå®Œå…¨æˆåŠŸï¼Œç­‰å¾…WebSocketæ•°æ®è§¦å‘é¢„æµ‹")
            
        except Exception as e:
            logger.warning(f"âš ï¸ é¦–æ¬¡é¢„æµ‹å¤±è´¥ï¼ˆä¸å½±å“ç³»ç»Ÿè¿è¡Œï¼‰: {e}")
    
    async def _predict_single_timeframe(self, symbol: str, timeframe: str) -> Optional[Dict[str, Any]]:
        """é¢„æµ‹å•ä¸ªæ—¶é—´æ¡†æ¶"""
        try:
            # ç¡®å®šéœ€è¦çš„æ•°æ®é‡ï¼ˆè¶…çŸ­çº¿ç­–ç•¥ï¼šè¾ƒçŸ­å‘¨æœŸï¼‰
            prediction_days_config = {
                '3m': 10,    # 10å¤©=4800æ¡ï¼ˆè¶…çŸ­æœŸï¼‰
                '5m': 10,    # 10å¤©=2880æ¡ï¼ˆä¸»æ—¶é—´æ¡†æ¶ï¼‰
                '15m': 10    # 10å¤©=960æ¡ï¼ˆè¶‹åŠ¿ç¡®è®¤ï¼‰
            }
            prediction_days = prediction_days_config.get(timeframe, 10)
            
            interval_minutes = {
                '1m': 1, '3m': 3, '5m': 5, '15m': 15, '30m': 30,
                '1h': 60, '6h': 360, '8h': 480,
                '12h': 720, '1d': 1440
            }
            minutes = interval_minutes.get(timeframe, 60)
            required_klines = int((prediction_days * 24 * 60) / minutes)
            
            # ä¼˜å…ˆä½¿ç”¨WebSocketç¼“å†²åŒº
            if timeframe in self.kline_buffers and len(self.kline_buffers[timeframe]) >= required_klines:
                df = self.kline_buffers[timeframe].tail(required_klines).copy()
                logger.debug(f"âœ“ ä½¿ç”¨ç¼“å†²åŒº: {timeframe} ({len(df)}æ¡)")
            else:
                # ä»APIè·å–ï¼ˆä½¿ç”¨ç»Ÿä¸€çš„åˆ†é¡µæ–¹æ³•ï¼‰
                logger.debug(f"âš ï¸ ç¼“å†²åŒºä¸è¶³ï¼Œä»APIè·å–: {timeframe} (éœ€è¦{required_klines}æ¡)")
                klines = self.exchange_client.get_klines_paginated(
                    symbol=symbol,
                    interval=timeframe,
                    limit=required_klines
                )
                if not klines:
                    logger.warning(f"âŒ {timeframe} æ•°æ®è·å–å¤±è´¥")
                    return None
                
                df = pd.DataFrame(klines)
                # ğŸ”¥ ç¡®ä¿timestampæ˜¯datetimeç±»å‹
                if 'timestamp' in df.columns:
                    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
            
            if df is None or len(df) < 50:
                logger.warning(f"âŒ {timeframe} æ•°æ®ä¸è¶³")
                return None
            
            # è°ƒç”¨MLæœåŠ¡é¢„æµ‹
            prediction = await self.ml_service.predict(df, timeframe=timeframe)
            return prediction
            
        except Exception as e:
            logger.error(f"é¢„æµ‹{timeframe}å¤±è´¥: {e}")
            return None
    
    async def _try_synthesize_cached_signals(self, symbol: str) -> Optional[TradingSignal]:
        """å°è¯•åˆæˆæ‰€æœ‰ç¼“å­˜çš„ä¿¡å·"""
        try:
            # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰æ—¶é—´æ¡†æ¶éƒ½æœ‰ç¼“å­˜
            if not self.cached_predictions:
                logger.debug("âŒ ä¿¡å·ç¼“å­˜ä¸ºç©º")
                return None
            
            # å¦‚æœä¸æ˜¯æ‰€æœ‰æ—¶é—´æ¡†æ¶éƒ½æœ‰é¢„æµ‹ï¼Œå¯ä»¥ç»§ç»­ï¼ˆä½¿ç”¨å·²æœ‰çš„ï¼‰
            # âœ… 5mæ˜¯ä¸»æ—¶é—´æ¡†æ¶ï¼Œå¿…é¡»è¦æœ‰ï¼›å…¶ä»–æ—¶é—´æ¡†æ¶ï¼ˆ3mã€15mï¼‰æ˜¯è¾…åŠ©çš„ï¼Œæœ‰åˆ™ç”¨ï¼Œæ— åˆ™å¿½ç•¥
            if '5m' not in self.cached_predictions:
                logger.warning("âŒ ç¼ºå°‘5mä¸»ä¿¡å·ï¼Œæ— æ³•åˆæˆ")
                return None
            
            # åˆæˆä¿¡å·ï¼ˆåˆæˆè¿‡ç¨‹ä¸­çš„æ—¥å¿—å·²åœ¨_synthesize_signalä¸­è¾“å‡ºï¼‰
            # åªè¦æœ‰5mä¿¡å·å°±å¯ä»¥åˆæˆï¼Œå…¶ä»–æ—¶é—´æ¡†æ¶ï¼ˆ3mã€15mï¼‰æœ‰åˆ™ç”¨ï¼Œæ— åˆ™å¿½ç•¥ï¼ˆè¾…åŠ©ä½œç”¨ï¼‰
            signal = await self._synthesize_signal(symbol, self.cached_predictions)
            
            # å¦‚æœæ²¡æœ‰ä¿¡å·ï¼ˆHOLDæˆ–å…¶ä»–åŸå› ï¼‰ï¼Œç›´æ¥è¿”å›
            # _synthesize_signal å†…éƒ¨å·²ç»è®°å½•äº†è¯¦ç»†æ—¥å¿—
            if not signal:
                return None
            
            # æ£€æŸ¥ç½®ä¿¡åº¦
            if signal.confidence < self.confidence_threshold:
                logger.info(f"âŒ ç½®ä¿¡åº¦ä¸è¶³: {signal.confidence:.4f} < {self.confidence_threshold}")
                return None
            
            # æ£€æŸ¥ä¿¡å·å»é‡ï¼ˆå»é‡æ£€æŸ¥ä¸­çš„æ—¥å¿—å·²åœ¨_should_send_signalä¸­è¾“å‡ºï¼‰
            if not await self._should_send_signal(symbol, signal.signal_type):
                return None
            
            return signal
            
        except Exception as e:
            logger.error(f"åˆæˆä¿¡å·å¤±è´¥: {e}")
            return None
    
    async def generate_signal(self, symbol: str) -> Optional[TradingSignal]:
        """ç”Ÿæˆäº¤æ˜“ä¿¡å·ï¼ˆåŸºäºWebSocketå®æ—¶æ•°æ®ï¼‰"""
        try:
            logger.info(f"ğŸ”® å¼€å§‹ç”Ÿæˆäº¤æ˜“ä¿¡å·: {symbol}")
            logger.debug(f"æ•°æ®æº: WebSocket å®æ—¶ç¼“å†²åŒº (ä¼˜å…ˆ) / API (å¤‡ç”¨)")
            
            # è·å–å¤šæ—¶é—´æ¡†æ¶é¢„æµ‹
            predictions = await self._get_multi_timeframe_predictions(symbol)
            
            if not predictions:
                logger.warning(f"æœªè·å–åˆ°æœ‰æ•ˆé¢„æµ‹æ•°æ®")
                return None
            
            # åˆæˆä¿¡å·
            signal = await self._synthesize_signal(symbol, predictions)
            
            if not signal or signal.confidence < self.confidence_threshold:
                logger.info(f"âŒ ä¿¡å·ç½®ä¿¡åº¦ä¸è¶³: {signal.confidence if signal else 0:.4f} < {self.confidence_threshold}")
                return None
            
            # æ£€æŸ¥ä¿¡å·å»é‡ï¼ˆä»ç¼“å­˜ä¸­è·å–ä¸Šä¸€æ¬¡çš„ä¿¡å·ï¼‰
            if not await self._should_send_signal(symbol, signal.signal_type):
                logger.info(f"âœ— ä¿¡å·å·²å­˜åœ¨ï¼Œæ‹’ç»é‡å¤: {signal.signal_type} {signal.confidence:.4f}")
                return None
            
            logger.info(f"âœ… ç”Ÿæˆæ–°äº¤æ˜“ä¿¡å·: {format_signal_type(signal.signal_type)} ç½®ä¿¡åº¦:{signal.confidence:.4f}")
            return signal
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆäº¤æ˜“ä¿¡å·å¤±è´¥: {e}")
            return None
    
    async def _get_multi_timeframe_predictions(self, symbol: str) -> Dict[str, Dict[str, Any]]:
        """è·å–å¤šæ—¶é—´æ¡†æ¶é¢„æµ‹ - ä½¿ç”¨å›ºå®šå¤©æ•°ç¡®ä¿æ—¶é—´å¯¹é½"""
        try:
            predictions = {}
            
            # âœ… å·®å¼‚åŒ–é¢„æµ‹å¤©æ•°ï¼šæ¯ä¸ªæ—¶é—´æ¡†æ¶ä½¿ç”¨æœ€ä¼˜é…ç½®
            # åŸåˆ™ï¼šç¡®ä¿ç‰¹å¾å®Œæ•´ï¼ˆæœ€é•¿çª—å£200æœŸï¼‰+ é€‚åˆæ—¶é—´æ¡†æ¶ç‰¹æ€§
            prediction_days_config = {
                '3m': 10,    # 10å¤©=4800æ¡ï¼ˆè¶…çŸ­æœŸï¼Œé«˜é¢‘æ ·æœ¬ï¼‰
                '5m': 10,    # 10å¤©=2880æ¡ï¼ˆä¸»æ—¶é—´æ¡†æ¶ï¼Œå¿«é€Ÿå“åº”ï¼‰
                '15m': 10    # 10å¤©=960æ¡ï¼ˆè¶‹åŠ¿ç¡®è®¤ï¼‰
            }
            
            # æ—¶é—´å‘¨æœŸå¯¹åº”çš„åˆ†é’Ÿæ•°
            interval_minutes = {
                '1m': 1, '3m': 3, '5m': 5, '15m': 15, '30m': 30,
                '1h': 60, '6h': 360, '8h': 480,
                '12h': 720, '1d': 1440
            }
            
            for timeframe in settings.TIMEFRAMES:
                df = None
                data_source = ""
                
                # æ ¹æ®æ—¶é—´æ¡†æ¶ä½¿ç”¨å·®å¼‚åŒ–çš„é¢„æµ‹å¤©æ•°
                prediction_days = prediction_days_config.get(timeframe, 35)
                minutes = interval_minutes.get(timeframe, 60)
                required_klines = int((prediction_days * 24 * 60) / minutes)
                
                # ä¼˜å…ˆä½¿ç”¨WebSocketç¼“å†²åŒºæ•°æ®
                if timeframe in self.kline_buffers and len(self.kline_buffers[timeframe]) >= required_klines:
                    df = self.kline_buffers[timeframe].tail(required_klines).copy()
                    data_source = "WebSocketç¼“å†²åŒº"
                    logger.debug(f"âœ“ ä½¿ç”¨WebSocketç¼“å†²åŒº: {timeframe} (éœ€è¦{required_klines}æ¡, å½“å‰{len(df)}æ¡, {prediction_days}å¤©)")
                else:
                    # ç¼“å†²åŒºæ•°æ®ä¸è¶³ï¼Œä»APIè·å–ï¼ˆä½¿ç”¨ç»Ÿä¸€çš„åˆ†é¡µæ–¹æ³•ï¼‰
                    logger.debug(f"âš ï¸ ç¼“å†²åŒºæ•°æ®ä¸è¶³({len(self.kline_buffers.get(timeframe, []))}æ¡ < {required_klines}æ¡)ï¼Œä»APIè·å–: {timeframe} (éœ€è¦{required_klines}æ¡)")
                    klines = self.exchange_client.get_klines_paginated(
                        symbol=symbol,
                        interval=timeframe,
                        limit=required_klines
                    )
                    
                    if not klines:
                        logger.warning(f"âŒ æœªè·å–åˆ°{timeframe}æ•°æ®")
                        continue
                    
                    df = pd.DataFrame(klines)
                    # ğŸ”¥ ç¡®ä¿timestampæ˜¯datetimeç±»å‹
                    if 'timestamp' in df.columns:
                        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
                    data_source = "APIå¤‡ç”¨"
                
                if df is None or len(df) < 50:
                    logger.warning(f"âŒ {timeframe}æ•°æ®ä¸è¶³: {len(df) if df is not None else 0}æ¡")
                    continue
                
                logger.debug(f"ğŸ¤– å¼€å§‹{timeframe}æ¨¡å‹é¢„æµ‹ (æ•°æ®æº: {data_source}, {len(df)}æ¡Kçº¿)...")
                
                # æ¨¡å‹é¢„æµ‹ï¼ˆä¼ å…¥timeframeä½¿ç”¨å¯¹åº”çš„æ¨¡å‹ï¼‰
                prediction = await self.ml_service.predict(df, timeframe=timeframe)
                
                if prediction:
                    predictions[timeframe] = prediction
                    logger.debug(f"âœ… {timeframe}é¢„æµ‹å®Œæˆ: {prediction.get('signal_type')} (ç½®ä¿¡åº¦={prediction.get('confidence'):.4f})")
                else:
                    # é¢„æµ‹å¤±è´¥æˆ–æ¨¡å‹è®­ç»ƒä¸­ï¼ˆè¯¦ç»†ä¿¡æ¯å·²åœ¨ml_serviceå±‚è®°å½•ï¼‰
                    logger.debug(f"â¸ï¸ {timeframe}é¢„æµ‹æš‚ä¸å¯ç”¨")
            
            return predictions
            
        except Exception as e:
            logger.error(f"è·å–å¤šæ—¶é—´æ¡†æ¶é¢„æµ‹å¤±è´¥: {e}")
            return {}
    
    async def _synthesize_signal(
        self, 
        symbol: str, 
        predictions: Dict[str, Dict[str, Any]]
    ) -> Optional[TradingSignal]:
        """åˆæˆå¤šæ—¶é—´æ¡†æ¶ä¿¡å·"""
        try:
            if not predictions:
                logger.warning("âš ï¸ æ²¡æœ‰å¯ç”¨çš„é¢„æµ‹æ•°æ®ï¼Œæ— æ³•åˆæˆä¿¡å·")
                return None
            
            # æ—¶é—´æ¡†æ¶æƒé‡ï¼ˆè¶…çŸ­çº¿äº¤æ˜“ç­–ç•¥ï¼šä»¥5mä¸ºä¸»å¯¼ï¼‰
            # å·®å¼‚åŒ–è®­ç»ƒå¤©æ•°åçš„æ•°æ®é‡ï¼š
            # 3m:  57,600æ¡/120å¤© (è®­ç»ƒ46k)  âœ… è¶…çŸ­æœŸè¾…åŠ©ï¼Œå¿«é€Ÿååº”
            # 5m:  34,560æ¡/120å¤© (è®­ç»ƒ27.6k) âœ… ä¸»å¯¼ï¼Œæ•æ‰çŸ­æœŸå…¥åœºç‚¹
            # 15m: 11,520æ¡/120å¤© (è®­ç»ƒ9.2k)  âœ… ä¸­æœŸè¾…åŠ©ï¼Œè¶‹åŠ¿è¿‡æ»¤
            timeframe_weights = {
                '3m': 0.15,    # è¶…çŸ­æœŸè¾…åŠ©ï¼šæ•æ‰æçŸ­æœŸæ³¢åŠ¨
                '5m': 0.70,    # ğŸ¯ çŸ­çº¿ä¸»å¯¼ï¼šæé«˜æƒé‡ï¼Œå¿«é€Ÿæ•æ‰å…¥åœºç‚¹
                '15m': 0.15    # ä¸­æœŸè¾…åŠ©ï¼šè¶‹åŠ¿ç¡®è®¤ï¼Œé¿å…é€†åŠ¿äº¤æ˜“
            }
            
            # è®¡ç®—åŠ æƒä¿¡å·ï¼ˆåŠ¨æ€æƒé‡ï¼šé•¿å‘¨æœŸHOLDæ—¶é™æƒï¼‰
            weighted_scores = {'LONG': 0, 'SHORT': 0, 'HOLD': 0}
            total_weight = 0
            
            for timeframe, prediction in predictions.items():
                base_weight = timeframe_weights.get(timeframe, 0.2)
                probabilities = prediction.get('probabilities', {})
                signal = prediction.get('signal_type')
                
                # ğŸ”‘ åŠ¨æ€æƒé‡è°ƒæ•´ï¼šå¦‚æœé•¿å‘¨æœŸï¼ˆ15mï¼‰æ˜¯HOLDä¸”ç½®ä¿¡åº¦é«˜ï¼Œå¤§å¹…é™ä½æƒé‡
                if timeframe in ['15m'] and signal == 'HOLD':
                    hold_confidence = prediction.get('confidence', 0)
                    if hold_confidence > 0.65:
                        # HOLDç½®ä¿¡åº¦å¾ˆé«˜æ—¶ï¼Œæƒé‡å‡åŠï¼ˆé¿å…å‹åˆ¶5mï¼‰
                        weight = base_weight * 0.5
                        logger.debug(f"   {timeframe} HOLDé«˜ç½®ä¿¡åº¦({hold_confidence:.2f})ï¼Œæƒé‡{base_weight}â†’{weight}")
                    else:
                        weight = base_weight
                else:
                    weight = base_weight
                
                weighted_scores['LONG'] += probabilities.get('long', 0) * weight
                weighted_scores['SHORT'] += probabilities.get('short', 0) * weight
                weighted_scores['HOLD'] += probabilities.get('hold', 0) * weight
                
                total_weight += weight
            
            # å½’ä¸€åŒ–
            if total_weight > 0:
                for key in weighted_scores:
                    weighted_scores[key] /= total_weight
            
            # ç¡®å®šæœ€ç»ˆä¿¡å·
            signal_type = max(weighted_scores, key=weighted_scores.get)
            confidence = weighted_scores[signal_type]
            
            # è®°å½•åˆæˆè¿‡ç¨‹
            logger.info(f"ğŸ”„ ä¿¡å·åˆæˆ: {len(predictions)}ä¸ªæ—¶é—´æ¡†æ¶")
            for tf, pred in predictions.items():
                logger.info(f"  â€¢ {tf}: {format_signal_type(pred['signal_type'])} (ç½®ä¿¡åº¦={pred['confidence']:.4f})")
            logger.info(f"  âœ æœ€ç»ˆ: {format_signal_type(signal_type)} (åŠ æƒç½®ä¿¡åº¦={confidence:.4f})")
            
            # è¿‡æ»¤HOLDä¿¡å·
            if signal_type == 'HOLD':
                logger.info(f"âŠ— æœ€ç»ˆä¿¡å·ä¸ºHOLDï¼Œä¸å‘å‡ºäº¤æ˜“ä¿¡å·")
                return None
            
            # ğŸ†• ä¿¡å·å¢å¼ºè¿‡æ»¤ï¼ˆé¢„æœŸèƒœç‡+5-10%ï¼‰
            filter_result = await self._enhanced_signal_filter(
                signal_type=signal_type,
                confidence=confidence,
                predictions=predictions,
                symbol=symbol
            )
            
            if not filter_result['pass']:
                logger.info(f"âŒ ä¿¡å·è¢«è¿‡æ»¤: {filter_result['reason']}")
                return None
            
            # è·å–å½“å‰ä»·æ ¼
            current_price = await self._get_current_price(symbol)
            if not current_price:
                logger.warning("âš ï¸ æ— æ³•è·å–å½“å‰ä»·æ ¼ï¼Œæ”¾å¼ƒæœ¬æ¬¡ä¿¡å·")
                return None
            
            # ğŸ†• ä½¿ç”¨åŠ¨æ€æ­¢æŸæ­¢ç›ˆï¼ˆåŸºäºATRï¼‰
            stop_levels = await RiskService.calculate_dynamic_stop_levels(
                symbol=symbol,
                entry_price=current_price,
                signal_type=signal_type,
                confidence=confidence
            )
            
            if not stop_levels:
                logger.warning("âš ï¸ æ­¢æŸæ­¢ç›ˆè®¡ç®—å¤±è´¥ï¼Œä½¿ç”¨å›ºå®šç™¾åˆ†æ¯”")
                # é™çº§æ–¹æ¡ˆ
                if signal_type == 'LONG':
                    stop_loss = current_price * (1 - self.stop_loss_pct)
                    take_profit = current_price * (1 + self.take_profit_pct)
                else:  # SHORT
                    stop_loss = current_price * (1 + self.stop_loss_pct)
                    take_profit = current_price * (1 - self.take_profit_pct)
            else:
                stop_loss = stop_levels['stop_loss']
                take_profit = stop_levels['take_profit']
                logger.debug(f"âœ… ä½¿ç”¨åŠ¨æ€æ­¢æŸ: ç›ˆäºæ¯” 1:{stop_levels.get('risk_reward_ratio', 0):.2f}")
            
            # ğŸ†• ç»Ÿä¸€ä½¿ç”¨ position_manager è®¡ç®—ä»“ä½å¤§å°ï¼ˆUSDTä»·å€¼ï¼‰
            # ä» Redis è¯»å–å½“å‰äº¤æ˜“æ¨¡å¼ï¼ˆæ”¯æŒåŠ¨æ€åˆ‡æ¢ï¼‰
            current_mode = await cache_manager.get("system:trading_mode")
            is_virtual_mode = (current_mode != "AUTO")  # é»˜è®¤è™šæ‹Ÿæ¨¡å¼ï¼Œåªæœ‰æ˜ç¡®æ˜¯ AUTO æ‰ç”¨å®ç›˜
            
            # ğŸ”‘ è·å–ä»“ä½å¤§å°ï¼ˆç›´æ¥ä½¿ç”¨USDTä»·å€¼ï¼Œä¸æ¢ç®—å¼ æ•°ï¼‰
            position_size = await position_manager.calculate_position_size(
                symbol, signal_type, confidence, current_price,
                is_virtual=is_virtual_mode  # åŠ¨æ€æ ¹æ® Redis ä¸­çš„æ¨¡å¼å†³å®š
            )
            
            logger.debug(f"ğŸ’° ä»“ä½å¤§å°: {position_size:.2f} USDT @ {current_price:.2f}")
            
            # åˆ›å»ºä¿¡å·å¯¹è±¡
            signal = TradingSignal(
                timestamp=datetime.now(),
                symbol=symbol,
                signal_type=signal_type,
                confidence=confidence,
                entry_price=current_price,
                stop_loss=stop_loss,
                take_profit=take_profit,
                position_size=position_size,
                timeframe='multi',
                model_version='1.0',
                metadata={
                    'timeframe_predictions': predictions,
                    'weighted_scores': weighted_scores,
                    'generation_method': 'multi_timeframe_synthesis'
                }
            )
            
            return signal
            
        except Exception as e:
            logger.error(f"åˆæˆä¿¡å·å¤±è´¥: {e}")
            return None
    
    async def _get_current_price(self, symbol: str) -> Optional[float]:
        """è·å–å½“å‰ä»·æ ¼ - ç›´æ¥ä»APIè·å–å®æ—¶ä»·æ ¼"""
        try:
            # ä¼˜å…ˆä»ç¼“å­˜è·å–æœ€æ–°ä»·æ ¼ï¼ˆç¼“å­˜æ˜¯WebSocketå®æ—¶æ›´æ–°çš„ï¼‰
            ticker_data = await cache_manager.get_market_data(symbol, "ticker")
            
            if ticker_data:
                logger.debug(f"ä»ç¼“å­˜è·å–ä»·æ ¼: {ticker_data.get('price')}")
                return float(ticker_data.get('price', 0))
            
            # ç¼“å­˜å¤±æ•ˆæ—¶ï¼Œç›´æ¥ä»APIè·å–æœ€æ–°ä»·æ ¼
            logger.debug(f"ä»APIè·å–å®æ—¶ä»·æ ¼: {symbol}")
            # âœ… ç»Ÿä¸€ä½¿ç”¨åˆ†é¡µæ–¹æ³•ï¼ˆlimit=1æ—¶è‡ªåŠ¨è°ƒç”¨å•æ¬¡è·å–ï¼Œä¸å½±å“æ€§èƒ½ï¼‰
            klines = self.exchange_client.get_klines_paginated(symbol, '1m', limit=1)
            
            if klines and len(klines) > 0:
                # ğŸ”¥ UnifiedKlineDataæ˜¯å¯¹è±¡ï¼Œä½¿ç”¨å±æ€§è®¿é—®è€Œä¸æ˜¯ç´¢å¼•
                kline = klines[0]
                if isinstance(kline, dict):
                    price = float(kline.get('close', 0))
                else:
                    price = float(kline.close)
                logger.debug(f"âœ“ APIä»·æ ¼: {price}")
                return price
            
            logger.warning(f"æ— æ³•è·å–{symbol}çš„å½“å‰ä»·æ ¼")
            return None
            
        except Exception as e:
            logger.error(f"è·å–å½“å‰ä»·æ ¼å¤±è´¥: {e}")
            return None
    
    # âœ… å·²ç§»é™¤é‡å¤çš„ _calculate_position_size æ–¹æ³•
    # ç°åœ¨ç»Ÿä¸€ä½¿ç”¨ position_manager.calculate_position_size()
    
    async def _should_send_signal(self, symbol: str, signal_type: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦åº”è¯¥å‘é€ä¿¡å· - åŸºäºç¼“å­˜çš„ä¸Šä¸€æ¬¡ä¿¡å·å»é‡"""
        try:
            # ä»ç¼“å­˜è·å–ä¸Šä¸€æ¬¡çš„ä¿¡å·
            last_signal = await cache_manager.get_trading_signal(symbol)
            
            # å¦‚æœæ²¡æœ‰ç¼“å­˜çš„ä¿¡å·ï¼Œç›´æ¥å‘é€
            if not last_signal:
                logger.info(f"âœ“ æ— ç¼“å­˜ä¿¡å·ï¼Œå…è®¸å‘é€ {signal_type}")
                return True
            
            # è·å–ä¸Šä¸€æ¬¡çš„ä¿¡å·ç±»å‹
            last_signal_type = last_signal.get('signal_type')
            
            # å¦‚æœä¿¡å·ç±»å‹ç›¸åŒï¼Œæ‹’ç»ï¼ˆå»é‡ï¼‰- ç›¸åŒæ–¹å‘ä¸éœ€è¦é‡å¤å¼€ä»“
            if last_signal_type == signal_type:
                logger.warning(f"âœ— ä¿¡å·é‡å¤: ä¸Šæ¬¡={last_signal_type}, æœ¬æ¬¡={signal_type}")
                return False
            
            # ä¿¡å·ç±»å‹ä¸åŒï¼Œå…è®¸å‘é€ï¼ˆæ–¹å‘æ”¹å˜ï¼‰
            logger.info(f"âœ“ ä¿¡å·æ–¹å‘æ”¹å˜: {last_signal_type} â†’ {signal_type}")
            return True
            
        except Exception as e:
            logger.error(f"æ£€æŸ¥ä¿¡å·å»é‡å¤±è´¥: {e}")
            # å‘ç”Ÿé”™è¯¯æ—¶ä¿å®ˆå¤„ç†ï¼Œå…è®¸å‘é€ä¿¡å·
            return True
    
    async def _process_signal(self, signal: TradingSignal):
        """å¤„ç†ç”Ÿæˆçš„ä¿¡å·ï¼ˆæ³¨æ„ï¼šsignal_counterå·²åœ¨è°ƒç”¨å‰+1ï¼‰"""
        try:
            # ğŸ”’ å®‰å…¨ä¿æŠ¤ï¼šå‰5ä¸ªä¿¡å·ä»…è®°å½•ä¸äº¤æ˜“
            # æ³¨æ„ï¼šsignal_counterå·²åœ¨_on_new_dataä¸­+1ï¼Œè¿™é‡Œä¸å†é‡å¤
            
            if self.signal_counter <= self.warmup_signals:
                logger.warning(f"âš ï¸ é¢„çƒ­ä¿¡å· [{self.signal_counter}/{self.warmup_signals}]ï¼šä»…è®°å½•ï¼Œä¸æ‰§è¡Œäº¤æ˜“")
                logger.info(f"   ä¿¡å·è¯¦æƒ…: {format_signal_type(signal.signal_type)} ç½®ä¿¡åº¦={signal.confidence:.4f} å…¥åœº={signal.entry_price:.2f}")
                
                # åªä¿å­˜åˆ°æ•°æ®åº“ç”¨äºè§‚å¯Ÿï¼Œä¸å‘é€ç»™äº¤æ˜“å¼•æ“
                await self._save_signal(signal)
                
                logger.info(f"âœ… é¢„çƒ­ä¿¡å·å·²è®°å½•åˆ°æ•°æ®åº“ (å‰©ä½™{self.warmup_signals - self.signal_counter}ä¸ªé¢„çƒ­ä¿¡å·)")
                return  # ğŸ”’ ç›´æ¥è¿”å›ï¼Œä¸æ‰§è¡Œåç»­äº¤æ˜“é€»è¾‘
            
            # âœ… é¢„çƒ­å®Œæˆï¼Œæ­£å¼äº¤æ˜“ä¿¡å·
            logger.info(f"ğŸš€ æ­£å¼äº¤æ˜“ä¿¡å· (ç¬¬{self.signal_counter}ä¸ª): {format_signal_type(signal.signal_type)} ç½®ä¿¡åº¦={signal.confidence:.4f}")
            
            # æ›´æ–°æœ€åä¿¡å·è®°å½•
            self.last_signals[signal.symbol] = signal
            
            # å­˜å‚¨ä¿¡å·åˆ°æ•°æ®åº“
            await self._save_signal(signal)
            
            # ç¼“å­˜ä¿¡å·ï¼ˆä¸è®¾ç½®è¿‡æœŸæ—¶é—´ï¼Œç”¨äºä¿¡å·å»é‡ï¼‰
            await cache_manager.set_trading_signal(
                signal.symbol,
                {
                    'signal_type': signal.signal_type,
                    'confidence': signal.confidence,
                    'entry_price': signal.entry_price,
                    'stop_loss': signal.stop_loss,
                    'take_profit': signal.take_profit,
                    'position_size': signal.position_size,
                    'timestamp': signal.timestamp.isoformat()
                },
                expire=None  # ä¸è¿‡æœŸï¼Œåªåœ¨æ–°ä¿¡å·äº§ç”Ÿæ—¶è¦†ç›–
            )
            
            # é€šçŸ¥å›è°ƒå‡½æ•°ï¼ˆå‘é€ç»™äº¤æ˜“å¼•æ“ï¼‰
            if not self.signal_callbacks:
                logger.warning(f"âš ï¸ æ²¡æœ‰æ³¨å†Œçš„ä¿¡å·å›è°ƒå‡½æ•°ï¼Œä¿¡å·å°†ä¸ä¼šè¢«æ‰§è¡Œï¼")
                logger.warning(f"   è¯·æ£€æŸ¥trading_controlleræ˜¯å¦æ­£ç¡®æ³¨å†Œäº†å›è°ƒ")
            else:
                logger.info(f"ğŸ“¤ å‡†å¤‡å‘é€ä¿¡å·åˆ°{len(self.signal_callbacks)}ä¸ªå›è°ƒå‡½æ•°")
                for idx, callback in enumerate(self.signal_callbacks):
                    try:
                        logger.debug(f"   è°ƒç”¨å›è°ƒå‡½æ•° {idx+1}/{len(self.signal_callbacks)}: {callback.__name__ if hasattr(callback, '__name__') else type(callback).__name__}")
                        await callback(signal)
                        logger.debug(f"   âœ… å›è°ƒå‡½æ•° {idx+1} æ‰§è¡ŒæˆåŠŸ")
                    except Exception as e:
                        logger.error(f"   âŒ å›è°ƒå‡½æ•° {idx+1} æ‰§è¡Œå¤±è´¥: {e}", exc_info=True)
            
            logger.info(f"âœ… äº¤æ˜“ä¿¡å·å·²å‘é€: {signal.symbol} {signal.signal_type}")
            
        except Exception as e:
            logger.error(f"å¤„ç†ä¿¡å·å¤±è´¥: {e}")
    
    async def _save_signal(self, signal: TradingSignal):
        """ä¿å­˜ä¿¡å·åˆ°æ•°æ®åº“ï¼ˆåªä¿å­˜ä¸€ä¸ªåˆæˆä¿¡å·ï¼Œpredictionsä¿ç•™åŸå§‹é¢„æµ‹è¯¦æƒ…ï¼‰"""
        try:
            # å¤„ç† predictions ä¸­çš„ datetime å¯¹è±¡ï¼ˆè½¬æ¢ä¸º ISO æ ¼å¼å­—ç¬¦ä¸²ï¼‰
            predictions = signal.metadata.get('timeframe_predictions', {})
            cleaned_predictions = {}
            for tf, pred in predictions.items():
                cleaned_pred = pred.copy()
                # å°† datetime å¯¹è±¡è½¬æ¢ä¸ºå­—ç¬¦ä¸²
                if 'timestamp' in cleaned_pred and hasattr(cleaned_pred['timestamp'], 'isoformat'):
                    cleaned_pred['timestamp'] = cleaned_pred['timestamp'].isoformat()
                cleaned_predictions[tf] = cleaned_pred
            
            signal_data = {
                'timestamp': signal.timestamp,
                'symbol': signal.symbol,
                'signal_type': signal.signal_type,
                'confidence': signal.confidence,
                'entry_price': signal.entry_price,
                'stop_loss': signal.stop_loss,
                'take_profit': signal.take_profit,
                'position_size': signal.position_size,
                # ä¿å­˜3ä¸ªæ—¶é—´æ¡†æ¶çš„é¢„æµ‹ä¿¡æ¯åˆ°predictionså­—æ®µï¼ˆå·²æ¸…ç† datetimeï¼‰
                'predictions': cleaned_predictions
            }
            
            await postgresql_manager.write_signal_data(signal_data)
            
        except Exception as e:
            logger.error(f"ä¿å­˜ä¿¡å·å¤±è´¥: {e}")
    
    async def get_recent_signals(
        self, 
        symbol: str, 
        hours: int = 24, 
        limit: int = 100
    ) -> List[Dict[str, Any]]:
        """è·å–æœ€è¿‘çš„ä¿¡å·"""
        try:
            end_time = datetime.now()
            start_time = end_time - timedelta(hours=hours)
            
            signals = await postgresql_manager.query_signals(
                symbol, start_time, end_time, limit
            )
            
            return signals
            
        except Exception as e:
            logger.error(f"è·å–æœ€è¿‘ä¿¡å·å¤±è´¥: {e}")
            return []
    
    async def get_signal_performance(self, symbol: str, days: int = 7) -> Dict[str, Any]:
        """è·å–ä¿¡å·è¡¨ç°ç»Ÿè®¡"""
        try:
            end_time = datetime.now()
            start_time = end_time - timedelta(days=days)
            
            signals = await postgresql_manager.query_signals(
                symbol, start_time, end_time
            )
            
            if not signals:
                return {}
            
            # ç»Ÿè®¡ä¿¡å·æ•°é‡
            total_signals = len(signals)
            long_signals = len([s for s in signals if s['signal_type'] == 'LONG'])
            short_signals = len([s for s in signals if s['signal_type'] == 'SHORT'])
            
            # å¹³å‡ç½®ä¿¡åº¦
            avg_confidence = np.mean([s['confidence'] for s in signals])
            
            # ä¿¡å·é¢‘ç‡ï¼ˆæ¯å¤©ï¼‰
            signal_frequency = total_signals / days
            
            performance = {
                'total_signals': total_signals,
                'long_signals': long_signals,
                'short_signals': short_signals,
                'long_ratio': long_signals / total_signals if total_signals > 0 else 0,
                'short_ratio': short_signals / total_signals if total_signals > 0 else 0,
                'avg_confidence': avg_confidence,
                'signal_frequency': signal_frequency,
                'period_days': days
            }
            
            return performance
            
        except Exception as e:
            logger.error(f"è·å–ä¿¡å·è¡¨ç°å¤±è´¥: {e}")
            return {}
    
    async def _enhanced_signal_filter(
        self,
        signal_type: str,
        confidence: float,
        predictions: Dict[str, Dict[str, Any]],
        symbol: str
    ) -> Dict[str, Any]:
        """å¢å¼ºçš„ä¿¡å·è¿‡æ»¤ï¼ˆä¼˜åŒ–ç›®æ ‡ï¼šèƒœç‡+5-10%ï¼‰
        
        å¤šç»´åº¦è¿‡æ»¤ä½è´¨é‡ä¿¡å·ï¼š
        1. è¶‹åŠ¿ä¸€è‡´æ€§è¿‡æ»¤
        2. é‡èƒ½ç¡®è®¤
        3. æ³¢åŠ¨ç‡è¿‡æ»¤
        4. æ—¶é—´è¿‡æ»¤
        
        Returns:
            {'pass': bool, 'reason': str}
        """
        try:
            # 1. ç½®ä¿¡åº¦åŸºç¡€è¿‡æ»¤ï¼ˆå·²æœ‰ï¼‰
            if confidence < self.confidence_threshold:
                return {'pass': False, 'reason': f'ç½®ä¿¡åº¦è¿‡ä½ ({confidence:.4f} < {self.confidence_threshold})'}
            
            # 2. è¶‹åŠ¿ä¸€è‡´æ€§è¿‡æ»¤
            # æ£€æŸ¥å¤šæ—¶é—´æ¡†æ¶æ˜¯å¦è¶‹åŠ¿ä¸€è‡´
            if len(predictions) >= 2:
                signal_types = [pred['signal_type'] for pred in predictions.values()]
                # å¦‚æœæœ‰ä»»ä½•ä¸€ä¸ªæ—¶é—´æ¡†æ¶æ˜¯åå‘ä¿¡å·ï¼Œè¿‡æ»¤
                if signal_type == 'LONG' and 'SHORT' in signal_types:
                    # ä½†å¦‚æœ15mç½®ä¿¡åº¦ç‰¹åˆ«é«˜ï¼ˆ>0.7ï¼‰ï¼Œå…è®¸é€šè¿‡
                    if confidence < 0.7:
                        return {'pass': False, 'reason': 'å¤šæ—¶é—´æ¡†æ¶è¶‹åŠ¿ä¸ä¸€è‡´ï¼ˆæœ‰SHORTä¿¡å·ï¼‰'}
                elif signal_type == 'SHORT' and 'LONG' in signal_types:
                    if confidence < 0.7:
                        return {'pass': False, 'reason': 'å¤šæ—¶é—´æ¡†æ¶è¶‹åŠ¿ä¸ä¸€è‡´ï¼ˆæœ‰LONGä¿¡å·ï¼‰'}
            
            # 3. æ³¢åŠ¨ç‡è¿‡æ»¤ï¼ˆé¿å…åœ¨æç«¯æ³¢åŠ¨æ—¶äº¤æ˜“ï¼‰
            try:
                # è·å–æœ€æ–°5m Kçº¿æ•°æ®æ¥è®¡ç®—æ³¢åŠ¨ç‡ï¼ˆä¸»æ—¶é—´æ¡†æ¶ï¼‰
                buffer_data = self.kline_buffers.get('5m', [])
                if len(buffer_data) >= 60:  # 5méœ€è¦æ›´å¤šæ ·æœ¬ï¼ˆ60ä¸ª=5å°æ—¶ï¼‰
                    recent_closes = [k['close'] for k in buffer_data[-60:]]
                    returns = [(recent_closes[i] - recent_closes[i-1]) / recent_closes[i-1] 
                              for i in range(1, len(recent_closes))]
                    current_volatility = np.std(returns)
                    
                    # æ—¥æ³¢åŠ¨ç‡ä¼°ç®—ï¼ˆ5åˆ†é’Ÿ â†’ æ—¥ï¼Œå‡è®¾288ä¸ª5åˆ†é’Ÿå‘¨æœŸï¼‰
                    daily_volatility = current_volatility * np.sqrt(288)
                    
                    if daily_volatility > 0.08:  # æ—¥æ³¢åŠ¨ç‡>8%
                        return {'pass': False, 'reason': f'å¸‚åœºæ³¢åŠ¨è¿‡å¤§ (æ—¥æ³¢åŠ¨ç‡={daily_volatility*100:.2f}%)'}
                    
                    if daily_volatility < 0.005:  # æ—¥æ³¢åŠ¨ç‡<0.5%
                        return {'pass': False, 'reason': f'å¸‚åœºæ³¢åŠ¨è¿‡å° (æ—¥æ³¢åŠ¨ç‡={daily_volatility*100:.2f}%)'}
            except Exception as e:
                logger.debug(f"æ³¢åŠ¨ç‡è®¡ç®—å¤±è´¥ï¼ˆè·³è¿‡æ­¤è¿‡æ»¤ï¼‰: {e}")
            
            # 4. é‡èƒ½ç¡®è®¤ï¼ˆé«˜ç½®ä¿¡åº¦ä¿¡å·éœ€è¦é‡èƒ½é…åˆï¼‰
            if confidence > 0.6:  # é«˜ç½®ä¿¡åº¦ä¿¡å·
                try:
                    buffer_data = self.kline_buffers.get('5m', [])
                    if len(buffer_data) >= 60:  # 5méœ€è¦æ›´å¤šæ ·æœ¬
                        recent_volumes = [k['volume'] for k in buffer_data[-20:]]
                        current_volume = buffer_data[-1]['volume']
                        avg_volume = np.mean(recent_volumes)
                        
                        # é«˜ç½®ä¿¡åº¦ä¿¡å·éœ€è¦é‡èƒ½è‡³å°‘è¾¾åˆ°å¹³å‡çš„70%
                        if current_volume < avg_volume * 0.7:
                            return {'pass': False, 'reason': f'é‡èƒ½ä¸è¶³ï¼ˆå½“å‰={current_volume:.0f}, å¹³å‡={avg_volume:.0f}ï¼‰'}
                except Exception as e:
                    logger.debug(f"é‡èƒ½æ£€æŸ¥å¤±è´¥ï¼ˆè·³è¿‡æ­¤è¿‡æ»¤ï¼‰: {e}")
            
            # 5. ä¿¡å·é¢‘ç‡é™åˆ¶ï¼ˆåŠ¨æ€é™åˆ¶ï¼ŒåŸºäºä¸»æ—¶é—´æ¡†æ¶ï¼‰
            # è¶…çŸ­çº¿ç­–ç•¥éœ€è¦åœ¨ä¿æŒçµæ´»æ€§çš„åŒæ—¶é¿å…è¿‡åº¦äº¤æ˜“
            try:
                # ğŸ”‘ åŸºäºæ—¶é—´æ¡†æ¶çš„åŠ¨æ€é™åˆ¶ç­–ç•¥
                # è®¡ç®—é€»è¾‘ï¼š1å°æ—¶å†…çš„Kçº¿æ•° Ã— åˆç†è§¦å‘ç‡
                timeframe_limits = {
                    '3m': 8,   # 3m: 1å°æ—¶20ä¸ªKçº¿ Ã— 40% = 8ä¸ªä¿¡å·
                    '5m': 6,   # 5m: 1å°æ—¶12ä¸ªKçº¿ Ã— 50% = 6ä¸ªä¿¡å·ï¼ˆä¸»æ—¶é—´æ¡†æ¶ï¼‰
                    '15m': 3   # 15m: 1å°æ—¶4ä¸ªKçº¿ Ã— 75% = 3ä¸ªä¿¡å·
                }
                
                # ä½¿ç”¨ä¸»æ—¶é—´æ¡†æ¶ï¼ˆ5mï¼‰çš„é™åˆ¶
                main_timeframe = '5m'  # å½“å‰ç³»ç»Ÿä¸»æ—¶é—´æ¡†æ¶
                max_signals_per_hour = timeframe_limits.get(main_timeframe, 6)
                
                # æŸ¥è¯¢æœ€è¿‘1å°æ—¶çš„ä¿¡å·
                recent_signals = await self.get_recent_signals(
                    symbol, 
                    hours=1, 
                    limit=max_signals_per_hour + 2  # å¤šæŸ¥2ä¸ªç”¨äºå‡†ç¡®åˆ¤æ–­
                )
                
                if len(recent_signals) >= max_signals_per_hour:
                    return {
                        'pass': False, 
                        'reason': f'ä¿¡å·é¢‘ç‡è¿‡é«˜ï¼ˆ1å°æ—¶å†…å·²æœ‰{len(recent_signals)}ä¸ªï¼Œ{main_timeframe}é™åˆ¶{max_signals_per_hour}ä¸ªï¼‰'
                    }
                
                # è°ƒè¯•æ—¥å¿—ï¼šæ˜¾ç¤ºå½“å‰ä¿¡å·é¢‘ç‡çŠ¶æ€
                logger.debug(f"âœ“ ä¿¡å·é¢‘ç‡æ£€æŸ¥é€šè¿‡: {len(recent_signals)}/{max_signals_per_hour} ({main_timeframe})")
                
            except Exception as e:
                logger.debug(f"ä¿¡å·é¢‘ç‡æ£€æŸ¥å¤±è´¥ï¼ˆè·³è¿‡æ­¤è¿‡æ»¤ï¼‰: {e}")
            
            # 6. æ‰€æœ‰è¿‡æ»¤å™¨é€šè¿‡
            logger.info(f"âœ… ä¿¡å·é€šè¿‡æ‰€æœ‰å¢å¼ºè¿‡æ»¤å™¨")
            return {'pass': True, 'reason': 'é€šè¿‡æ‰€æœ‰è¿‡æ»¤æ¡ä»¶'}
            
        except Exception as e:
            logger.error(f"ä¿¡å·è¿‡æ»¤å¤±è´¥: {e}")
            # è¿‡æ»¤å¤±è´¥æ—¶ä¿å®ˆå¤„ç†ï¼šé€šè¿‡ä¿¡å·ï¼ˆé¿å…é”™å¤±æœºä¼šï¼‰
            return {'pass': True, 'reason': 'è¿‡æ»¤å™¨å¼‚å¸¸ï¼Œé»˜è®¤é€šè¿‡'}
    
    def add_signal_callback(self, callback: callable):
        """æ·»åŠ ä¿¡å·å›è°ƒå‡½æ•°"""
        self.signal_callbacks.append(callback)
    
    def remove_signal_callback(self, callback: callable):
        """ç§»é™¤ä¿¡å·å›è°ƒå‡½æ•°"""
        if callback in self.signal_callbacks:
            self.signal_callbacks.remove(callback)
    
    async def force_generate_signal(self, symbol: str) -> Optional[TradingSignal]:
        """å¼ºåˆ¶ç”Ÿæˆä¿¡å·ï¼ˆç”¨äºæ‰‹åŠ¨è§¦å‘ï¼‰"""
        try:
            logger.info(f"å¼ºåˆ¶ç”Ÿæˆä¿¡å·: {symbol}")
            
            # ä¸´æ—¶ç§»é™¤æ—¶é—´é—´éš”é™åˆ¶
            original_interval = self.min_signal_interval
            self.min_signal_interval = 0
            
            signal = await self.generate_signal(symbol)
            
            # æ¢å¤æ—¶é—´é—´éš”é™åˆ¶
            self.min_signal_interval = original_interval
            
            if signal:
                await self._process_signal(signal)
            
            return signal
            
        except Exception as e:
            logger.error(f"å¼ºåˆ¶ç”Ÿæˆä¿¡å·å¤±è´¥: {e}")
            return None
    
    async def _load_warmup_state(self):
        """ä»RedisåŠ è½½é¢„çƒ­çŠ¶æ€ï¼ˆæŒä¹…åŒ–ï¼Œé¿å…é‡å¯/é‡è®­ç»ƒåé‡æ–°é¢„çƒ­ï¼‰"""
        try:
            # ä»RedisåŠ è½½ä¿¡å·è®¡æ•°å™¨
            cached_counter = await cache_manager.get(f"warmup:signal_counter:{settings.SYMBOL}")
            
            if cached_counter is not None:
                self.signal_counter = int(cached_counter)
                logger.info(f"ğŸ“‚ å·²åŠ è½½é¢„çƒ­çŠ¶æ€: {self.signal_counter}/{self.warmup_signals} ä¸ªä¿¡å·")
                
                if self.signal_counter >= self.warmup_signals:
                    logger.info(f"âœ… é¢„çƒ­å·²åœ¨ä¹‹å‰å®Œæˆï¼Œç³»ç»Ÿå¤„äºæ­£å¸¸äº¤æ˜“æ¨¡å¼")
            else:
                logger.info(f"ğŸ“‚ é¦–æ¬¡éƒ¨ç½²ï¼Œåˆå§‹åŒ–é¢„çƒ­çŠ¶æ€: 0/{self.warmup_signals}")
                await self._save_warmup_state()
                
        except Exception as e:
            logger.warning(f"åŠ è½½é¢„çƒ­çŠ¶æ€å¤±è´¥ï¼ˆä½¿ç”¨é»˜è®¤å€¼0ï¼‰: {e}")
            self.signal_counter = 0
    
    async def _save_warmup_state(self):
        """ä¿å­˜é¢„çƒ­çŠ¶æ€åˆ°Redisï¼ˆæ— è¿‡æœŸæ—¶é—´ï¼Œæ°¸ä¹…ä¿å­˜ï¼‰"""
        try:
            # ä¿å­˜ä¿¡å·è®¡æ•°å™¨åˆ°Redisï¼ˆä¸è¿‡æœŸï¼‰
            await cache_manager.set(
                f"warmup:signal_counter:{settings.SYMBOL}",
                self.signal_counter,
                expire=None  # æ°¸ä¸è¿‡æœŸ
            )
            logger.debug(f"ğŸ’¾ é¢„çƒ­çŠ¶æ€å·²ä¿å­˜: {self.signal_counter}/{self.warmup_signals}")
            
        except Exception as e:
            logger.warning(f"ä¿å­˜é¢„çƒ­çŠ¶æ€å¤±è´¥: {e}")