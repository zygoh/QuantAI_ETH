"""
ç‰¹å¾å·¥ç¨‹æ¨¡å—
"""
import logging
from typing import Dict, List, Any, Optional
import pandas as pd
import numpy as np
from datetime import datetime
import ta

logger = logging.getLogger(__name__)

class FeatureEngineer:
    """ç‰¹å¾å·¥ç¨‹å™¨"""
    
    def __init__(self):
        self.feature_columns = []
    
    def create_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """åˆ›å»ºæ‰€æœ‰ç‰¹å¾"""
        try:
            if df.empty:
                return df
            
            logger.info(f"ğŸ”§ å¼€å§‹ç‰¹å¾å·¥ç¨‹: {len(df)}è¡ŒåŸå§‹æ•°æ®")
            
            # å¤„ç† timestampï¼šå¦‚æœæ˜¯ indexï¼Œé‡ç½®ä¸ºåˆ—
            if df.index.name == 'timestamp' or 'timestamp' not in df.columns:
                df = df.reset_index()
            
            # ğŸ”¥ ç¡®ä¿ timestamp åˆ—æ˜¯ç»Ÿä¸€çš„ datetime ç±»å‹ï¼ˆé¿å…æ··åˆç±»å‹å¯¼è‡´æ’åºå¤±è´¥ï¼‰
            if 'timestamp' in df.columns:
                if not pd.api.types.is_datetime64_any_dtype(df['timestamp']):
                    df['timestamp'] = pd.to_datetime(df['timestamp'])
            
            # ç¡®ä¿æ•°æ®æŒ‰æ—¶é—´æ’åº
            df = df.sort_values('timestamp').reset_index(drop=True)
            
            # åŸºç¡€ä»·æ ¼ç‰¹å¾
            df = self._add_price_features(df)
            
            # æŠ€æœ¯æŒ‡æ ‡ç‰¹å¾
            df = self._add_technical_indicators(df)
            
            # æˆäº¤é‡ç‰¹å¾
            df = self._add_volume_features(df)
            
            # æ—¶é—´ç‰¹å¾
            df = self._add_time_features(df)
            
            # å¸‚åœºå¾®è§‚ç»“æ„ç‰¹å¾
            df = self._add_microstructure_features(df)
            
            # æ³¢åŠ¨ç‡ç‰¹å¾
            df = self._add_volatility_features(df)
            
            # åŠ¨é‡ç‰¹å¾
            df = self._add_momentum_features(df)
            
            # ğŸ†• å¸‚åœºæƒ…ç»ªç‰¹å¾
            df = self._add_sentiment_features(df)
            
            # ç§»é™¤åŒ…å«NaNçš„è¡Œ
            df = df.dropna()
            
            logger.info(f"âœ… ç‰¹å¾å·¥ç¨‹å®Œæˆ: {len(df)}è¡Œï¼Œç‰¹å¾æ•°: {len(df.columns)}")  # æ”¹ä¸ºINFOçº§åˆ«
            
            return df
            
        except Exception as e:
            logger.error(f"âŒ ç‰¹å¾å·¥ç¨‹å¤±è´¥: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return df
    
    def _add_price_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """æ·»åŠ ä»·æ ¼ç‰¹å¾ - ä¼˜åŒ–æ€§èƒ½"""
        try:
            new_features = {}
            
            # ä»·æ ¼å˜åŒ–ç‡
            price_change = df['close'].pct_change()
            new_features['price_change'] = price_change
            new_features['price_change_abs'] = price_change.abs()
            
            # ä»·æ ¼èŒƒå›´
            new_features['price_range'] = (df['high'] - df['low']) / df['close']
            new_features['upper_shadow'] = (df['high'] - df[['open', 'close']].max(axis=1)) / df['close']
            new_features['lower_shadow'] = (df[['open', 'close']].min(axis=1) - df['low']) / df['close']
            
            # å¼€ç›˜ä»·ä¸æ”¶ç›˜ä»·å…³ç³»
            new_features['open_close_ratio'] = df['open'] / df['close']
            new_features['body_size'] = abs(df['close'] - df['open']) / df['close']
            
            # ä»·æ ¼ä½ç½®
            new_features['close_position'] = (df['close'] - df['low']) / (df['high'] - df['low'])
            
            # å¤šå‘¨æœŸä»·æ ¼å˜åŒ–
            for period in [2, 3, 5, 10, 20]:
                new_features[f'price_change_{period}'] = df['close'].pct_change(period)
                new_features[f'high_low_ratio_{period}'] = df['high'].rolling(period).max() / df['low'].rolling(period).min()
            
            # âœ… ä»·æ ¼åŠ é€Ÿåº¦ï¼ˆæ•æ‰è¶‹åŠ¿åŠ é€Ÿ/å‡é€Ÿï¼‰
            new_features['price_acceleration'] = price_change - price_change.shift(1)
            new_features['price_acceleration_3'] = price_change - price_change.shift(3)
            new_features['price_acceleration_5'] = price_change - price_change.shift(5)
            
            # âœ… è¿ç»­æ¶¨è·Œï¼ˆæ•æ‰è¶‹åŠ¿å»¶ç»­æ€§ï¼‰
            new_features['consecutive_up'] = (df['close'] > df['close'].shift(1)).astype(int).rolling(5).sum()
            new_features['consecutive_down'] = (df['close'] < df['close'].shift(1)).astype(int).rolling(5).sum()
            
            # âœ… ä»·æ ¼åŠ¨é‡å¼ºåº¦
            new_features['price_momentum_strength'] = price_change.abs().rolling(5).mean()
            new_features['price_momentum_direction'] = price_change.rolling(5).mean() / (price_change.rolling(5).std() + 1e-8)
            
            # ä¸€æ¬¡æ€§æ·»åŠ æ‰€æœ‰ç‰¹å¾
            df = pd.concat([df, pd.DataFrame(new_features, index=df.index)], axis=1)
            
            return df
            
        except Exception as e:
            logger.error(f"æ·»åŠ ä»·æ ¼ç‰¹å¾å¤±è´¥: {e}")
            return df
    
    def _add_technical_indicators(self, df: pd.DataFrame) -> pd.DataFrame:
        """æ·»åŠ æŠ€æœ¯æŒ‡æ ‡ç‰¹å¾ - ä¼˜åŒ–æ€§èƒ½"""
        try:
            new_features = {}
            
            # RSI
            for period in [14, 21, 30]:
                new_features[f'rsi_{period}'] = ta.momentum.RSIIndicator(df['close'], window=period).rsi()
            
            # MACD
            macd = ta.trend.MACD(df['close'])
            new_features['macd'] = macd.macd()
            new_features['macd_signal'] = macd.macd_signal()
            new_features['macd_histogram'] = macd.macd_diff()
            
            # Bollinger Bands
            for period in [20, 50]:
                bb = ta.volatility.BollingerBands(df['close'], window=period)
                bb_upper = bb.bollinger_hband()
                bb_lower = bb.bollinger_lband()
                bb_middle = bb.bollinger_mavg()
                
                new_features[f'bb_upper_{period}'] = bb_upper
                new_features[f'bb_lower_{period}'] = bb_lower
                new_features[f'bb_middle_{period}'] = bb_middle
                new_features[f'bb_width_{period}'] = (bb_upper - bb_lower) / bb_middle
                new_features[f'bb_position_{period}'] = (df['close'] - bb_lower) / (bb_upper - bb_lower)
            
            # ç§»åŠ¨å¹³å‡çº¿
            sma_dict = {}
            ema_dict = {}
            for period in [5, 10, 20, 50, 100, 200]:
                sma = ta.trend.SMAIndicator(df['close'], window=period).sma_indicator()
                ema = ta.trend.EMAIndicator(df['close'], window=period).ema_indicator()
                
                sma_dict[period] = sma
                ema_dict[period] = ema
                
                new_features[f'sma_{period}'] = sma
                new_features[f'ema_{period}'] = ema
                new_features[f'price_sma_ratio_{period}'] = df['close'] / sma
                new_features[f'price_ema_ratio_{period}'] = df['close'] / ema
            
            # ç§»åŠ¨å¹³å‡çº¿äº¤å‰
            new_features['sma_5_20_cross'] = np.where(sma_dict[5] > sma_dict[20], 1, 0)
            new_features['sma_10_50_cross'] = np.where(sma_dict[10] > sma_dict[50], 1, 0)
            new_features['ema_5_20_cross'] = np.where(ema_dict[5] > ema_dict[20], 1, 0)
            
            # Stochastic
            stoch = ta.momentum.StochasticOscillator(df['high'], df['low'], df['close'])
            new_features['stoch_k'] = stoch.stoch()
            new_features['stoch_d'] = stoch.stoch_signal()
            
            # Williams %R
            new_features['williams_r'] = ta.momentum.WilliamsRIndicator(df['high'], df['low'], df['close']).williams_r()
            
            # CCI (Commodity Channel Index)
            new_features['cci'] = ta.trend.CCIIndicator(df['high'], df['low'], df['close']).cci()
            
            # ADX (Average Directional Index)
            adx = ta.trend.ADXIndicator(df['high'], df['low'], df['close'])
            new_features['adx'] = adx.adx()
            new_features['adx_pos'] = adx.adx_pos()
            new_features['adx_neg'] = adx.adx_neg()
            
            # Parabolic SAR
            psar = ta.trend.PSARIndicator(df['high'], df['low'], df['close']).psar()
            new_features['psar'] = psar
            new_features['psar_signal'] = np.where(df['close'] > psar, 1, 0)
            
            # ä¸€æ¬¡æ€§æ·»åŠ æ‰€æœ‰ç‰¹å¾
            df = pd.concat([df, pd.DataFrame(new_features, index=df.index)], axis=1)
            
            return df
            
        except Exception as e:
            logger.error(f"æ·»åŠ æŠ€æœ¯æŒ‡æ ‡å¤±è´¥: {e}")
            return df
    
    def _add_volume_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """æ·»åŠ æˆäº¤é‡ç‰¹å¾ - ä¼˜åŒ–æ€§èƒ½"""
        try:
            new_features = {}
            
            # æˆäº¤é‡å˜åŒ–
            volume_change = df['volume'].pct_change()
            volume_sma_5 = df['volume'].rolling(5).mean()
            volume_sma_20 = df['volume'].rolling(20).mean()
            
            new_features['volume_change'] = volume_change
            new_features['volume_sma_5'] = volume_sma_5
            new_features['volume_sma_20'] = volume_sma_20
            new_features['volume_ratio'] = df['volume'] / volume_sma_20
            
            # ä»·é‡å…³ç³»
            new_features['price_volume_trend'] = df['price_change'] * volume_change
            
            # OBV (On Balance Volume)
            obv = ta.volume.OnBalanceVolumeIndicator(df['close'], df['volume']).on_balance_volume()
            new_features['obv'] = obv
            new_features['obv_sma'] = obv.rolling(20).mean()
            
            # Volume Price Trend
            new_features['vpt'] = ta.volume.VolumePriceTrendIndicator(df['close'], df['volume']).volume_price_trend()
            
            # Accumulation/Distribution Line
            new_features['ad_line'] = ta.volume.AccDistIndexIndicator(df['high'], df['low'], df['close'], df['volume']).acc_dist_index()
            
            # Chaikin Money Flow
            new_features['cmf'] = ta.volume.ChaikinMoneyFlowIndicator(df['high'], df['low'], df['close'], df['volume']).chaikin_money_flow()
            
            # Volume Weighted Average Price (VWAP)
            vwap = (df['close'] * df['volume']).rolling(20).sum() / df['volume'].rolling(20).sum()
            new_features['vwap'] = vwap
            new_features['price_vwap_ratio'] = df['close'] / vwap
            
            # âœ… æˆäº¤é‡çªç ´ï¼ˆæ•æ‰æ”¾é‡ä¿¡å·ï¼‰
            volume_ma_5 = df['volume'].rolling(5).mean()
            volume_ma_20 = df['volume'].rolling(20).mean()
            new_features['volume_spike'] = df['volume'] / volume_ma_20
            new_features['volume_trend'] = volume_ma_5 / volume_ma_20
            
            # âœ… ä»·æ ¼-æˆäº¤é‡èƒŒç¦»ï¼ˆé‡è¦ä¿¡å·ï¼‰
            price_change_1 = df['close'].pct_change(1)  # å®šä¹‰ä»·æ ¼å˜åŒ–ç‡
            price_change_5 = df['close'].pct_change(5)
            volume_change_5 = df['volume'].pct_change(5)
            new_features['price_volume_divergence'] = price_change_5 * volume_change_5  # åŒå‘ä¸ºæ­£ï¼ŒèƒŒç¦»ä¸ºè´Ÿ
            
            # âœ… æˆäº¤é‡åŠ æƒä»·æ ¼å˜åŒ–ï¼ˆç»“åˆé‡ä»·ï¼‰
            new_features['volume_weighted_price_change'] = price_change_1 * (df['volume'] / volume_ma_20)
            
            # ä¸€æ¬¡æ€§æ·»åŠ æ‰€æœ‰ç‰¹å¾
            df = pd.concat([df, pd.DataFrame(new_features, index=df.index)], axis=1)
            
            return df
            
        except Exception as e:
            logger.error(f"æ·»åŠ æˆäº¤é‡ç‰¹å¾å¤±è´¥: {e}")
            return df
    
    def _add_time_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """æ·»åŠ æ—¶é—´ç‰¹å¾ - ä¼˜åŒ–æ€§èƒ½"""
        try:
            # ç¡®ä¿ timestamp æ˜¯ datetime ç±»å‹
            if 'timestamp' in df.columns:
                if not pd.api.types.is_datetime64_any_dtype(df['timestamp']):
                    df['timestamp'] = pd.to_datetime(df['timestamp'])
                datetime_col = df['timestamp']
            else:
                # timestamp å¯èƒ½åœ¨ index ä¸­
                logger.warning("timestamp åˆ—ä¸å­˜åœ¨ï¼Œè·³è¿‡æ—¶é—´ç‰¹å¾")
                return df
            
            new_features = {}
            
            # åŸºç¡€æ—¶é—´ç‰¹å¾
            hour = datetime_col.dt.hour
            day_of_week = datetime_col.dt.dayofweek
            month = datetime_col.dt.month
            
            new_features['hour'] = hour
            new_features['day_of_week'] = day_of_week
            new_features['day_of_month'] = datetime_col.dt.day
            new_features['month'] = month
            new_features['quarter'] = datetime_col.dt.quarter
            
            # å‘¨æœŸæ€§ç¼–ç 
            new_features['hour_sin'] = np.sin(2 * np.pi * hour / 24)
            new_features['hour_cos'] = np.cos(2 * np.pi * hour / 24)
            new_features['day_sin'] = np.sin(2 * np.pi * day_of_week / 7)
            new_features['day_cos'] = np.cos(2 * np.pi * day_of_week / 7)
            new_features['month_sin'] = np.sin(2 * np.pi * month / 12)
            new_features['month_cos'] = np.cos(2 * np.pi * month / 12)
            
            # äº¤æ˜“æ—¶æ®µ
            new_features['is_asian_session'] = ((hour >= 0) & (hour < 8)).astype(int)
            new_features['is_european_session'] = ((hour >= 8) & (hour < 16)).astype(int)
            new_features['is_american_session'] = ((hour >= 16) & (hour < 24)).astype(int)
            
            # å‘¨æœ«æ ‡è¯†
            new_features['is_weekend'] = (day_of_week >= 5).astype(int)
            
            # ä¸€æ¬¡æ€§æ·»åŠ æ‰€æœ‰ç‰¹å¾
            df = pd.concat([df, pd.DataFrame(new_features, index=df.index)], axis=1)
            
            return df
            
        except Exception as e:
            logger.error(f"æ·»åŠ æ—¶é—´ç‰¹å¾å¤±è´¥: {e}")
            return df
    
    def _add_microstructure_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """æ·»åŠ å¸‚åœºå¾®è§‚ç»“æ„ç‰¹å¾ - å¢å¼ºç‰ˆï¼ˆä¼˜åŒ–ç›®æ ‡ï¼šå‡†ç¡®ç‡+3-5%ï¼‰"""
        try:
            new_features = {}
            
            # 1. ä¹°å–å‹åŠ›æŒ‡æ ‡ï¼ˆåŸºç¡€ï¼‰
            price_range = df['high'] - df['low'] + 1e-10  # é¿å…é™¤é›¶
            new_features['buying_pressure'] = (df['close'] - df['low']) / price_range
            new_features['selling_pressure'] = (df['high'] - df['close']) / price_range
            
            # 2. ğŸ†• ä»·æ ¼ä½ç½®ç™¾åˆ†æ¯”ï¼ˆæ•æ‰æ”¯æ’‘é˜»åŠ›ï¼‰
            for period in [5, 20, 50]:
                rolling_high = df['high'].rolling(period).max()
                rolling_low = df['low'].rolling(period).min()
                price_position = (df['close'] - rolling_low) / (rolling_high - rolling_low + 1e-10)
                new_features[f'price_position_{period}'] = price_position
                # è¶…ä¹°è¶…å–æ ‡è¯†
                new_features[f'overbought_{period}'] = (price_position > 0.8).astype(int)
                new_features[f'oversold_{period}'] = (price_position < 0.2).astype(int)
            
            # 3. ğŸ†• Kçº¿å½¢æ€ç‰¹å¾ï¼ˆå®ä½“å’Œå½±çº¿ï¼‰
            body = abs(df['close'] - df['open'])
            new_features['body_range'] = body / (price_range + 1e-10)
            new_features['upper_shadow'] = (df['high'] - df[['open', 'close']].max(axis=1)) / (price_range + 1e-10)
            new_features['lower_shadow'] = (df[['open', 'close']].min(axis=1) - df['low']) / (price_range + 1e-10)
            
            # 4. ğŸ†• Kçº¿å¼ºåº¦ï¼ˆçœ‹æ¶¨/çœ‹è·ŒåŠ›é‡ï¼‰
            new_features['bullish_candle'] = (df['close'] > df['open']).astype(int)
            new_features['strong_bullish'] = ((df['close'] - df['open']) / (price_range + 1e-10) > 0.6).astype(int)
            new_features['strong_bearish'] = ((df['open'] - df['close']) / (price_range + 1e-10) > 0.6).astype(int)
            new_features['doji'] = (body / (price_range + 1e-10) < 0.1).astype(int)  # åå­—æ˜Ÿ
            
            # 5. ğŸ†• è¿ç»­Kçº¿å½¢æ€ï¼ˆè¶‹åŠ¿å»¶ç»­ï¼‰
            bullish = (df['close'] > df['open']).astype(int)
            new_features['consecutive_bull'] = bullish.groupby((bullish != bullish.shift()).cumsum()).cumsum()
            new_features['consecutive_bear'] = (1 - bullish).groupby((bullish == bullish.shift()).cumsum()).cumsum()
            
            # 6. ä»·æ ¼æ•ˆç‡ï¼ˆå·²æœ‰ï¼Œä¿ç•™ï¼‰
            for period in [5, 10, 20]:
                price_change = df['close'].diff(period)
                sum_abs_changes = df['close'].diff().abs().rolling(period).sum()
                new_features[f'price_efficiency_{period}'] = price_change.abs() / (sum_abs_changes + 1e-10)
            
            # 7. ğŸ†• ä»·æ ¼åŠ é€Ÿåº¦ï¼ˆæ•æ‰æ‹ç‚¹ï¼‰
            returns = df['close'].pct_change()
            new_features['price_acceleration'] = returns.diff()
            new_features['price_jerk'] = returns.diff().diff()  # åŠ åŠ é€Ÿåº¦
            
            # 8. åˆ†å½¢ç»´åº¦ï¼ˆå·²æœ‰ï¼Œä¿ç•™ï¼‰
            for period in [10, 20]:
                new_features[f'fractal_dimension_{period}'] = self._calculate_fractal_dimension(df['close'], period)
            
            # 9. HurstæŒ‡æ•°ï¼ˆå·²æœ‰ï¼Œä¿ç•™ï¼‰
            for period in [20, 50]:
                new_features[f'hurst_exponent_{period}'] = self._calculate_hurst_exponent(df['close'], period)
            
            # 10. ğŸ†• çœŸå®æ³¢åŠ¨èŒƒå›´å æ¯”ï¼ˆæ•æ‰å¼‚å¸¸æ³¢åŠ¨ï¼‰
            atr_14 = ta.volatility.AverageTrueRange(df['high'], df['low'], df['close'], window=14).average_true_range()
            new_features['range_to_atr'] = price_range / (atr_14 + 1e-10)
            new_features['body_to_atr'] = body / (atr_14 + 1e-10)
            
            # ä¸€æ¬¡æ€§æ·»åŠ æ‰€æœ‰ç‰¹å¾
            df = pd.concat([df, pd.DataFrame(new_features, index=df.index)], axis=1)
            
            logger.info(f"âœ… å¸‚åœºå¾®è§‚ç»“æ„ç‰¹å¾å·²å¢å¼ºï¼šæ–°å¢ {len(new_features)} ä¸ªç‰¹å¾")  # æ”¹ä¸ºINFOçº§åˆ«
            
            return df
            
        except Exception as e:
            logger.error(f"âŒ æ·»åŠ å¸‚åœºå¾®è§‚ç»“æ„ç‰¹å¾å¤±è´¥: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return df
    
    def _add_volatility_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """æ·»åŠ æ³¢åŠ¨ç‡ç‰¹å¾ - ä¼˜åŒ–æ€§èƒ½"""
        try:
            new_features = {}
            
            # å†å²æ³¢åŠ¨ç‡
            returns = df['close'].pct_change()
            for period in [5, 10, 20, 50]:
                new_features[f'volatility_{period}'] = returns.rolling(period).std() * np.sqrt(252)
            
            # ATR (Average True Range)
            for period in [14, 20]:
                atr = ta.volatility.AverageTrueRange(df['high'], df['low'], df['close'], window=period).average_true_range()
                new_features[f'atr_{period}'] = atr
                new_features[f'atr_ratio_{period}'] = atr / df['close']
            
            # Keltner Channels
            kc = ta.volatility.KeltnerChannel(df['high'], df['low'], df['close'])
            kc_upper = kc.keltner_channel_hband()
            kc_lower = kc.keltner_channel_lband()
            kc_middle = kc.keltner_channel_mband()
            
            new_features['kc_upper'] = kc_upper
            new_features['kc_lower'] = kc_lower
            new_features['kc_middle'] = kc_middle
            new_features['kc_position'] = (df['close'] - kc_lower) / (kc_upper - kc_lower)
            
            # Donchian Channels
            dc = ta.volatility.DonchianChannel(df['high'], df['low'], df['close'])
            new_features['dc_upper'] = dc.donchian_channel_hband()
            new_features['dc_lower'] = dc.donchian_channel_lband()
            new_features['dc_middle'] = dc.donchian_channel_mband()
            
            # ä¸€æ¬¡æ€§æ·»åŠ æ‰€æœ‰ç‰¹å¾
            df = pd.concat([df, pd.DataFrame(new_features, index=df.index)], axis=1)
            
            return df
            
        except Exception as e:
            logger.error(f"æ·»åŠ æ³¢åŠ¨ç‡ç‰¹å¾å¤±è´¥: {e}")
            return df
    
    def _add_momentum_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """æ·»åŠ åŠ¨é‡ç‰¹å¾ - ä¼˜åŒ–æ€§èƒ½"""
        try:
            new_features = {}
            
            # ROC (Rate of Change)
            for period in [5, 10, 20]:
                new_features[f'roc_{period}'] = ta.momentum.ROCIndicator(df['close'], window=period).roc()
            
            # Momentum
            for period in [5, 10, 20]:
                new_features[f'momentum_{period}'] = df['close'] / df['close'].shift(period) - 1
            
            # TSI (True Strength Index)
            new_features['tsi'] = ta.momentum.TSIIndicator(df['close']).tsi()
            
            # Ultimate Oscillator
            new_features['uo'] = ta.momentum.UltimateOscillator(df['high'], df['low'], df['close']).ultimate_oscillator()
            
            # Awesome Oscillator
            new_features['ao'] = ta.momentum.AwesomeOscillatorIndicator(df['high'], df['low']).awesome_oscillator()
            
            # âœ… è¶‹åŠ¿å¼ºåº¦æŒ‡æ ‡ï¼ˆADXï¼‰
            adx = ta.trend.ADXIndicator(df['high'], df['low'], df['close'])
            new_features['adx'] = adx.adx()
            new_features['adx_pos'] = adx.adx_pos()
            new_features['adx_neg'] = adx.adx_neg()
            
            # âœ… åŠ¨é‡åŠ é€Ÿåº¦ï¼ˆæ•æ‰åŠ¨é‡å˜åŒ–ï¼‰
            rsi_14 = ta.momentum.RSIIndicator(df['close'], window=14).rsi()
            new_features['rsi_acceleration'] = rsi_14 - rsi_14.shift(1)
            new_features['rsi_velocity'] = rsi_14.diff()
            
            # âœ… å¤šå‘¨æœŸåŠ¨é‡ä¸€è‡´æ€§ï¼ˆè¶‹åŠ¿ç¡®è®¤ï¼‰
            roc_5 = ta.momentum.ROCIndicator(df['close'], window=5).roc()
            roc_10 = ta.momentum.ROCIndicator(df['close'], window=10).roc()
            roc_20 = ta.momentum.ROCIndicator(df['close'], window=20).roc()
            # å¦‚æœå¤šä¸ªå‘¨æœŸéƒ½æ˜¯æ­£/è´Ÿï¼Œåˆ™è¶‹åŠ¿æ›´å¯é 
            new_features['momentum_alignment'] = ((roc_5 > 0).astype(int) + 
                                                  (roc_10 > 0).astype(int) + 
                                                  (roc_20 > 0).astype(int)) - 1.5  # -1.5 to 1.5
            
            # ä¸€æ¬¡æ€§æ·»åŠ æ‰€æœ‰ç‰¹å¾
            df = pd.concat([df, pd.DataFrame(new_features, index=df.index)], axis=1)
            
            return df
            
        except Exception as e:
            logger.error(f"æ·»åŠ åŠ¨é‡ç‰¹å¾å¤±è´¥: {e}")
            return df
    
    def _add_statistical_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """æ·»åŠ ç»Ÿè®¡ç‰¹å¾ - ä¼˜åŒ–æ€§èƒ½ï¼Œé¿å…DataFrameç¢ç‰‡åŒ–"""
        try:
            new_features = {}
            
            # æ»šåŠ¨ç»Ÿè®¡
            for period in [5, 10, 20, 50]:
                rolling = df['close'].rolling(period)
                new_features[f'close_mean_{period}'] = rolling.mean()
                new_features[f'close_std_{period}'] = rolling.std()
                new_features[f'close_skew_{period}'] = rolling.skew()
                new_features[f'close_kurt_{period}'] = rolling.kurt()
                
                # Z-score
                mean_col = new_features[f'close_mean_{period}']
                std_col = new_features[f'close_std_{period}']
                new_features[f'close_zscore_{period}'] = (df['close'] - mean_col) / std_col
            
            # åˆ†ä½æ•°
            for period in [20, 50]:
                rolling = df['close'].rolling(period)
                new_features[f'close_quantile_25_{period}'] = rolling.quantile(0.25)
                new_features[f'close_quantile_75_{period}'] = rolling.quantile(0.75)
                new_features[f'close_iqr_{period}'] = (
                    new_features[f'close_quantile_75_{period}'] - 
                    new_features[f'close_quantile_25_{period}']
                )
            
            # ä¸€æ¬¡æ€§æ·»åŠ æ‰€æœ‰ç‰¹å¾
            df = pd.concat([df, pd.DataFrame(new_features, index=df.index)], axis=1)
            
            return df
            
        except Exception as e:
            logger.error(f"æ·»åŠ ç»Ÿè®¡ç‰¹å¾å¤±è´¥: {e}")
            return df
    
    def _calculate_fractal_dimension(self, series: pd.Series, period: int) -> pd.Series:
        """è®¡ç®—åˆ†å½¢ç»´åº¦"""
        try:
            def fractal_dim(data):
                try:
                    data = np.array(data)
                    if len(data) < 10:
                        return np.nan
                    
                    # Higuchiæ–¹æ³•è®¡ç®—åˆ†å½¢ç»´åº¦
                    N = len(data)
                    L = []
                    x = []
                    
                    for k in range(1, min(N//2, 10)):
                        Lk = 0
                        for m in range(k):
                            Lmk = 0
                            for i in range(1, int((N-m)/k)):
                                Lmk += abs(data[m+i*k] - data[m+(i-1)*k])
                            if ((N-m)/k) * k > 0:
                                Lmk = Lmk * (N-1) / (((N-m)/k) * k)
                            Lk += Lmk
                        
                        if k > 0:
                            L.append(Lk/k)
                            x.append(1.0/k)
                    
                    if len(L) < 2:
                        return np.nan
                    
                    # çº¿æ€§å›å½’è®¡ç®—æ–œç‡
                    x = np.log(x)
                    y = np.log(L)
                    coeffs = np.polyfit(x, y, 1)
                    return coeffs[0]
                except:
                    return np.nan
            
            return series.rolling(period).apply(fractal_dim, raw=False)
            
        except Exception as e:
            logger.error(f"è®¡ç®—åˆ†å½¢ç»´åº¦å¤±è´¥: {e}")
            return pd.Series(np.nan, index=series.index)
    
    def _calculate_hurst_exponent(self, series: pd.Series, period: int) -> pd.Series:
        """è®¡ç®—HurstæŒ‡æ•°"""
        try:
            def hurst_exp(data):
                if len(data) < 10:
                    return np.nan
                
                # R/Såˆ†æè®¡ç®—HurstæŒ‡æ•°
                data = np.array(data)
                N = len(data)
                
                # è®¡ç®—ç´¯ç§¯åå·®
                mean_data = np.mean(data)
                cumulative_deviate = np.cumsum(data - mean_data)
                
                # è®¡ç®—èŒƒå›´
                R = np.max(cumulative_deviate) - np.min(cumulative_deviate)
                
                # è®¡ç®—æ ‡å‡†å·®
                S = np.std(data)
                
                if S == 0:
                    return np.nan
                
                # R/Sæ¯”ç‡
                rs = R / S
                
                if rs <= 0:
                    return np.nan
                
                # HurstæŒ‡æ•°
                return np.log(rs) / np.log(N)
            
            return series.rolling(period).apply(hurst_exp, raw=False)
            
        except Exception as e:
            logger.error(f"è®¡ç®—HurstæŒ‡æ•°å¤±è´¥: {e}")
            return pd.Series(np.nan, index=series.index)
    
    def _add_sentiment_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """æ·»åŠ å¸‚åœºæƒ…ç»ªç‰¹å¾ï¼ˆä¼˜åŒ–ç›®æ ‡ï¼šå‡†ç¡®ç‡+2-3%ï¼‰"""
        try:
            new_features = {}
            
            # 1. ææ…ŒæŒ‡æ•°ï¼ˆåŸºäºä»·æ ¼æ³¢åŠ¨ï¼‰
            returns = df['close'].pct_change()
            short_vol = returns.rolling(20).std()
            long_vol = returns.rolling(100).std()
            new_features['fear_index'] = short_vol / (long_vol + 1e-10)
            
            # 2. ğŸ†• è¿ç»­æ¶¨è·Œå¤©æ•°ï¼ˆæ•æ‰è¶‹åŠ¿ç–²åŠ³ï¼‰
            up_days = (returns > 0).astype(int)
            down_days = (returns < 0).astype(int)
            new_features['consecutive_up'] = up_days.groupby((up_days != up_days.shift()).cumsum()).cumsum()
            new_features['consecutive_down'] = down_days.groupby((down_days != down_days.shift()).cumsum()).cumsum()
            
            # 3. ğŸ†• RSIè¡ç”Ÿæƒ…ç»ªæŒ‡æ ‡
            if 'rsi_14' in df.columns:
                rsi = df['rsi_14']
                new_features['extreme_overbought'] = (rsi > 70).astype(int)
                new_features['extreme_oversold'] = (rsi < 30).astype(int)
                new_features['rsi_momentum'] = rsi - rsi.shift(5)  # RSIåŠ¨é‡
                new_features['rsi_volatility'] = rsi.rolling(10).std()  # RSIæ³¢åŠ¨ç‡
            
            # 4. ğŸ†• ä»·æ ¼åŠ é€Ÿåº¦ï¼ˆæƒ…ç»ªè½¬å˜ï¼‰
            price_change = df['close'].pct_change()
            new_features['price_acceleration'] = price_change.diff()
            new_features['acceleration_magnitude'] = new_features['price_acceleration'].abs()
            
            # 5. ğŸ†• æˆäº¤é‡æƒ…ç»ªï¼ˆåŸºäºæ”¾é‡/ç¼©é‡ï¼‰
            if 'volume' in df.columns:
                volume_ma = df['volume'].rolling(20).mean()
                new_features['volume_surge'] = (df['volume'] > volume_ma * 2).astype(int)  # æ”¾é‡
                new_features['volume_dry'] = (df['volume'] < volume_ma * 0.5).astype(int)  # ç¼©é‡
                
                # ä»·é‡èƒŒç¦»ï¼ˆä»·æ¶¨é‡è·Œ = çœ‹è·Œä¿¡å·ï¼‰
                price_trend = (price_change.rolling(5).mean() > 0).astype(int)
                volume_trend = (df['volume'].pct_change().rolling(5).mean() > 0).astype(int)
                new_features['price_volume_divergence'] = (price_trend != volume_trend).astype(int)
            
            # 6. ğŸ†• å¸‚åœºæ³¢åŠ¨æƒ…ç»ª
            returns_abs = returns.abs()
            new_features['volatility_regime'] = returns_abs.rolling(20).mean() / returns_abs.rolling(100).mean()
            
            # 7. ğŸ†• è¶‹åŠ¿ä¸€è‡´æ€§ï¼ˆå¤šä¸ªå‡çº¿æ–¹å‘ä¸€è‡´åº¦ï¼‰
            if 'sma_5' in df.columns and 'sma_20' in df.columns and 'sma_50' in df.columns:
                sma5_up = (df['sma_5'] > df['sma_5'].shift(1)).astype(int)
                sma20_up = (df['sma_20'] > df['sma_20'].shift(1)).astype(int)
                sma50_up = (df['sma_50'] > df['sma_50'].shift(1)).astype(int)
                new_features['trend_alignment'] = (sma5_up + sma20_up + sma50_up) / 3  # 0-1ä¹‹é—´
            
            # 8. ğŸ†• å¸‚åœºæƒ…ç»ªç»¼åˆæŒ‡æ•°
            # ç»„åˆå¤šä¸ªæƒ…ç»ªæŒ‡æ ‡
            sentiment_score = 0
            if 'rsi_14' in df.columns:
                sentiment_score += ((df['rsi_14'] - 50) / 50)  # RSIè´¡çŒ®
            
            if 'macd_histogram' in df.columns:
                macd_norm = df['macd_histogram'] / (df['close'] * 0.01 + 1e-10)  # å½’ä¸€åŒ–
                sentiment_score += np.clip(macd_norm, -1, 1)  # MACDè´¡çŒ®
            
            sentiment_score += price_change.rolling(10).mean() * 100  # çŸ­æœŸåŠ¨é‡è´¡çŒ®
            new_features['sentiment_composite'] = sentiment_score / 3  # å¹³å‡
            
            # ä¸€æ¬¡æ€§æ·»åŠ æ‰€æœ‰ç‰¹å¾
            df = pd.concat([df, pd.DataFrame(new_features, index=df.index)], axis=1)
            
            logger.info(f"âœ… å¸‚åœºæƒ…ç»ªç‰¹å¾å·²æ·»åŠ ï¼šæ–°å¢ {len(new_features)} ä¸ªç‰¹å¾")  # æ”¹ä¸ºINFOçº§åˆ«
            
            return df
            
        except Exception as e:
            logger.error(f"âŒ æ·»åŠ å¸‚åœºæƒ…ç»ªç‰¹å¾å¤±è´¥: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return df
    
    def get_feature_importance(self, df: pd.DataFrame) -> Dict[str, float]:
        """è·å–ç‰¹å¾é‡è¦æ€§ï¼ˆåŸºäºæ–¹å·®ï¼‰"""
        try:
            # æ’é™¤éç‰¹å¾åˆ—
            exclude_cols = ['timestamp', 'datetime', 'open', 'high', 'low', 'close', 'volume', 'quote_volume']
            feature_cols = [col for col in df.columns if col not in exclude_cols]
            
            # è®¡ç®—ç‰¹å¾æ–¹å·®
            feature_variance = {}
            for col in feature_cols:
                # âœ… ä½¿ç”¨pandasç±»å‹æ£€æŸ¥
                if pd.api.types.is_numeric_dtype(df[col]):
                    variance = df[col].var()
                    feature_variance[col] = variance if not np.isnan(variance) else 0
            
            # å½’ä¸€åŒ–
            total_variance = sum(feature_variance.values())
            if total_variance > 0:
                feature_importance = {k: v/total_variance for k, v in feature_variance.items()}
            else:
                feature_importance = feature_variance
            
            return dict(sorted(feature_importance.items(), key=lambda x: x[1], reverse=True))
            
        except Exception as e:
            logger.error(f"è®¡ç®—ç‰¹å¾é‡è¦æ€§å¤±è´¥: {e}")
            return {}
    
    def select_features(self, df: pd.DataFrame, top_n: int = 50) -> List[str]:
        """é€‰æ‹©é‡è¦ç‰¹å¾"""
        try:
            feature_importance = self.get_feature_importance(df)
            
            # é€‰æ‹©å‰Nä¸ªé‡è¦ç‰¹å¾
            selected_features = list(feature_importance.keys())[:top_n]
            
            logger.debug(f"é€‰æ‹©äº†{len(selected_features)}ä¸ªé‡è¦ç‰¹å¾")
            return selected_features
            
        except Exception as e:
            logger.error(f"ç‰¹å¾é€‰æ‹©å¤±è´¥: {e}")
            return []

# å…¨å±€ç‰¹å¾å·¥ç¨‹å™¨å®ä¾‹
feature_engineer = FeatureEngineer()