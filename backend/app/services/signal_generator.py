"""
äº¤æ˜“ä¿¡å·ç”Ÿæˆå™¨

èŒè´£ï¼š
1. ğŸ¯ å¤šæ—¶é—´æ¡†æ¶ä¿¡å·ç”Ÿæˆï¼ˆ15m/2h/4hï¼‰
2. ğŸ”„ ä¿¡å·ç¼“å­˜ä¸åˆæˆ
3. ğŸ”’ é¢„çƒ­ä¿¡å·ä¿æŠ¤ï¼ˆå‰5ä¸ªä¿¡å·ä»…è®°å½•ï¼‰
4. ğŸ“Š WebSocketå®æ—¶æ•°æ®å¤„ç†

æ³¨æ„ï¼š
- ä»“ä½è®¡ç®—å·²å§”æ‰˜ç»™ position_managerï¼ˆé¿å…é‡å¤ä»£ç ï¼‰
- ä¿¡å·ç”ŸæˆåŸºäºç¼“å­˜çš„é¢„æµ‹ç»“æœï¼Œé¿å…é‡å¤é¢„æµ‹
"""
import asyncio
import logging
from typing import Dict, List, Any, Optional
from datetime import datetime, timedelta
from dataclasses import dataclass
import pandas as pd
import numpy as np

from app.core.config import settings
from app.core.database import postgresql_manager
from app.core.cache import cache_manager
from app.services.ml_service import MLService
from app.services.data_service import DataService, KlineData

logger = logging.getLogger(__name__)

@dataclass
class TradingSignal:
    """äº¤æ˜“ä¿¡å·æ•°æ®ç±»"""
    timestamp: datetime
    symbol: str
    signal_type: str  # LONG, SHORT, CLOSE
    confidence: float
    entry_price: float
    stop_loss: float
    take_profit: float
    position_size: float
    timeframe: str
    model_version: str
    metadata: Dict[str, Any]

class SignalGenerator:
    """äº¤æ˜“ä¿¡å·ç”Ÿæˆå™¨"""
    
    def __init__(self, ml_service: MLService, data_service: DataService):
        self.ml_service = ml_service
        self.data_service = data_service
        self.is_running = False
        self.signal_callbacks: List[callable] = []
        self.last_signals: Dict[str, TradingSignal] = {}
        
        # ä¿¡å·ç”Ÿæˆå‚æ•°
        self.confidence_threshold = settings.CONFIDENCE_THRESHOLD
        self.min_signal_interval = 900  # çŸ­çº¿ç­–ç•¥ï¼š3åˆ†é’Ÿæœ€å°ä¿¡å·é—´éš”ï¼ˆæ›´é¢‘ç¹ï¼‰
        
        # æ­¢æŸæ­¢ç›ˆå‚æ•°ï¼ˆä¸­é¢‘äº¤æ˜“ç­–ç•¥ï¼šæ›´ç´§çš„æ­¢æŸï¼Œä¿æŒæ­¢ç›ˆï¼‰
        self.stop_loss_pct = 0.015  # 1.5%æ­¢æŸï¼ˆä¸­é¢‘å¿«é€Ÿæ­¢æŸï¼Œå‡å°‘é£é™©ï¼‰
        self.take_profit_pct = 0.04   # 4%æ­¢ç›ˆï¼ˆè®©åˆ©æ¶¦å¥”è·‘ï¼‰
        
        # WebSocket æ•°æ®ç¼“å†²åŒºï¼ˆå­˜å‚¨å®æ—¶Kçº¿æ•°æ®ï¼‰
        self.kline_buffers: Dict[str, pd.DataFrame] = {}  # {timeframe: DataFrame}
        
        # ğŸ”¥ ä¿¡å·ç¼“å­˜ï¼šæ¯ä¸ªæ—¶é—´æ¡†æ¶ç‹¬ç«‹ç¼“å­˜é¢„æµ‹ç»“æœ
        self.cached_predictions: Dict[str, Dict[str, Any]] = {}  # {timeframe: prediction}
        
        # ğŸ”’ å®‰å…¨ä¿æŠ¤ï¼šå‰5ä¸ªä¿¡å·ä»…è®°å½•ï¼Œä¸äº¤æ˜“ï¼ˆä»…é¦–æ¬¡éƒ¨ç½²æ—¶å¯ç”¨ï¼‰
        self.warmup_signals = 5  # é¢„çƒ­ä¿¡å·æ•°é‡
        self.signal_counter = 0  # ä¿¡å·è®¡æ•°å™¨ï¼ˆå¯åŠ¨æ—¶ä¼šä»RedisåŠ è½½ï¼‰
        
        # ç¼“å†²åŒºè®¾è®¡ï¼šæŒ‰å¤©æ•°ç»Ÿä¸€ï¼ˆæ‰€æœ‰æ—¶é—´æ¡†æ¶è¦†ç›–ç›¸åŒå¤©æ•°ï¼‰
        self.buffer_days = 60  # ç»Ÿä¸€60å¤©è¦†ç›–èŒƒå›´ï¼ˆè®­ç»ƒ180å¤©çš„1/3ï¼‰
        
        # æ ¹æ®æ—¶é—´æ¡†æ¶è®¡ç®—å®é™…éœ€è¦çš„Kçº¿æ•°é‡
        self.buffer_sizes = {
            '15m': int(self.buffer_days * 24 * 4),    # 60å¤© = 5760æ¡
            '1h':  int(self.buffer_days * 24),        # 60å¤© = 1440æ¡
            '2h':  int(self.buffer_days * 12),        # 60å¤© = 720æ¡
            '4h':  int(self.buffer_days * 6),         # 60å¤© = 360æ¡
            '1d':  int(self.buffer_days * 1),         # 60å¤© = 60æ¡
        }
        
        # æ³¨å†Œæ•°æ®å›è°ƒ
        self.data_service.add_data_callback(self._on_new_data)
        
        # æ³¨å†ŒWebSocketé‡è¿å›è°ƒ
        self.data_service.add_reconnect_callback(self._on_websocket_reconnect)
    
    async def start(self):
        """å¯åŠ¨ä¿¡å·ç”Ÿæˆå™¨"""
        try:
            logger.info("å¯åŠ¨äº¤æ˜“ä¿¡å·ç”Ÿæˆå™¨...")
            
            # åˆå§‹åŒ–WebSocketæ•°æ®ç¼“å†²åŒº
            await self._initialize_kline_buffers()
            
            self.is_running = True
            
            # ğŸ”’ ä»RedisåŠ è½½é¢„çƒ­çŠ¶æ€ï¼ˆæŒä¹…åŒ–ï¼Œé¿å…é‡å¯åé‡æ–°é¢„çƒ­ï¼‰
            await self._load_warmup_state()
            
            # ğŸ”’ å¯åŠ¨å®‰å…¨ä¿æŠ¤æç¤º
            if self.signal_counter < self.warmup_signals:
                logger.warning(f"ğŸ”’ å®‰å…¨ä¿æŠ¤å·²å¯ç”¨ï¼šå‰ {self.warmup_signals} ä¸ªä¿¡å·ä»…è®°å½•ï¼Œä¸æ‰§è¡Œäº¤æ˜“")
                logger.info(f"   å½“å‰å·²å®Œæˆ: {self.signal_counter}/{self.warmup_signals} ä¸ªä¿¡å·")
                logger.info(f"   ç›®çš„ï¼šè§‚å¯Ÿæ¨¡å‹ç¨³å®šæ€§ï¼Œç¡®ä¿èµ„é‡‘å®‰å…¨")
            else:
                logger.info(f"âœ… é¢„çƒ­å·²å®Œæˆï¼ˆ{self.signal_counter}ä¸ªä¿¡å·ï¼‰ï¼Œç³»ç»Ÿå¤„äºæ­£å¸¸äº¤æ˜“æ¨¡å¼")
            
            # ğŸ”¥ é¦–æ¬¡å¯åŠ¨ï¼šç«‹å³å¯¹æ‰€æœ‰æ—¶é—´æ¡†æ¶è¿›è¡Œé¢„æµ‹ï¼Œå¡«å……ä¿¡å·ç¼“å­˜
            await self._initial_predictions()
            
            logger.info("âœ… äº¤æ˜“ä¿¡å·ç”Ÿæˆå™¨å¯åŠ¨å®Œæˆ")
        except Exception as e:
            logger.error(f"å¯åŠ¨ä¿¡å·ç”Ÿæˆå™¨å¤±è´¥: {e}")
            raise
    
    async def _initialize_kline_buffers(self):
        """åˆå§‹åŒ–Kçº¿æ•°æ®ç¼“å†²åŒº - ä»APIè·å–åˆå§‹æ•°æ®"""
        try:
            from app.services.binance_client import binance_client
            
            symbol = settings.SYMBOL
            logger.info(f"åˆå§‹åŒ–WebSocketæ•°æ®ç¼“å†²åŒº: {symbol}")
            
            for timeframe in settings.TIMEFRAMES:
                try:
                    # è·å–è¯¥æ—¶é—´æ¡†æ¶éœ€è¦çš„Kçº¿æ•°é‡
                    buffer_size = self.buffer_sizes.get(timeframe, 500)
                    
                    # Binance API limit æœ€å¤§1500æ¡ï¼Œéœ€è¦åˆ†æ‰¹è·å–
                    max_limit = 1500
                    all_klines = []
                    
                    if buffer_size <= max_limit:
                        # ä¸€æ¬¡æ€§è·å–
                        klines = binance_client.get_klines(
                            symbol=symbol,
                            interval=timeframe,
                            limit=buffer_size
                        )
                        if klines:
                            all_klines = klines
                    else:
                        # åˆ†æ‰¹è·å–
                        logger.info(f"è·å– {timeframe} åˆå§‹æ•°æ®ï¼ˆ{buffer_size}æ¡ï¼Œè¦†ç›–{self.buffer_days}å¤©ï¼Œéœ€åˆ†æ‰¹è·å–ï¼‰...")
                        batches = (buffer_size + max_limit - 1) // max_limit
                        
                        for batch in range(batches):
                            batch_limit = min(max_limit, buffer_size - len(all_klines))
                            
                            # è®¡ç®— end_timeï¼ˆå€’æ¨è·å–ï¼‰
                            if all_klines:
                                # ä½¿ç”¨ä¸Šä¸€æ‰¹æœ€æ—©çš„æ—¶é—´æˆ³
                                end_time = all_klines[0]['timestamp'] - 1
                            else:
                                # ç¬¬ä¸€æ‰¹ä½¿ç”¨å½“å‰æ—¶é—´
                                from datetime import datetime
                                end_time = int(datetime.now().timestamp() * 1000)
                            
                            klines = binance_client.get_klines(
                                symbol=symbol,
                                interval=timeframe,
                                limit=batch_limit,
                                end_time=end_time
                            )
                            
                            if klines:
                                # æ’å…¥åˆ°å¼€å¤´ï¼ˆå› ä¸ºæ˜¯å€’åºè·å–ï¼‰
                                all_klines = klines + all_klines
                            else:
                                logger.warning(f"  æ‰¹æ¬¡ {batch + 1} æœªè·å–åˆ°æ•°æ®")
                                break
                            
                            # APIé™æµ
                            await asyncio.sleep(0.2)
                    
                    if all_klines:
                        # åˆå§‹åŒ–ç¼“å†²åŒº
                        df = pd.DataFrame(all_klines)
                        
                        # âœ… timestamp ä¿æŒä¸ºæ•´æ•°ï¼ˆæ¯«ç§’æ—¶é—´æˆ³ï¼‰ï¼Œä¸è½¬æ¢
                        # ä¸ WebSocket æ–°æ•°æ®ä¿æŒä¸€è‡´ï¼ˆKlineData.open_time ç°åœ¨æ˜¯ int ç±»å‹ï¼‰
                        
                        self.kline_buffers[timeframe] = df
                        days_covered = len(all_klines) / self.buffer_sizes.get(timeframe, 1) * self.buffer_days
                        logger.info(f"âœ“ {timeframe} ç¼“å†²åŒºåˆå§‹åŒ–å®Œæˆ: {len(all_klines)}æ¡æ•°æ®ï¼ˆçº¦{days_covered:.1f}å¤©ï¼‰")
                    else:
                        logger.warning(f"âš ï¸ {timeframe} åˆå§‹æ•°æ®è·å–å¤±è´¥")
                    
                    # APIé™æµå»¶è¿Ÿ
                    await asyncio.sleep(0.1)
                    
                except Exception as e:
                    logger.error(f"åˆå§‹åŒ– {timeframe} ç¼“å†²åŒºå¤±è´¥: {e}")
            
            logger.info(f"WebSocketæ•°æ®ç¼“å†²åŒºåˆå§‹åŒ–å®Œæˆ: {len(self.kline_buffers)}ä¸ªæ—¶é—´æ¡†æ¶")
            
        except Exception as e:
            logger.error(f"åˆå§‹åŒ–Kçº¿ç¼“å†²åŒºå¤±è´¥: {e}")
    
    async def stop(self):
        """åœæ­¢ä¿¡å·ç”Ÿæˆå™¨"""
        try:
            logger.info("åœæ­¢äº¤æ˜“ä¿¡å·ç”Ÿæˆå™¨...")
            self.is_running = False
            logger.info("äº¤æ˜“ä¿¡å·ç”Ÿæˆå™¨å·²åœæ­¢")
        except Exception as e:
            logger.error(f"åœæ­¢ä¿¡å·ç”Ÿæˆå™¨å¤±è´¥: {e}")
    
    async def _on_websocket_reconnect(self):
        """WebSocketé‡è¿å›è°ƒ - é‡ç½®ç¼“å†²åŒº"""
        try:
            logger.warning("âš ï¸ WebSocketå·²é‡è¿ï¼Œå¼€å§‹é‡ç½®ç¼“å†²åŒº...")
            logger.info("ğŸ”„ åŸå› ï¼šé‡è¿æœŸé—´æ•°æ®å¯èƒ½æœ‰ç¼ºå£ï¼Œé‡æ–°è·å–å®Œæ•´æ•°æ®ä»¥ç¡®ä¿è´¨é‡")
            
            # æ¸…ç©ºç°æœ‰ç¼“å†²åŒº
            self.kline_buffers.clear()
            logger.info("âœ“ å·²æ¸…ç©ºæ—§ç¼“å†²åŒºæ•°æ®")
            
            # é‡æ–°åˆå§‹åŒ–ç¼“å†²åŒºï¼ˆä»APIè·å–æœ€æ–°çš„å®Œæ•´æ•°æ®ï¼‰
            await self._initialize_kline_buffers()
            
            logger.info("âœ… ç¼“å†²åŒºé‡ç½®å®Œæˆï¼Œæ•°æ®è´¨é‡å·²æ¢å¤")
            
        except Exception as e:
            logger.error(f"WebSocketé‡è¿å›è°ƒå¤±è´¥: {e}")
    
    async def _on_new_data(self, kline_data: KlineData):
        """å¤„ç†æ–°çš„Kçº¿æ•°æ® - æ›´æ–°ç¼“å†²åŒºå¹¶é¢„æµ‹è¯¥æ—¶é—´æ¡†æ¶"""
        try:
            logger.debug(f"ğŸ“Š ä¿¡å·ç”Ÿæˆå™¨æ”¶åˆ°æ–°Kçº¿: {kline_data.symbol} {kline_data.interval}")
            
            if not self.is_running:
                logger.warning("âš ï¸ ä¿¡å·ç”Ÿæˆå™¨æœªè¿è¡Œï¼Œè·³è¿‡å¤„ç†")
                return
            
            # 1. å°†WebSocketæ•°æ®æ·»åŠ åˆ°ç¼“å†²åŒº
            await self._update_kline_buffer(kline_data)
            
            # 2. ğŸ”¥ å¯¹è¯¥æ—¶é—´æ¡†æ¶è¿›è¡Œé¢„æµ‹å¹¶ç¼“å­˜ï¼ˆæ¯ä¸ªæ—¶é—´æ¡†æ¶ç‹¬ç«‹é¢„æµ‹ï¼‰
            timeframe = kline_data.interval
            
            prediction = await self._predict_single_timeframe(kline_data.symbol, timeframe)
            
            if prediction:
                # ç¼“å­˜è¯¥æ—¶é—´æ¡†æ¶çš„é¢„æµ‹ç»“æœ
                self.cached_predictions[timeframe] = prediction
                logger.debug(f"âœ… {timeframe} é¢„æµ‹å®Œæˆå¹¶ç¼“å­˜: {prediction.get('signal_type')} (ç½®ä¿¡åº¦={prediction.get('confidence'):.4f})")
            else:
                logger.warning(f"âŒ {timeframe} é¢„æµ‹å¤±è´¥")
                return
            
            # 3. ğŸ”¥ åªæœ‰15mä¿¡å·æ›´æ–°æ—¶æ‰è§¦å‘åˆæˆï¼ˆ15mä½œä¸ºä¸»æ—¶é—´æ¡†æ¶ï¼‰
            if timeframe != settings.TIMEFRAMES[0]:
                logger.debug(f"â­ï¸ {timeframe} ä¿¡å·å·²ç¼“å­˜ï¼Œç­‰å¾…15mè§¦å‘åˆæˆ")
                return
            
            logger.debug(f"ğŸ”„ 15mä¿¡å·æ›´æ–°ï¼Œè§¦å‘åˆæˆ (å½“å‰å·²ç¼“å­˜: {list(self.cached_predictions.keys())})")
            
            # ğŸ”¥ é¢„çƒ­è®¡æ•°åº”è¯¥åœ¨å°è¯•åˆæˆå‰å°±+1ï¼ˆä¸ç®¡æ˜¯å¦HOLDï¼‰
            self.signal_counter += 1
            # ğŸ’¾ ä¿å­˜é¢„çƒ­çŠ¶æ€åˆ°Redisï¼ˆæŒä¹…åŒ–ï¼‰
            await self._save_warmup_state()
            
            signal = await self._try_synthesize_cached_signals(kline_data.symbol)
            
            if signal:
                from app.utils.helpers import format_signal_type
                logger.info(f"âœ… ç”Ÿæˆåˆæˆä¿¡å·: {format_signal_type(signal.signal_type)} ç½®ä¿¡åº¦={signal.confidence:.4f}")
                await self._process_signal(signal)
            else:
                # HOLDæˆ–ç½®ä¿¡åº¦ä¸è¶³
                logger.debug(f"â¸ï¸ æœªç”Ÿæˆäº¤æ˜“ä¿¡å·ï¼ˆå¯èƒ½æ˜¯HOLDæˆ–ç½®ä¿¡åº¦ä¸è¶³ï¼‰")
                
                # å¦‚æœåœ¨é¢„çƒ­æœŸï¼Œä¹Ÿåº”è¯¥è®°å½•
                if self.signal_counter <= self.warmup_signals:
                    logger.info(f"â„¹ï¸ é¢„çƒ­æœŸè§‚æœ› [{self.signal_counter}/{self.warmup_signals}]ï¼ˆä¿¡å·ä¸ºHOLDæˆ–ä½ç½®ä¿¡åº¦ï¼‰")
                    logger.info(f"   å‰©ä½™{self.warmup_signals - self.signal_counter}ä¸ªé¢„çƒ­ä¿¡å·")
                
        except Exception as e:
            logger.error(f"âŒ å¤„ç†æ–°æ•°æ®å¤±è´¥: {e}", exc_info=True)
    
    async def _update_kline_buffer(self, kline_data: KlineData):
        """æ›´æ–°Kçº¿æ•°æ®ç¼“å†²åŒºï¼ˆåŒæ—¶å†™å…¥æ•°æ®åº“æŒä¹…åŒ–ï¼‰"""
        try:
            timeframe = kline_data.interval
            
            # è½¬æ¢ä¸ºDataFrameè¡Œ
            new_row = pd.DataFrame([{
                'timestamp': kline_data.open_time,
                'open': kline_data.open_price,
                'high': kline_data.high_price,
                'low': kline_data.low_price,
                'close': kline_data.close_price,
                'volume': kline_data.volume,
                'quote_volume': kline_data.quote_volume
            }])
            
            # å¦‚æœç¼“å†²åŒºä¸å­˜åœ¨ï¼Œåˆå§‹åŒ–
            if timeframe not in self.kline_buffers:
                logger.info(f"åˆå§‹åŒ– {timeframe} æ•°æ®ç¼“å†²åŒº")
                self.kline_buffers[timeframe] = new_row
            else:
                # è®°å½•è¿½åŠ å‰çš„ç¼“å†²åŒºå¤§å°
                old_size = len(self.kline_buffers[timeframe])
                old_last_close = self.kline_buffers[timeframe]['close'].iloc[-1]
                
                # è¿½åŠ æ–°æ•°æ®
                self.kline_buffers[timeframe] = pd.concat(
                    [self.kline_buffers[timeframe], new_row],
                    ignore_index=True
                )
                
                # é™åˆ¶ç¼“å†²åŒºå¤§å°ï¼ˆæ ¹æ®æ—¶é—´æ¡†æ¶ä¿æŒç»Ÿä¸€å¤©æ•°ï¼‰
                buffer_size = self.buffer_sizes.get(timeframe, 500)
                if len(self.kline_buffers[timeframe]) > buffer_size:
                    self.kline_buffers[timeframe] = self.kline_buffers[timeframe].tail(buffer_size)
                
                # âœ… è°ƒè¯•æ—¥å¿—ï¼šéªŒè¯ç¼“å†²åŒºæ›´æ–°
                new_size = len(self.kline_buffers[timeframe])
                new_last_close = self.kline_buffers[timeframe]['close'].iloc[-1]
                logger.debug(f"ğŸ“ˆ {timeframe} ç¼“å†²åŒºæ›´æ–°: {old_size}â†’{new_size}æ¡, æœ€æ–°æ”¶ç›˜ä»·: {old_last_close:.2f}â†’{new_last_close:.2f}")
            
            # âœ… å†™å…¥æ•°æ®åº“æŒä¹…åŒ–ï¼ˆPostgreSQL + TimescaleDBï¼‰
            try:
                from app.core.database import postgresql_manager
                from datetime import datetime
                import pytz
                
                # ç›´æ¥ä½¿ç”¨ Binance çš„æ—¶é—´æˆ³ï¼ˆæ¯«ç§’ï¼‰ï¼Œä¸åšä»»ä½•è½¬æ¢
                kline_dict = {
                    'symbol': kline_data.symbol,
                    'interval': timeframe,
                    'timestamp': kline_data.open_time,  # âœ… BinanceåŸå§‹æ—¶é—´æˆ³ï¼ˆæ¯«ç§’ï¼‰
                    'open': kline_data.open_price,
                    'high': kline_data.high_price,
                    'low': kline_data.low_price,
                    'close': kline_data.close_price,
                    'volume': kline_data.volume,
                    'close_time': kline_data.close_time,  # âœ… BinanceåŸå§‹æ—¶é—´æˆ³ï¼ˆæ¯«ç§’ï¼‰
                    'quote_volume': kline_data.quote_volume,
                    'trades': kline_data.trades,  # âœ… ä½¿ç”¨çœŸå®çš„tradesæ•°æ®
                    'taker_buy_base_volume': kline_data.taker_buy_base_volume,  # âœ… ä¸»åŠ¨ä¹°å…¥é‡
                    'taker_buy_quote_volume': kline_data.taker_buy_quote_volume  # âœ… ä¸»åŠ¨ä¹°å…¥é¢
                }
                
                # ğŸš€ å¼‚æ­¥å†™å…¥æ•°æ®åº“ï¼ˆä¸ç­‰å¾…å®Œæˆï¼Œé¿å…é˜»å¡ä¿¡å·ç”Ÿæˆï¼‰
                import asyncio
                asyncio.create_task(postgresql_manager.write_kline_data([kline_dict]))
                
                # âœ… ç®€åŒ–æ—¥å¿—è¾“å‡ºï¼ˆæ”¹ä¸ºDEBUGçº§åˆ«ï¼Œå‡å°‘æ—¥å¿—é‡ï¼‰
                logger.debug(f"ğŸ’¾ WebSocketæ•°æ®å·²æäº¤å†™å…¥: {timeframe} | trades={kline_data.trades}")
            except Exception as db_error:
                logger.error(f"âŒ å†™å…¥æ•°æ®åº“å¤±è´¥: {db_error}")
                logger.error(f"   Kçº¿è¯¦æƒ…: symbol={kline_dict.get('symbol')} interval={kline_dict.get('interval')} timestamp={kline_dict.get('timestamp')}")
            
            logger.debug(f"ğŸ“ˆ æ›´æ–° {timeframe} ç¼“å†²åŒºå®Œæˆ: å½“å‰{len(self.kline_buffers[timeframe])}æ¡æ•°æ®")
            
        except Exception as e:
            logger.error(f"æ›´æ–°Kçº¿ç¼“å†²åŒºå¤±è´¥: {e}")
    
    async def _initial_predictions(self):
        """é¦–æ¬¡å¯åŠ¨æ—¶é¢„æµ‹æ‰€æœ‰æ—¶é—´æ¡†æ¶å¹¶å¡«å……ç¼“å­˜ï¼ˆå¦‚æœæ¨¡å‹å¯ç”¨ï¼‰"""
        try:
            symbol = settings.SYMBOL
            
            # ğŸ”’ æ£€æŸ¥æ¨¡å‹æ˜¯å¦å¯ç”¨ï¼ˆå¯èƒ½æ­£åœ¨è®­ç»ƒä¸­ï¼‰
            # å…¼å®¹EnsembleMLServiceï¼ˆä½¿ç”¨ensemble_modelsï¼‰å’ŒMLServiceï¼ˆä½¿ç”¨modelsï¼‰
            models_dict = getattr(self.ml_service, 'ensemble_models', None) or getattr(self.ml_service, 'models', None)
            
            if not models_dict or len(models_dict) == 0:
                logger.warning("âš ï¸ æ¨¡å‹å°šæœªè®­ç»ƒå®Œæˆï¼Œè·³è¿‡é¦–æ¬¡é¢„æµ‹ï¼ˆç­‰å¾…æ¨¡å‹è®­ç»ƒå®Œæˆåé¦–æ¬¡WebSocketè§¦å‘ï¼‰")
                return
            
            logger.info(f"ğŸ¯ å¼€å§‹é¦–æ¬¡é¢„æµ‹æ‰€æœ‰æ—¶é—´æ¡†æ¶: {settings.TIMEFRAMES}")
            
            for timeframe in settings.TIMEFRAMES:
                try:
                    # å†æ¬¡ç¡®è®¤è¯¥æ—¶é—´æ¡†æ¶çš„æ¨¡å‹å­˜åœ¨
                    if timeframe not in models_dict:
                        logger.warning(f"âš ï¸ {timeframe} æ¨¡å‹ä¸å¯ç”¨ï¼Œè·³è¿‡é¦–æ¬¡é¢„æµ‹")
                        continue
                    
                    prediction = await self._predict_single_timeframe(symbol, timeframe)
                    if prediction:
                        self.cached_predictions[timeframe] = prediction
                        from app.utils.helpers import format_signal_type
                        logger.info(f"âœ… {timeframe} é¦–æ¬¡é¢„æµ‹å®Œæˆ: {format_signal_type(prediction.get('signal_type'))} (ç½®ä¿¡åº¦={prediction.get('confidence'):.4f})")
                    else:
                        logger.warning(f"âš ï¸ {timeframe} é¦–æ¬¡é¢„æµ‹è¿”å›ç©ºç»“æœ")
                except Exception as e:
                    logger.warning(f"âš ï¸ {timeframe} é¦–æ¬¡é¢„æµ‹å¼‚å¸¸ï¼ˆä¸å½±å“ç³»ç»Ÿè¿è¡Œï¼‰: {e}")
            
            logger.info(f"âœ… é¦–æ¬¡é¢„æµ‹å®Œæˆï¼Œå·²ç¼“å­˜ {len(self.cached_predictions)}/{len(settings.TIMEFRAMES)} ä¸ªæ—¶é—´æ¡†æ¶")
            
            # å°è¯•ç«‹å³ç”Ÿæˆä¸€ä¸ªä¿¡å·ï¼ˆå¦‚æœæ‰€æœ‰æ—¶é—´æ¡†æ¶éƒ½é¢„æµ‹æˆåŠŸï¼‰
            if len(self.cached_predictions) == len(settings.TIMEFRAMES):
                logger.info("ğŸ”„ å°è¯•åŸºäºé¦–æ¬¡é¢„æµ‹ç”Ÿæˆåˆå§‹ä¿¡å·...")
                
                # ğŸ”¥ é¦–æ¬¡é¢„æµ‹ä¸è®¡å…¥é¢„çƒ­ä¿¡å·ï¼ˆåªæ˜¯åˆå§‹åŒ–ç¼“å­˜ï¼‰
                # é¢„çƒ­ä¿¡å·åº”è¯¥ä»å®æ—¶WebSocketä¿¡å·å¼€å§‹è®¡æ•°
                signal = await self._try_synthesize_cached_signals(symbol)
                if signal:
                    from app.utils.helpers import format_signal_type
                    logger.info(f"âœ… ç”Ÿæˆåˆå§‹ä¿¡å·: {format_signal_type(signal.signal_type)} ç½®ä¿¡åº¦={signal.confidence:.4f}")
                    logger.info(f"ğŸ’¡ é¦–æ¬¡ä¿¡å·ä¸è®¡å…¥é¢„çƒ­ï¼ˆé¢„çƒ­ä»å®æ—¶WebSocketä¿¡å·å¼€å§‹ï¼‰")
                else:
                    logger.info(f"â„¹ï¸ åˆå§‹ä¿¡å·ä¸ºHOLDæˆ–ä½ç½®ä¿¡åº¦ï¼Œç­‰å¾…å®æ—¶ä¿¡å·")
            else:
                logger.info(f"â¸ï¸ é¦–æ¬¡é¢„æµ‹æœªå®Œå…¨æˆåŠŸï¼Œç­‰å¾…WebSocketæ•°æ®è§¦å‘é¢„æµ‹")
            
        except Exception as e:
            logger.warning(f"âš ï¸ é¦–æ¬¡é¢„æµ‹å¤±è´¥ï¼ˆä¸å½±å“ç³»ç»Ÿè¿è¡Œï¼‰: {e}")
    
    async def _predict_single_timeframe(self, symbol: str, timeframe: str) -> Optional[Dict[str, Any]]:
        """é¢„æµ‹å•ä¸ªæ—¶é—´æ¡†æ¶"""
        try:
            from app.services.binance_client import binance_client
            
            # ç¡®å®šéœ€è¦çš„æ•°æ®é‡
            prediction_days_config = {
                '15m': 15,   # 15å¤©=1440æ¡
                '2h': 20,    # 20å¤©=240æ¡
                '4h': 35     # 35å¤©=210æ¡
            }
            prediction_days = prediction_days_config.get(timeframe, 35)
            
            interval_minutes = {
                '1m': 1, '3m': 3, '5m': 5, '15m': 15, '30m': 30,
                '1h': 60, '2h': 120, '4h': 240, '6h': 360, '8h': 480,
                '12h': 720, '1d': 1440
            }
            minutes = interval_minutes.get(timeframe, 60)
            required_klines = int((prediction_days * 24 * 60) / minutes)
            
            # ä¼˜å…ˆä½¿ç”¨WebSocketç¼“å†²åŒº
            if timeframe in self.kline_buffers and len(self.kline_buffers[timeframe]) >= required_klines:
                df = self.kline_buffers[timeframe].tail(required_klines).copy()
                logger.debug(f"âœ“ ä½¿ç”¨ç¼“å†²åŒº: {timeframe} ({len(df)}æ¡)")
            else:
                # ä»APIè·å–
                logger.debug(f"âš ï¸ ç¼“å†²åŒºä¸è¶³ï¼Œä»APIè·å–: {timeframe}")
                klines = binance_client.get_klines(
                    symbol=symbol,
                    interval=timeframe,
                    limit=required_klines
                )
                if not klines:
                    logger.warning(f"âŒ {timeframe} æ•°æ®è·å–å¤±è´¥")
                    return None
                
                df = pd.DataFrame(klines)
                # ğŸ”¥ ç¡®ä¿timestampæ˜¯datetimeç±»å‹
                if 'timestamp' in df.columns:
                    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
            
            if df is None or len(df) < 50:
                logger.warning(f"âŒ {timeframe} æ•°æ®ä¸è¶³")
                return None
            
            # è°ƒç”¨MLæœåŠ¡é¢„æµ‹
            prediction = await self.ml_service.predict(df, timeframe=timeframe)
            return prediction
            
        except Exception as e:
            logger.error(f"é¢„æµ‹{timeframe}å¤±è´¥: {e}")
            return None
    
    async def _try_synthesize_cached_signals(self, symbol: str) -> Optional[TradingSignal]:
        """å°è¯•åˆæˆæ‰€æœ‰ç¼“å­˜çš„ä¿¡å·"""
        try:
            # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰æ—¶é—´æ¡†æ¶éƒ½æœ‰ç¼“å­˜
            if not self.cached_predictions:
                logger.debug("âŒ ä¿¡å·ç¼“å­˜ä¸ºç©º")
                return None
            
            # å¦‚æœä¸æ˜¯æ‰€æœ‰æ—¶é—´æ¡†æ¶éƒ½æœ‰é¢„æµ‹ï¼Œå¯ä»¥ç»§ç»­ï¼ˆä½¿ç”¨å·²æœ‰çš„ï¼‰
            # ä½†è‡³å°‘éœ€è¦15m
            if '15m' not in self.cached_predictions:
                logger.warning("âŒ ç¼ºå°‘15mä¿¡å·ï¼Œæ— æ³•åˆæˆ")
                return None
            
            # åˆæˆä¿¡å·ï¼ˆåˆæˆè¿‡ç¨‹ä¸­çš„æ—¥å¿—å·²åœ¨_synthesize_signalä¸­è¾“å‡ºï¼‰
            signal = await self._synthesize_signal(symbol, self.cached_predictions)
            
            # å¦‚æœæ²¡æœ‰ä¿¡å·ï¼ˆHOLDæˆ–å…¶ä»–åŸå› ï¼‰ï¼Œç›´æ¥è¿”å›
            # _synthesize_signal å†…éƒ¨å·²ç»è®°å½•äº†è¯¦ç»†æ—¥å¿—
            if not signal:
                return None
            
            # æ£€æŸ¥ç½®ä¿¡åº¦
            if signal.confidence < self.confidence_threshold:
                logger.info(f"âŒ ç½®ä¿¡åº¦ä¸è¶³: {signal.confidence:.4f} < {self.confidence_threshold}")
                return None
            
            # æ£€æŸ¥ä¿¡å·å»é‡ï¼ˆå»é‡æ£€æŸ¥ä¸­çš„æ—¥å¿—å·²åœ¨_should_send_signalä¸­è¾“å‡ºï¼‰
            if not await self._should_send_signal(symbol, signal.signal_type):
                return None
            
            return signal
            
        except Exception as e:
            logger.error(f"åˆæˆä¿¡å·å¤±è´¥: {e}")
            return None
    
    async def generate_signal(self, symbol: str) -> Optional[TradingSignal]:
        """ç”Ÿæˆäº¤æ˜“ä¿¡å·ï¼ˆåŸºäºWebSocketå®æ—¶æ•°æ®ï¼‰"""
        try:
            logger.info(f"ğŸ”® å¼€å§‹ç”Ÿæˆäº¤æ˜“ä¿¡å·: {symbol}")
            logger.debug(f"æ•°æ®æº: WebSocket å®æ—¶ç¼“å†²åŒº (ä¼˜å…ˆ) / API (å¤‡ç”¨)")
            
            # è·å–å¤šæ—¶é—´æ¡†æ¶é¢„æµ‹
            predictions = await self._get_multi_timeframe_predictions(symbol)
            
            if not predictions:
                logger.warning(f"æœªè·å–åˆ°æœ‰æ•ˆé¢„æµ‹æ•°æ®")
                return None
            
            # åˆæˆä¿¡å·
            signal = await self._synthesize_signal(symbol, predictions)
            
            if not signal or signal.confidence < self.confidence_threshold:
                logger.info(f"âŒ ä¿¡å·ç½®ä¿¡åº¦ä¸è¶³: {signal.confidence if signal else 0:.4f} < {self.confidence_threshold}")
                return None
            
            # æ£€æŸ¥ä¿¡å·å»é‡ï¼ˆä»ç¼“å­˜ä¸­è·å–ä¸Šä¸€æ¬¡çš„ä¿¡å·ï¼‰
            if not await self._should_send_signal(symbol, signal.signal_type):
                logger.info(f"âœ— ä¿¡å·å·²å­˜åœ¨ï¼Œæ‹’ç»é‡å¤: {signal.signal_type} {signal.confidence:.4f}")
                return None
            
            from app.utils.helpers import format_signal_type
            logger.info(f"âœ… ç”Ÿæˆæ–°äº¤æ˜“ä¿¡å·: {format_signal_type(signal.signal_type)} ç½®ä¿¡åº¦:{signal.confidence:.4f}")
            return signal
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆäº¤æ˜“ä¿¡å·å¤±è´¥: {e}")
            return None
    
    async def _get_multi_timeframe_predictions(self, symbol: str) -> Dict[str, Dict[str, Any]]:
        """è·å–å¤šæ—¶é—´æ¡†æ¶é¢„æµ‹ - ä½¿ç”¨å›ºå®šå¤©æ•°ç¡®ä¿æ—¶é—´å¯¹é½"""
        try:
            from app.services.binance_client import binance_client
            
            predictions = {}
            
            # âœ… å·®å¼‚åŒ–é¢„æµ‹å¤©æ•°ï¼šæ¯ä¸ªæ—¶é—´æ¡†æ¶ä½¿ç”¨æœ€ä¼˜é…ç½®
            # åŸåˆ™ï¼šç¡®ä¿ç‰¹å¾å®Œæ•´ï¼ˆæœ€é•¿çª—å£200æœŸï¼‰+ é€‚åˆæ—¶é—´æ¡†æ¶ç‰¹æ€§
            prediction_days_config = {
                '15m': 15,   # 15å¤©=1440æ¡ (çŸ­æœŸæ•æ„Ÿï¼Œå¿«é€Ÿå“åº”)
                '2h': 20,    # 20å¤©=240æ¡ (ä¸­æœŸå¹³è¡¡)
                '4h': 35     # 35å¤©=210æ¡ (é•¿æœŸç¨³å®šï¼Œç¡®ä¿200æœŸç‰¹å¾)
            }
            
            # æ—¶é—´å‘¨æœŸå¯¹åº”çš„åˆ†é’Ÿæ•°
            interval_minutes = {
                '1m': 1, '3m': 3, '5m': 5, '15m': 15, '30m': 30,
                '1h': 60, '2h': 120, '4h': 240, '6h': 360, '8h': 480,
                '12h': 720, '1d': 1440
            }
            
            for timeframe in settings.TIMEFRAMES:
                df = None
                data_source = ""
                
                # æ ¹æ®æ—¶é—´æ¡†æ¶ä½¿ç”¨å·®å¼‚åŒ–çš„é¢„æµ‹å¤©æ•°
                prediction_days = prediction_days_config.get(timeframe, 35)
                minutes = interval_minutes.get(timeframe, 60)
                required_klines = int((prediction_days * 24 * 60) / minutes)
                
                # ä¼˜å…ˆä½¿ç”¨WebSocketç¼“å†²åŒºæ•°æ®
                if timeframe in self.kline_buffers and len(self.kline_buffers[timeframe]) >= required_klines:
                    df = self.kline_buffers[timeframe].tail(required_klines).copy()
                    data_source = "WebSocketç¼“å†²åŒº"
                    logger.debug(f"âœ“ ä½¿ç”¨WebSocketç¼“å†²åŒº: {timeframe} (éœ€è¦{required_klines}æ¡, å½“å‰{len(df)}æ¡, {prediction_days}å¤©)")
                else:
                    # ç¼“å†²åŒºæ•°æ®ä¸è¶³ï¼Œä»APIè·å–
                    logger.debug(f"âš ï¸ ç¼“å†²åŒºæ•°æ®ä¸è¶³({len(self.kline_buffers.get(timeframe, []))}æ¡ < {required_klines}æ¡)ï¼Œä»APIè·å–: {timeframe}")
                    klines = binance_client.get_klines(
                        symbol=symbol,
                        interval=timeframe,
                        limit=required_klines
                    )
                    
                    if not klines:
                        logger.warning(f"âŒ æœªè·å–åˆ°{timeframe}æ•°æ®")
                        continue
                    
                    df = pd.DataFrame(klines)
                    # ğŸ”¥ ç¡®ä¿timestampæ˜¯datetimeç±»å‹
                    if 'timestamp' in df.columns:
                        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
                    data_source = "APIå¤‡ç”¨"
                
                if df is None or len(df) < 50:
                    logger.warning(f"âŒ {timeframe}æ•°æ®ä¸è¶³: {len(df) if df is not None else 0}æ¡")
                    continue
                
                logger.debug(f"ğŸ¤– å¼€å§‹{timeframe}æ¨¡å‹é¢„æµ‹ (æ•°æ®æº: {data_source}, {len(df)}æ¡Kçº¿)...")
                
                # æ¨¡å‹é¢„æµ‹ï¼ˆä¼ å…¥timeframeä½¿ç”¨å¯¹åº”çš„æ¨¡å‹ï¼‰
                prediction = await self.ml_service.predict(df, timeframe=timeframe)
                
                if prediction:
                    predictions[timeframe] = prediction
                    logger.debug(f"âœ… {timeframe}é¢„æµ‹å®Œæˆ: {prediction.get('signal_type')} (ç½®ä¿¡åº¦={prediction.get('confidence'):.4f})")
                else:
                    logger.warning(f"âŒ {timeframe}é¢„æµ‹å¤±è´¥æˆ–è¿”å›ç©º")
            
            return predictions
            
        except Exception as e:
            logger.error(f"è·å–å¤šæ—¶é—´æ¡†æ¶é¢„æµ‹å¤±è´¥: {e}")
            return {}
    
    async def _synthesize_signal(
        self, 
        symbol: str, 
        predictions: Dict[str, Dict[str, Any]]
    ) -> Optional[TradingSignal]:
        """åˆæˆå¤šæ—¶é—´æ¡†æ¶ä¿¡å·"""
        try:
            if not predictions:
                logger.warning("âš ï¸ æ²¡æœ‰å¯ç”¨çš„é¢„æµ‹æ•°æ®ï¼Œæ— æ³•åˆæˆä¿¡å·")
                return None
            
            # æ—¶é—´æ¡†æ¶æƒé‡ï¼ˆçŸ­çº¿äº¤æ˜“ç­–ç•¥ï¼šä»¥15mä¸ºä¸»å¯¼ï¼‰
            # å·®å¼‚åŒ–è®­ç»ƒå¤©æ•°åçš„æ•°æ®é‡ï¼š
            # 15m: 17,280æ¡/180å¤© (è®­ç»ƒ13.8k) âœ… å……è¶³ï¼Œæ•æ‰çŸ­æœŸæœºä¼š
            # 2h:  4,320æ¡/360å¤©  (è®­ç»ƒ3.5k)  âœ… æ›´å……è¶³ï¼Œè¶‹åŠ¿è¿‡æ»¤ â¬†ï¸ å¢åŠ 
            # 4h:  3,240æ¡/540å¤©  (è®­ç»ƒ2.6k)  âœ… å¤§å¹…å¢åŠ ï¼Œå¤§è¶‹åŠ¿ç¡®è®¤ â¬†ï¸ å¢åŠ 
            timeframe_weights = {
                '15m': 0.70,   # ğŸ¯ çŸ­çº¿ä¸»å¯¼ï¼šæé«˜æƒé‡ï¼Œå¿«é€Ÿæ•æ‰å…¥åœºç‚¹
                '2h': 0.20,    # ä¸­æœŸè¾…åŠ©ï¼šè¶‹åŠ¿è¿‡æ»¤
                '4h': 0.10     # é•¿æœŸè¾…åŠ©ï¼šé¿å…é€†åŠ¿äº¤æ˜“ï¼ˆæƒé‡ä½ï¼Œé¿å…4hä¿¡å·é•¿æ—¶é—´ä¸»å¯¼ï¼‰
            }
            
            # è®¡ç®—åŠ æƒä¿¡å·ï¼ˆåŠ¨æ€æƒé‡ï¼šé•¿å‘¨æœŸHOLDæ—¶é™æƒï¼‰
            weighted_scores = {'LONG': 0, 'SHORT': 0, 'HOLD': 0}
            total_weight = 0
            
            for timeframe, prediction in predictions.items():
                base_weight = timeframe_weights.get(timeframe, 0.2)
                probabilities = prediction.get('probabilities', {})
                signal = prediction.get('signal_type')
                
                # ğŸ”‘ åŠ¨æ€æƒé‡è°ƒæ•´ï¼šå¦‚æœé•¿å‘¨æœŸï¼ˆ2h/4hï¼‰æ˜¯HOLDä¸”ç½®ä¿¡åº¦é«˜ï¼Œå¤§å¹…é™ä½æƒé‡
                if timeframe in ['2h', '4h'] and signal == 'HOLD':
                    hold_confidence = prediction.get('confidence', 0)
                    if hold_confidence > 0.65:
                        # HOLDç½®ä¿¡åº¦å¾ˆé«˜æ—¶ï¼Œæƒé‡å‡åŠï¼ˆé¿å…å‹åˆ¶15mï¼‰
                        weight = base_weight * 0.5
                        logger.debug(f"   {timeframe} HOLDé«˜ç½®ä¿¡åº¦({hold_confidence:.2f})ï¼Œæƒé‡{base_weight}â†’{weight}")
                    else:
                        weight = base_weight
                else:
                    weight = base_weight
                
                weighted_scores['LONG'] += probabilities.get('long', 0) * weight
                weighted_scores['SHORT'] += probabilities.get('short', 0) * weight
                weighted_scores['HOLD'] += probabilities.get('hold', 0) * weight
                
                total_weight += weight
            
            # å½’ä¸€åŒ–
            if total_weight > 0:
                for key in weighted_scores:
                    weighted_scores[key] /= total_weight
            
            # ç¡®å®šæœ€ç»ˆä¿¡å·
            signal_type = max(weighted_scores, key=weighted_scores.get)
            confidence = weighted_scores[signal_type]
            
            # è®°å½•åˆæˆè¿‡ç¨‹
            from app.utils.helpers import format_signal_type
            logger.info(f"ğŸ”„ ä¿¡å·åˆæˆ: {len(predictions)}ä¸ªæ—¶é—´æ¡†æ¶")
            for tf, pred in predictions.items():
                logger.info(f"  â€¢ {tf}: {format_signal_type(pred['signal_type'])} (ç½®ä¿¡åº¦={pred['confidence']:.4f})")
            logger.info(f"  âœ æœ€ç»ˆ: {format_signal_type(signal_type)} (åŠ æƒç½®ä¿¡åº¦={confidence:.4f})")
            
            # è¿‡æ»¤HOLDä¿¡å·
            if signal_type == 'HOLD':
                logger.info(f"âŠ— æœ€ç»ˆä¿¡å·ä¸ºHOLDï¼Œä¸å‘å‡ºäº¤æ˜“ä¿¡å·")
                return None
            
            # ğŸ†• ä¿¡å·å¢å¼ºè¿‡æ»¤ï¼ˆé¢„æœŸèƒœç‡+5-10%ï¼‰
            filter_result = await self._enhanced_signal_filter(
                signal_type=signal_type,
                confidence=confidence,
                predictions=predictions,
                symbol=symbol
            )
            
            if not filter_result['pass']:
                logger.info(f"âŒ ä¿¡å·è¢«è¿‡æ»¤: {filter_result['reason']}")
                return None
            
            # è·å–å½“å‰ä»·æ ¼
            current_price = await self._get_current_price(symbol)
            if not current_price:
                logger.warning("âš ï¸ æ— æ³•è·å–å½“å‰ä»·æ ¼ï¼Œæ”¾å¼ƒæœ¬æ¬¡ä¿¡å·")
                return None
            
            # ğŸ†• ä½¿ç”¨åŠ¨æ€æ­¢æŸæ­¢ç›ˆï¼ˆåŸºäºATRï¼‰
            from app.services.risk_service import RiskService
            stop_levels = await RiskService.calculate_dynamic_stop_levels(
                symbol=symbol,
                entry_price=current_price,
                signal_type=signal_type,
                confidence=confidence
            )
            
            if not stop_levels:
                logger.warning("âš ï¸ æ­¢æŸæ­¢ç›ˆè®¡ç®—å¤±è´¥ï¼Œä½¿ç”¨å›ºå®šç™¾åˆ†æ¯”")
                # é™çº§æ–¹æ¡ˆ
                if signal_type == 'LONG':
                    stop_loss = current_price * (1 - self.stop_loss_pct)
                    take_profit = current_price * (1 + self.take_profit_pct)
                else:  # SHORT
                    stop_loss = current_price * (1 + self.stop_loss_pct)
                    take_profit = current_price * (1 - self.take_profit_pct)
            else:
                stop_loss = stop_levels['stop_loss']
                take_profit = stop_levels['take_profit']
                logger.debug(f"âœ… ä½¿ç”¨åŠ¨æ€æ­¢æŸ: ç›ˆäºæ¯” 1:{stop_levels.get('risk_reward_ratio', 0):.2f}")
            
            # ğŸ†• ç»Ÿä¸€ä½¿ç”¨ position_manager è®¡ç®—ä»“ä½å¤§å°ï¼ˆUSDTä»·å€¼ï¼‰
            # ä» Redis è¯»å–å½“å‰äº¤æ˜“æ¨¡å¼ï¼ˆæ”¯æŒåŠ¨æ€åˆ‡æ¢ï¼‰
            from app.services.position_manager import position_manager
            current_mode = await cache_manager.get("system:trading_mode")
            is_virtual_mode = (current_mode != "AUTO")  # é»˜è®¤è™šæ‹Ÿæ¨¡å¼ï¼Œåªæœ‰æ˜ç¡®æ˜¯ AUTO æ‰ç”¨å®ç›˜
            
            # ğŸ”‘ è·å–ä»“ä½å¤§å°ï¼ˆç›´æ¥ä½¿ç”¨USDTä»·å€¼ï¼Œä¸æ¢ç®—å¼ æ•°ï¼‰
            position_size = await position_manager.calculate_position_size(
                symbol, signal_type, confidence, current_price,
                is_virtual=is_virtual_mode  # åŠ¨æ€æ ¹æ® Redis ä¸­çš„æ¨¡å¼å†³å®š
            )
            
            logger.debug(f"ğŸ’° ä»“ä½å¤§å°: {position_size:.2f} USDT @ {current_price:.2f}")
            
            # åˆ›å»ºä¿¡å·å¯¹è±¡
            signal = TradingSignal(
                timestamp=datetime.now(),
                symbol=symbol,
                signal_type=signal_type,
                confidence=confidence,
                entry_price=current_price,
                stop_loss=stop_loss,
                take_profit=take_profit,
                position_size=position_size,
                timeframe='multi',
                model_version='1.0',
                metadata={
                    'timeframe_predictions': predictions,
                    'weighted_scores': weighted_scores,
                    'generation_method': 'multi_timeframe_synthesis'
                }
            )
            
            return signal
            
        except Exception as e:
            logger.error(f"åˆæˆä¿¡å·å¤±è´¥: {e}")
            return None
    
    async def _get_current_price(self, symbol: str) -> Optional[float]:
        """è·å–å½“å‰ä»·æ ¼ - ç›´æ¥ä»APIè·å–å®æ—¶ä»·æ ¼"""
        try:
            from app.services.binance_client import binance_client
            
            # ä¼˜å…ˆä»ç¼“å­˜è·å–æœ€æ–°ä»·æ ¼ï¼ˆç¼“å­˜æ˜¯WebSocketå®æ—¶æ›´æ–°çš„ï¼‰
            ticker_data = await cache_manager.get_market_data(symbol, "ticker")
            
            if ticker_data:
                logger.debug(f"ä»ç¼“å­˜è·å–ä»·æ ¼: {ticker_data.get('price')}")
                return float(ticker_data.get('price', 0))
            
            # ç¼“å­˜å¤±æ•ˆæ—¶ï¼Œç›´æ¥ä»APIè·å–æœ€æ–°ä»·æ ¼
            logger.debug(f"ä»APIè·å–å®æ—¶ä»·æ ¼: {symbol}")
            klines = binance_client.get_klines(symbol, '1m', limit=1)
            
            if klines and len(klines) > 0:
                price = float(klines[0]['close'])
                logger.debug(f"âœ“ APIä»·æ ¼: {price}")
                return price
            
            logger.warning(f"æ— æ³•è·å–{symbol}çš„å½“å‰ä»·æ ¼")
            return None
            
        except Exception as e:
            logger.error(f"è·å–å½“å‰ä»·æ ¼å¤±è´¥: {e}")
            return None
    
    # âœ… å·²ç§»é™¤é‡å¤çš„ _calculate_position_size æ–¹æ³•
    # ç°åœ¨ç»Ÿä¸€ä½¿ç”¨ position_manager.calculate_position_size()
    
    async def _should_send_signal(self, symbol: str, signal_type: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦åº”è¯¥å‘é€ä¿¡å· - åŸºäºç¼“å­˜çš„ä¸Šä¸€æ¬¡ä¿¡å·å»é‡"""
        try:
            # ä»ç¼“å­˜è·å–ä¸Šä¸€æ¬¡çš„ä¿¡å·
            from app.core.cache import cache_manager
            last_signal = await cache_manager.get_trading_signal(symbol)
            
            # å¦‚æœæ²¡æœ‰ç¼“å­˜çš„ä¿¡å·ï¼Œç›´æ¥å‘é€
            if not last_signal:
                logger.info(f"âœ“ æ— ç¼“å­˜ä¿¡å·ï¼Œå…è®¸å‘é€ {signal_type}")
                return True
            
            # è·å–ä¸Šä¸€æ¬¡çš„ä¿¡å·ç±»å‹
            last_signal_type = last_signal.get('signal_type')
            
            # å¦‚æœä¿¡å·ç±»å‹ç›¸åŒï¼Œæ‹’ç»ï¼ˆå»é‡ï¼‰
            if last_signal_type == signal_type:
                logger.warning(f"âœ— ä¿¡å·é‡å¤: ä¸Šæ¬¡={last_signal_type}, æœ¬æ¬¡={signal_type}")
                return False
            
            # ä¿¡å·ç±»å‹ä¸åŒï¼Œå…è®¸å‘é€ï¼ˆæ–¹å‘æ”¹å˜ï¼‰
            logger.info(f"âœ“ ä¿¡å·æ–¹å‘æ”¹å˜: {last_signal_type} â†’ {signal_type}")
            return True
            
        except Exception as e:
            logger.error(f"æ£€æŸ¥ä¿¡å·å»é‡å¤±è´¥: {e}")
            # å‘ç”Ÿé”™è¯¯æ—¶ä¿å®ˆå¤„ç†ï¼Œå…è®¸å‘é€ä¿¡å·
            return True
    
    async def _process_signal(self, signal: TradingSignal):
        """å¤„ç†ç”Ÿæˆçš„ä¿¡å·ï¼ˆæ³¨æ„ï¼šsignal_counterå·²åœ¨è°ƒç”¨å‰+1ï¼‰"""
        try:
            # ğŸ”’ å®‰å…¨ä¿æŠ¤ï¼šå‰5ä¸ªä¿¡å·ä»…è®°å½•ä¸äº¤æ˜“
            # æ³¨æ„ï¼šsignal_counterå·²åœ¨_on_new_dataä¸­+1ï¼Œè¿™é‡Œä¸å†é‡å¤
            
            if self.signal_counter <= self.warmup_signals:
                from app.utils.helpers import format_signal_type
                logger.warning(f"âš ï¸ é¢„çƒ­ä¿¡å· [{self.signal_counter}/{self.warmup_signals}]ï¼šä»…è®°å½•ï¼Œä¸æ‰§è¡Œäº¤æ˜“")
                logger.info(f"   ä¿¡å·è¯¦æƒ…: {format_signal_type(signal.signal_type)} ç½®ä¿¡åº¦={signal.confidence:.4f} å…¥åœº={signal.entry_price:.2f}")
                
                # åªä¿å­˜åˆ°æ•°æ®åº“ç”¨äºè§‚å¯Ÿï¼Œä¸å‘é€ç»™äº¤æ˜“å¼•æ“
                await self._save_signal(signal)
                
                logger.info(f"âœ… é¢„çƒ­ä¿¡å·å·²è®°å½•åˆ°æ•°æ®åº“ (å‰©ä½™{self.warmup_signals - self.signal_counter}ä¸ªé¢„çƒ­ä¿¡å·)")
                return  # ğŸ”’ ç›´æ¥è¿”å›ï¼Œä¸æ‰§è¡Œåç»­äº¤æ˜“é€»è¾‘
            
            # âœ… é¢„çƒ­å®Œæˆï¼Œæ­£å¼äº¤æ˜“ä¿¡å·
            from app.utils.helpers import format_signal_type
            logger.info(f"ğŸš€ æ­£å¼äº¤æ˜“ä¿¡å· (ç¬¬{self.signal_counter}ä¸ª): {format_signal_type(signal.signal_type)} ç½®ä¿¡åº¦={signal.confidence:.4f}")
            
            # æ›´æ–°æœ€åä¿¡å·è®°å½•
            self.last_signals[signal.symbol] = signal
            
            # å­˜å‚¨ä¿¡å·åˆ°æ•°æ®åº“
            await self._save_signal(signal)
            
            # ç¼“å­˜ä¿¡å·ï¼ˆä¸è®¾ç½®è¿‡æœŸæ—¶é—´ï¼Œç”¨äºä¿¡å·å»é‡ï¼‰
            await cache_manager.set_trading_signal(
                signal.symbol,
                {
                    'signal_type': signal.signal_type,
                    'confidence': signal.confidence,
                    'entry_price': signal.entry_price,
                    'stop_loss': signal.stop_loss,
                    'take_profit': signal.take_profit,
                    'position_size': signal.position_size,
                    'timestamp': signal.timestamp.isoformat()
                },
                expire=None  # ä¸è¿‡æœŸï¼Œåªåœ¨æ–°ä¿¡å·äº§ç”Ÿæ—¶è¦†ç›–
            )
            
            # é€šçŸ¥å›è°ƒå‡½æ•°ï¼ˆå‘é€ç»™äº¤æ˜“å¼•æ“ï¼‰
            for callback in self.signal_callbacks:
                try:
                    await callback(signal)
                except Exception as e:
                    logger.error(f"ä¿¡å·å›è°ƒå¤±è´¥: {e}")
            
            logger.info(f"âœ… äº¤æ˜“ä¿¡å·å·²å‘é€: {signal.symbol} {signal.signal_type}")
            
        except Exception as e:
            logger.error(f"å¤„ç†ä¿¡å·å¤±è´¥: {e}")
    
    async def _save_signal(self, signal: TradingSignal):
        """ä¿å­˜ä¿¡å·åˆ°æ•°æ®åº“ï¼ˆåªä¿å­˜ä¸€ä¸ªåˆæˆä¿¡å·ï¼Œpredictionsä¿ç•™åŸå§‹é¢„æµ‹è¯¦æƒ…ï¼‰"""
        try:
            # å¤„ç† predictions ä¸­çš„ datetime å¯¹è±¡ï¼ˆè½¬æ¢ä¸º ISO æ ¼å¼å­—ç¬¦ä¸²ï¼‰
            predictions = signal.metadata.get('timeframe_predictions', {})
            cleaned_predictions = {}
            for tf, pred in predictions.items():
                cleaned_pred = pred.copy()
                # å°† datetime å¯¹è±¡è½¬æ¢ä¸ºå­—ç¬¦ä¸²
                if 'timestamp' in cleaned_pred and hasattr(cleaned_pred['timestamp'], 'isoformat'):
                    cleaned_pred['timestamp'] = cleaned_pred['timestamp'].isoformat()
                cleaned_predictions[tf] = cleaned_pred
            
            signal_data = {
                'timestamp': signal.timestamp,
                'symbol': signal.symbol,
                'signal_type': signal.signal_type,
                'confidence': signal.confidence,
                'entry_price': signal.entry_price,
                'stop_loss': signal.stop_loss,
                'take_profit': signal.take_profit,
                'position_size': signal.position_size,
                # ä¿å­˜3ä¸ªæ—¶é—´æ¡†æ¶çš„é¢„æµ‹ä¿¡æ¯åˆ°predictionså­—æ®µï¼ˆå·²æ¸…ç† datetimeï¼‰
                'predictions': cleaned_predictions
            }
            
            await postgresql_manager.write_signal_data(signal_data)
            
        except Exception as e:
            logger.error(f"ä¿å­˜ä¿¡å·å¤±è´¥: {e}")
    
    async def get_recent_signals(
        self, 
        symbol: str, 
        hours: int = 24, 
        limit: int = 100
    ) -> List[Dict[str, Any]]:
        """è·å–æœ€è¿‘çš„ä¿¡å·"""
        try:
            end_time = datetime.now()
            start_time = end_time - timedelta(hours=hours)
            
            signals = await postgresql_manager.query_signals(
                symbol, start_time, end_time, limit
            )
            
            return signals
            
        except Exception as e:
            logger.error(f"è·å–æœ€è¿‘ä¿¡å·å¤±è´¥: {e}")
            return []
    
    async def get_signal_performance(self, symbol: str, days: int = 7) -> Dict[str, Any]:
        """è·å–ä¿¡å·è¡¨ç°ç»Ÿè®¡"""
        try:
            end_time = datetime.now()
            start_time = end_time - timedelta(days=days)
            
            signals = await postgresql_manager.query_signals(
                symbol, start_time, end_time
            )
            
            if not signals:
                return {}
            
            # ç»Ÿè®¡ä¿¡å·æ•°é‡
            total_signals = len(signals)
            long_signals = len([s for s in signals if s['signal_type'] == 'LONG'])
            short_signals = len([s for s in signals if s['signal_type'] == 'SHORT'])
            
            # å¹³å‡ç½®ä¿¡åº¦
            avg_confidence = np.mean([s['confidence'] for s in signals])
            
            # ä¿¡å·é¢‘ç‡ï¼ˆæ¯å¤©ï¼‰
            signal_frequency = total_signals / days
            
            performance = {
                'total_signals': total_signals,
                'long_signals': long_signals,
                'short_signals': short_signals,
                'long_ratio': long_signals / total_signals if total_signals > 0 else 0,
                'short_ratio': short_signals / total_signals if total_signals > 0 else 0,
                'avg_confidence': avg_confidence,
                'signal_frequency': signal_frequency,
                'period_days': days
            }
            
            return performance
            
        except Exception as e:
            logger.error(f"è·å–ä¿¡å·è¡¨ç°å¤±è´¥: {e}")
            return {}
    
    async def _enhanced_signal_filter(
        self,
        signal_type: str,
        confidence: float,
        predictions: Dict[str, Dict[str, Any]],
        symbol: str
    ) -> Dict[str, Any]:
        """å¢å¼ºçš„ä¿¡å·è¿‡æ»¤ï¼ˆä¼˜åŒ–ç›®æ ‡ï¼šèƒœç‡+5-10%ï¼‰
        
        å¤šç»´åº¦è¿‡æ»¤ä½è´¨é‡ä¿¡å·ï¼š
        1. è¶‹åŠ¿ä¸€è‡´æ€§è¿‡æ»¤
        2. é‡èƒ½ç¡®è®¤
        3. æ³¢åŠ¨ç‡è¿‡æ»¤
        4. æ—¶é—´è¿‡æ»¤
        
        Returns:
            {'pass': bool, 'reason': str}
        """
        try:
            # 1. ç½®ä¿¡åº¦åŸºç¡€è¿‡æ»¤ï¼ˆå·²æœ‰ï¼‰
            if confidence < self.confidence_threshold:
                return {'pass': False, 'reason': f'ç½®ä¿¡åº¦è¿‡ä½ ({confidence:.4f} < {self.confidence_threshold})'}
            
            # 2. è¶‹åŠ¿ä¸€è‡´æ€§è¿‡æ»¤
            # æ£€æŸ¥å¤šæ—¶é—´æ¡†æ¶æ˜¯å¦è¶‹åŠ¿ä¸€è‡´
            if len(predictions) >= 2:
                signal_types = [pred['signal_type'] for pred in predictions.values()]
                # å¦‚æœæœ‰ä»»ä½•ä¸€ä¸ªæ—¶é—´æ¡†æ¶æ˜¯åå‘ä¿¡å·ï¼Œè¿‡æ»¤
                if signal_type == 'LONG' and 'SHORT' in signal_types:
                    # ä½†å¦‚æœ15mç½®ä¿¡åº¦ç‰¹åˆ«é«˜ï¼ˆ>0.7ï¼‰ï¼Œå…è®¸é€šè¿‡
                    if confidence < 0.7:
                        return {'pass': False, 'reason': 'å¤šæ—¶é—´æ¡†æ¶è¶‹åŠ¿ä¸ä¸€è‡´ï¼ˆæœ‰SHORTä¿¡å·ï¼‰'}
                elif signal_type == 'SHORT' and 'LONG' in signal_types:
                    if confidence < 0.7:
                        return {'pass': False, 'reason': 'å¤šæ—¶é—´æ¡†æ¶è¶‹åŠ¿ä¸ä¸€è‡´ï¼ˆæœ‰LONGä¿¡å·ï¼‰'}
            
            # 3. æ³¢åŠ¨ç‡è¿‡æ»¤ï¼ˆé¿å…åœ¨æç«¯æ³¢åŠ¨æ—¶äº¤æ˜“ï¼‰
            try:
                # è·å–æœ€æ–°15m Kçº¿æ•°æ®æ¥è®¡ç®—æ³¢åŠ¨ç‡
                buffer_data = self.kline_buffers.get(symbol, {}).get('15m', [])
                if len(buffer_data) >= 20:
                    recent_closes = [k['close'] for k in buffer_data[-20:]]
                    returns = [(recent_closes[i] - recent_closes[i-1]) / recent_closes[i-1] 
                              for i in range(1, len(recent_closes))]
                    current_volatility = np.std(returns)
                    
                    # æ—¥æ³¢åŠ¨ç‡ä¼°ç®—ï¼ˆ15åˆ†é’Ÿ â†’ æ—¥ï¼Œå‡è®¾96ä¸ª15åˆ†é’Ÿå‘¨æœŸï¼‰
                    daily_volatility = current_volatility * np.sqrt(96)
                    
                    if daily_volatility > 0.08:  # æ—¥æ³¢åŠ¨ç‡>8%
                        return {'pass': False, 'reason': f'å¸‚åœºæ³¢åŠ¨è¿‡å¤§ (æ—¥æ³¢åŠ¨ç‡={daily_volatility*100:.2f}%)'}
                    
                    if daily_volatility < 0.005:  # æ—¥æ³¢åŠ¨ç‡<0.5%
                        return {'pass': False, 'reason': f'å¸‚åœºæ³¢åŠ¨è¿‡å° (æ—¥æ³¢åŠ¨ç‡={daily_volatility*100:.2f}%)'}
            except Exception as e:
                logger.debug(f"æ³¢åŠ¨ç‡è®¡ç®—å¤±è´¥ï¼ˆè·³è¿‡æ­¤è¿‡æ»¤ï¼‰: {e}")
            
            # 4. é‡èƒ½ç¡®è®¤ï¼ˆé«˜ç½®ä¿¡åº¦ä¿¡å·éœ€è¦é‡èƒ½é…åˆï¼‰
            if confidence > 0.6:  # é«˜ç½®ä¿¡åº¦ä¿¡å·
                try:
                    buffer_data = self.kline_buffers.get(symbol, {}).get('15m', [])
                    if len(buffer_data) >= 20:
                        recent_volumes = [k['volume'] for k in buffer_data[-20:]]
                        current_volume = buffer_data[-1]['volume']
                        avg_volume = np.mean(recent_volumes)
                        
                        # é«˜ç½®ä¿¡åº¦ä¿¡å·éœ€è¦é‡èƒ½è‡³å°‘è¾¾åˆ°å¹³å‡çš„70%
                        if current_volume < avg_volume * 0.7:
                            return {'pass': False, 'reason': f'é‡èƒ½ä¸è¶³ï¼ˆå½“å‰={current_volume:.0f}, å¹³å‡={avg_volume:.0f}ï¼‰'}
                except Exception as e:
                    logger.debug(f"é‡èƒ½æ£€æŸ¥å¤±è´¥ï¼ˆè·³è¿‡æ­¤è¿‡æ»¤ï¼‰: {e}")
            
            # 5. ä¿¡å·é¢‘ç‡é™åˆ¶ï¼ˆé¿å…è¿‡åº¦äº¤æ˜“ï¼‰
            # æ£€æŸ¥æœ€è¿‘1å°æ—¶å†…çš„ä¿¡å·æ•°é‡
            try:
                recent_signals = await self.get_recent_signals(symbol, hours=1, limit=10)
                if len(recent_signals) >= 5:  # 1å°æ—¶å†…è¶…è¿‡5ä¸ªä¿¡å·
                    return {'pass': False, 'reason': f'ä¿¡å·é¢‘ç‡è¿‡é«˜ï¼ˆ1å°æ—¶å†…å·²æœ‰{len(recent_signals)}ä¸ªä¿¡å·ï¼‰'}
            except Exception as e:
                logger.debug(f"ä¿¡å·é¢‘ç‡æ£€æŸ¥å¤±è´¥ï¼ˆè·³è¿‡æ­¤è¿‡æ»¤ï¼‰: {e}")
            
            # 6. æ‰€æœ‰è¿‡æ»¤å™¨é€šè¿‡
            logger.info(f"âœ… ä¿¡å·é€šè¿‡æ‰€æœ‰å¢å¼ºè¿‡æ»¤å™¨")
            return {'pass': True, 'reason': 'é€šè¿‡æ‰€æœ‰è¿‡æ»¤æ¡ä»¶'}
            
        except Exception as e:
            logger.error(f"ä¿¡å·è¿‡æ»¤å¤±è´¥: {e}")
            # è¿‡æ»¤å¤±è´¥æ—¶ä¿å®ˆå¤„ç†ï¼šé€šè¿‡ä¿¡å·ï¼ˆé¿å…é”™å¤±æœºä¼šï¼‰
            return {'pass': True, 'reason': 'è¿‡æ»¤å™¨å¼‚å¸¸ï¼Œé»˜è®¤é€šè¿‡'}
    
    def add_signal_callback(self, callback: callable):
        """æ·»åŠ ä¿¡å·å›è°ƒå‡½æ•°"""
        self.signal_callbacks.append(callback)
    
    def remove_signal_callback(self, callback: callable):
        """ç§»é™¤ä¿¡å·å›è°ƒå‡½æ•°"""
        if callback in self.signal_callbacks:
            self.signal_callbacks.remove(callback)
    
    async def force_generate_signal(self, symbol: str) -> Optional[TradingSignal]:
        """å¼ºåˆ¶ç”Ÿæˆä¿¡å·ï¼ˆç”¨äºæ‰‹åŠ¨è§¦å‘ï¼‰"""
        try:
            logger.info(f"å¼ºåˆ¶ç”Ÿæˆä¿¡å·: {symbol}")
            
            # ä¸´æ—¶ç§»é™¤æ—¶é—´é—´éš”é™åˆ¶
            original_interval = self.min_signal_interval
            self.min_signal_interval = 0
            
            signal = await self.generate_signal(symbol)
            
            # æ¢å¤æ—¶é—´é—´éš”é™åˆ¶
            self.min_signal_interval = original_interval
            
            if signal:
                await self._process_signal(signal)
            
            return signal
            
        except Exception as e:
            logger.error(f"å¼ºåˆ¶ç”Ÿæˆä¿¡å·å¤±è´¥: {e}")
            return None
    
    async def _load_warmup_state(self):
        """ä»RedisåŠ è½½é¢„çƒ­çŠ¶æ€ï¼ˆæŒä¹…åŒ–ï¼Œé¿å…é‡å¯/é‡è®­ç»ƒåé‡æ–°é¢„çƒ­ï¼‰"""
        try:
            from app.core.cache import cache_manager
            
            # ä»RedisåŠ è½½ä¿¡å·è®¡æ•°å™¨
            cached_counter = await cache_manager.get(f"warmup:signal_counter:{settings.SYMBOL}")
            
            if cached_counter is not None:
                self.signal_counter = int(cached_counter)
                logger.info(f"ğŸ“‚ å·²åŠ è½½é¢„çƒ­çŠ¶æ€: {self.signal_counter}/{self.warmup_signals} ä¸ªä¿¡å·")
                
                if self.signal_counter >= self.warmup_signals:
                    logger.info(f"âœ… é¢„çƒ­å·²åœ¨ä¹‹å‰å®Œæˆï¼Œç³»ç»Ÿå¤„äºæ­£å¸¸äº¤æ˜“æ¨¡å¼")
            else:
                logger.info(f"ğŸ“‚ é¦–æ¬¡éƒ¨ç½²ï¼Œåˆå§‹åŒ–é¢„çƒ­çŠ¶æ€: 0/{self.warmup_signals}")
                await self._save_warmup_state()
                
        except Exception as e:
            logger.warning(f"åŠ è½½é¢„çƒ­çŠ¶æ€å¤±è´¥ï¼ˆä½¿ç”¨é»˜è®¤å€¼0ï¼‰: {e}")
            self.signal_counter = 0
    
    async def _save_warmup_state(self):
        """ä¿å­˜é¢„çƒ­çŠ¶æ€åˆ°Redisï¼ˆæ— è¿‡æœŸæ—¶é—´ï¼Œæ°¸ä¹…ä¿å­˜ï¼‰"""
        try:
            from app.core.cache import cache_manager
            
            # ä¿å­˜ä¿¡å·è®¡æ•°å™¨åˆ°Redisï¼ˆä¸è¿‡æœŸï¼‰
            await cache_manager.set(
                f"warmup:signal_counter:{settings.SYMBOL}",
                self.signal_counter,
                expire=None  # æ°¸ä¸è¿‡æœŸ
            )
            logger.debug(f"ğŸ’¾ é¢„çƒ­çŠ¶æ€å·²ä¿å­˜: {self.signal_counter}/{self.warmup_signals}")
            
        except Exception as e:
            logger.warning(f"ä¿å­˜é¢„çƒ­çŠ¶æ€å¤±è´¥: {e}")