"""
è¶…å‚æ•°è‡ªåŠ¨ä¼˜åŒ–å™¨ - ä½¿ç”¨Optuna
"""

import logging
import gc
from typing import Dict, Any, Optional, List
from dataclasses import dataclass
from datetime import datetime
import numpy as np
import pandas as pd
import optuna
from optuna.samplers import TPESampler
import lightgbm as lgb
import xgboost as xgb
import catboost as cb
from sklearn.model_selection import TimeSeriesSplit
from sklearn.metrics import accuracy_score
from sklearn.utils.class_weight import compute_sample_weight
from sklearn.preprocessing import StandardScaler
import torch
import torch.nn as nn
from torch.utils.data import DataLoader, Dataset, TensorDataset
from torch.optim.lr_scheduler import ReduceLROnPlateau
from app.model.informer2_model import Informer2ForClassification
from app.model.gmadl_loss import create_trade_loss
from app.model.ml_service import MLService
from app.core.config import settings

# å¯é€‰ä¾èµ–ï¼šbitsandbytesï¼ˆ8-bitä¼˜åŒ–å™¨ï¼‰
try:
    import bitsandbytes as bnb
    BNB_AVAILABLE = True
except ImportError:
    BNB_AVAILABLE = False

logger = logging.getLogger(__name__)


@dataclass
class ScaleRecord:
    """Scaleç›‘æ§è®°å½•"""
    epoch: int
    batch: int
    scale_value: float
    has_overflow: bool
    consecutive_overflow_count: int
    timestamp: datetime


class DynamicGradScalerConfig:
    """
    åŠ¨æ€GradScaleré…ç½®å™¨
    
    æ ¹æ®æ¨¡å‹è§„æ¨¡å’Œè®­ç»ƒé˜¶æ®µåŠ¨æ€è°ƒæ•´GradScalerå‚æ•°
    """
    
    def __init__(self, model_param_count: int):
        """
        åˆå§‹åŒ–é…ç½®å™¨
        
        Args:
            model_param_count: æ¨¡å‹å‚æ•°é‡
        """
        self.model_param_count = model_param_count
        self.init_scale = self.calculate_init_scale(model_param_count)
        self.growth_factor = settings.GRAD_SCALER_GROWTH_FACTOR
        self.backoff_factor = 0.5
        self.growth_interval = settings.GRAD_SCALER_GROWTH_INTERVAL
        self.max_scale = settings.GRAD_SCALER_MAX_SCALE
        
        logger.info(f"ğŸ”§ GradScaleré…ç½®å™¨åˆå§‹åŒ–:")
        logger.info(f"   æ¨¡å‹å‚æ•°é‡: {model_param_count/1e6:.2f}M")
        logger.info(f"   åˆå§‹scale: {self.init_scale}")
        logger.info(f"   å¢é•¿å› å­: {self.growth_factor}")
        logger.info(f"   å¢é•¿é—´éš”: {self.growth_interval}")
        logger.info(f"   æœ€å¤§scaleé˜ˆå€¼: {self.max_scale}")
    
    @staticmethod
    def calculate_init_scale(param_count: int) -> float:
        """
        æ ¹æ®æ¨¡å‹å‚æ•°é‡è®¡ç®—åˆå§‹scale
        
        Args:
            param_count: æ¨¡å‹å‚æ•°é‡
        
        Returns:
            åˆå§‹scaleå€¼
        """
        if param_count > 10_000_000:  # >10Må‚æ•°ï¼šå¤§æ¨¡å‹
            init_scale = 2.**12  # 4096
            logger.debug(f"   æ£€æµ‹åˆ°å¤§æ¨¡å‹({param_count/1e6:.1f}Må‚æ•°)ï¼Œä½¿ç”¨init_scale=2^12={init_scale}")
        elif param_count > 1_000_000:  # 1M-10Må‚æ•°ï¼šä¸­ç­‰æ¨¡å‹
            init_scale = 2.**14  # 16384
            logger.debug(f"   æ£€æµ‹åˆ°ä¸­ç­‰æ¨¡å‹({param_count/1e6:.1f}Må‚æ•°)ï¼Œä½¿ç”¨init_scale=2^14={init_scale}")
        else:  # <1Må‚æ•°ï¼šå°æ¨¡å‹
            init_scale = 2.**16  # 65536
            logger.debug(f"   æ£€æµ‹åˆ°å°æ¨¡å‹({param_count/1e6:.1f}Må‚æ•°)ï¼Œä½¿ç”¨init_scale=2^16={init_scale}")
        
        return init_scale
    
    def create_scaler(self, device: str) -> torch.amp.GradScaler:
        """
        åˆ›å»ºé…ç½®å¥½çš„GradScaler
        
        Args:
            device: è®¾å¤‡ç±»å‹ï¼ˆ'cuda'æˆ–'cpu'ï¼‰
        
        Returns:
            é…ç½®å¥½çš„GradScalerå®ä¾‹
        """
        scaler = torch.amp.GradScaler(
            device,
            init_scale=self.init_scale,
            growth_factor=self.growth_factor,
            backoff_factor=self.backoff_factor,
            growth_interval=self.growth_interval,
            enabled=True
        )
        
        logger.info(f"âœ… GradScalerå·²åˆ›å»º (åˆå§‹scale={self.init_scale})")
        return scaler


class GradScalerMonitor:
    """
    GradScalerç›‘æ§å™¨
    
    ç›‘æ§scaleå€¼å˜åŒ–ï¼Œæ£€æµ‹å¼‚å¸¸å¹¶è§¦å‘è‡ªåŠ¨é‡ç½®
    """
    
    def __init__(self, scaler: torch.amp.GradScaler, init_scale: float):
        """
        åˆå§‹åŒ–ç›‘æ§å™¨
        
        Args:
            scaler: GradScalerå®ä¾‹
            init_scale: åˆå§‹scaleå€¼
        """
        self.scaler = scaler
        self.init_scale = init_scale
        self.scale_history: List[float] = []
        self.max_scale_threshold = settings.GRAD_SCALER_MAX_SCALE
        self.consecutive_overflow_count = 0
        self.max_consecutive_overflow = settings.GRAD_SCALER_MAX_CONSECUTIVE_OVERFLOW
        self.epoch_scale_records: Dict[int, float] = {}
        self.scale_records: List[ScaleRecord] = []
        self.abnormal_epoch_count = 0
        self.reset_threshold_epochs = settings.GRAD_SCALER_RESET_THRESHOLD_EPOCHS
        
        logger.info(f"ğŸ“Š GradScalerç›‘æ§å™¨åˆå§‹åŒ–:")
        logger.info(f"   æœ€å¤§scaleé˜ˆå€¼: {self.max_scale_threshold}")
        logger.info(f"   æœ€å¤§è¿ç»­æº¢å‡º: {self.max_consecutive_overflow}")
        logger.info(f"   é‡ç½®é˜ˆå€¼epochæ•°: {self.reset_threshold_epochs}")
    
    def record_scale(self, epoch: int, batch: int) -> bool:
        """
        è®°å½•å½“å‰scaleå€¼
        
        Args:
            epoch: å½“å‰epoch
            batch: å½“å‰batch
        
        Returns:
            æ˜¯å¦è¶…è¿‡é˜ˆå€¼
        """
        current_scale = self.scaler.get_scale()
        self.scale_history.append(current_scale)
        
        if epoch not in self.epoch_scale_records:
            self.epoch_scale_records[epoch] = current_scale
        
        # æ£€æŸ¥æ˜¯å¦è¶…è¿‡é˜ˆå€¼
        if current_scale > self.max_scale_threshold:
            logger.warning(f"âš ï¸ Epoch {epoch} Batch {batch}: Scaleå€¼è¿‡å¤§ ({current_scale:.2f} > {self.max_scale_threshold})")
            return True
        
        return False
    
    def check_overflow(self, has_overflow: bool, epoch: int, batch: int) -> bool:
        """
        æ£€æŸ¥æ¢¯åº¦æº¢å‡º
        
        Args:
            has_overflow: æ˜¯å¦å‘ç”Ÿæº¢å‡º
            epoch: å½“å‰epoch
            batch: å½“å‰batch
        
        Returns:
            æ˜¯å¦éœ€è¦é‡ç½®scale
        """
        if has_overflow:
            self.consecutive_overflow_count += 1
            
            # è®°å½•æº¢å‡º
            record = ScaleRecord(
                epoch=epoch,
                batch=batch,
                scale_value=self.scaler.get_scale(),
                has_overflow=True,
                consecutive_overflow_count=self.consecutive_overflow_count,
                timestamp=datetime.now()
            )
            self.scale_records.append(record)
            
            if self.consecutive_overflow_count >= self.max_consecutive_overflow:
                logger.error(f"âŒ Epoch {epoch} Batch {batch}: è¿ç»­{self.consecutive_overflow_count}æ¬¡æ¢¯åº¦æº¢å‡º")
                return True
        else:
            self.consecutive_overflow_count = 0
        
        return False
    
    def check_epoch_abnormal(self, epoch: int) -> bool:
        """
        æ£€æŸ¥epochçº§åˆ«çš„å¼‚å¸¸
        
        Args:
            epoch: å½“å‰epoch
        
        Returns:
            æ˜¯å¦éœ€è¦é‡ç½®scale
        """
        if epoch in self.epoch_scale_records:
            scale = self.epoch_scale_records[epoch]
            if scale > self.max_scale_threshold:
                self.abnormal_epoch_count += 1
                logger.warning(f"âš ï¸ Epoch {epoch}: å¼‚å¸¸epochè®¡æ•° {self.abnormal_epoch_count}/{self.reset_threshold_epochs}")
                
                if self.abnormal_epoch_count >= self.reset_threshold_epochs:
                    logger.error(f"âŒ è¿ç»­{self.abnormal_epoch_count}ä¸ªepochçš„scaleå¼‚å¸¸")
                    return True
            else:
                self.abnormal_epoch_count = 0
        
        return False
    
    def reset_scale(self, reset_to_percent: float = 0.5):
        """
        é‡ç½®scaleå€¼
        
        Args:
            reset_to_percent: é‡ç½®åˆ°åˆå§‹å€¼çš„ç™¾åˆ†æ¯”
        """
        current_scale = self.scaler.get_scale()
        new_scale = self.init_scale * reset_to_percent
        
        # ç›´æ¥ä¿®æ”¹scalerçš„å†…éƒ¨scaleå€¼
        self.scaler._scale = torch.tensor(new_scale).to(self.scaler._scale.device)
        
        # é‡ç½®è®¡æ•°å™¨
        self.consecutive_overflow_count = 0
        self.abnormal_epoch_count = 0
        
        logger.warning(f"ğŸ”„ Scaleå·²é‡ç½®: {current_scale:.2f} -> {new_scale:.2f} (åˆå§‹å€¼çš„{reset_to_percent*100:.0f}%)")
    
    def get_statistics(self) -> Dict[str, Any]:
        """
        è·å–ç›‘æ§ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        if not self.scale_history:
            return {
                'current_scale': self.scaler.get_scale(),
                'min_scale': 0,
                'max_scale': 0,
                'avg_scale': 0,
                'consecutive_overflow': self.consecutive_overflow_count,
                'abnormal_epoch_count': self.abnormal_epoch_count,
                'epoch_records': self.epoch_scale_records
            }
        
        return {
            'current_scale': self.scaler.get_scale(),
            'min_scale': min(self.scale_history),
            'max_scale': max(self.scale_history),
            'avg_scale': sum(self.scale_history) / len(self.scale_history),
            'consecutive_overflow': self.consecutive_overflow_count,
            'abnormal_epoch_count': self.abnormal_epoch_count,
            'epoch_records': self.epoch_scale_records,
            'total_records': len(self.scale_records),
            'overflow_count': sum(1 for r in self.scale_records if r.has_overflow)
        }


class HyperparameterOptimizer:
    """
    è¶…å‚æ•°è‡ªåŠ¨ä¼˜åŒ–å™¨
    
    ä½¿ç”¨Optunaçš„TPEï¼ˆTree-structured Parzen Estimatorï¼‰ç®—æ³•
    è‡ªåŠ¨æœç´¢æœ€ä½³è¶…å‚æ•°ç»„åˆ
    """
    
    def __init__(
        self,
        X: np.ndarray,
        y: pd.Series,
        timeframe: str,
        model_type: str = "lightgbm",
        use_gpu: bool = True
    ):
        """
        åˆå§‹åŒ–ä¼˜åŒ–å™¨
        
        Args:
            X: ç‰¹å¾æ•°æ®ï¼ˆå·²ç¼©æ”¾ï¼‰
            y: æ ‡ç­¾æ•°æ®
        timeframe: æ—¶é—´æ¡†æ¶ï¼ˆ3m/5m/15mï¼‰
            model_type: æ¨¡å‹ç±»å‹ï¼ˆlightgbm/xgboost/catboostï¼‰
            use_gpu: æ˜¯å¦ä½¿ç”¨GPUåŠ é€Ÿ
        """
        self.X = X
        self.y = y
        self.timeframe = timeframe
        self.model_type = model_type
        self.use_gpu = use_gpu
        self.best_params: Optional[Dict[str, Any]] = None
        self.best_score: float = 0.0
        
        # HOLDæƒ©ç½šç³»æ•°ï¼ˆä¸è®­ç»ƒä¿æŒä¸€è‡´ï¼‰
        self.hold_penalty = 0.65
        
        logger.info(f"ğŸ”§ åˆå§‹åŒ–è¶…å‚æ•°ä¼˜åŒ–å™¨: {timeframe} - {model_type}")
        if len(X.shape) == 3:
            logger.info(f"   æ ·æœ¬æ•°: {len(X)}, åºåˆ—é•¿åº¦: {X.shape[1]}, ç‰¹å¾æ•°: {X.shape[2]}")
        else:
            logger.info(f"   æ ·æœ¬æ•°: {len(X)}, ç‰¹å¾æ•°: {X.shape[1]}")
        logger.info(f"   GPUåŠ é€Ÿ: {'å¯ç”¨' if use_gpu else 'å…³é—­'}")
    
    def clear_gpu_memory(self):
        """
        ç»Ÿä¸€GPUå†…å­˜æ¸…ç†æ–¹æ³•
        
        åŠŸèƒ½ï¼š
        - æ¸…ç©ºPyTorchç¼“å­˜
        - åŒæ­¥GPUæ“ä½œ
        - å¼ºåˆ¶åƒåœ¾å›æ”¶
        - è®°å½•æ¸…ç†çŠ¶æ€
        """
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            torch.cuda.synchronize()
            gc.collect()
            
            # è®°å½•GPUå†…å­˜çŠ¶æ€
            gpu_memory = torch.cuda.get_device_properties(0).total_memory
            gpu_used = torch.cuda.memory_allocated(0)
            gpu_free = gpu_memory - gpu_used
            logger.debug(f"ğŸ§¹ GPUå†…å­˜å·²æ¸…ç† (ä½¿ç”¨: {gpu_used/1024**3:.1f}GB, å¯ç”¨: {gpu_free/1024**3:.1f}GB)")
        else:
            logger.debug("ğŸ§¹ CPUæ¨¡å¼ï¼Œæ— éœ€æ¸…ç†GPUå†…å­˜")
    
    def monitor_gpu_memory(self):
        """
        ç›‘æ§GPUå†…å­˜ä½¿ç”¨æƒ…å†µ
        
        Returns:
            Dict: GPUå†…å­˜çŠ¶æ€ä¿¡æ¯
        """
        if torch.cuda.is_available():
            gpu_memory = torch.cuda.get_device_properties(0).total_memory
            gpu_used = torch.cuda.memory_allocated(0)
            gpu_free = gpu_memory - gpu_used
            gpu_reserved = torch.cuda.memory_reserved(0)
            
            return {
                'total': gpu_memory,
                'used': gpu_used,
                'free': gpu_free,
                'reserved': gpu_reserved,
                'usage_percent': (gpu_used / gpu_memory) * 100
            }
        else:
            return {'error': 'GPUä¸å¯ç”¨'}
    
    def _get_lightgbm_search_space(self, trial: optuna.Trial) -> Dict[str, Any]:
        """
        LightGBMæœç´¢ç©ºé—´
        
        æ ¹æ®æ—¶é—´æ¡†æ¶å·®å¼‚åŒ–é…ç½®æœç´¢èŒƒå›´
        """
        # åŸºç¡€å‚æ•°
        base_params = {}
        
        if self.timeframe == "15m":
            # 15m: æ ·æœ¬å¤šï¼Œå¯ä»¥å¤æ‚ä¸€äº›
            base_params = {
                'n_estimators': trial.suggest_int('n_estimators', 200, 500),
                'max_depth': trial.suggest_int('max_depth', 6, 12),
                'num_leaves': trial.suggest_int('num_leaves', 63, 127),
                'learning_rate': trial.suggest_float('learning_rate', 0.02, 0.1, log=True),
                'min_child_samples': trial.suggest_int('min_child_samples', 20, 50),
                'subsample': trial.suggest_float('subsample', 0.6, 0.9),
                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 0.9),
                'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 0.5),
                'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 0.5),
                'min_split_gain': trial.suggest_float('min_split_gain', 0.0, 0.1),
                'random_state': 42,
                'verbose': -1,
                'force_col_wise': True
            }
        else:
            # 3m/5m ç®€åŒ–æœç´¢ï¼ˆä¸15måŒºåˆ†ï¼‰
            base_params = {
                'n_estimators': trial.suggest_int('n_estimators', 120, 320),
                'max_depth': trial.suggest_int('max_depth', 4, 8),
                'num_leaves': trial.suggest_int('num_leaves', 31, 63),
                'learning_rate': trial.suggest_float('learning_rate', 0.03, 0.12, log=True),
                'min_child_samples': trial.suggest_int('min_child_samples', 30, 70),
                'subsample': trial.suggest_float('subsample', 0.6, 0.85),
                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 0.85),
                'reg_alpha': trial.suggest_float('reg_alpha', 0.3, 1.0),
                'reg_lambda': trial.suggest_float('reg_lambda', 0.3, 1.0),
                'min_split_gain': trial.suggest_float('min_split_gain', 0.0, 0.2),
                'random_state': 42,
                'verbose': -1,
                'force_col_wise': True
            }
        
        # ğŸ® GPUåŠ é€Ÿï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if self.use_gpu:
            base_params['device'] = 'gpu'
            base_params['gpu_platform_id'] = 0
            base_params['gpu_device_id'] = 0
        
        # ğŸ”‘ æ·»åŠ å›ºå®šå‚æ•°ï¼ˆå¤šåˆ†ç±»ä»»åŠ¡ï¼‰
        base_params['objective'] = 'multiclass'
        base_params['num_class'] = 3
        base_params['metric'] = 'multi_logloss'
        base_params['boosting_type'] = 'gbdt'
        
        return base_params
    
    def _get_xgboost_search_space(self, trial: optuna.Trial) -> Dict[str, Any]:
        """XGBoostæœç´¢ç©ºé—´"""
        if self.timeframe == "15m":
            base_params = {
                'n_estimators': trial.suggest_int('n_estimators', 200, 500),
                'max_depth': trial.suggest_int('max_depth', 4, 8),
                'learning_rate': trial.suggest_float('learning_rate', 0.02, 0.1, log=True),
                'subsample': trial.suggest_float('subsample', 0.6, 0.9),
                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 0.9),
                'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 0.5),
                'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 0.5),
                'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),
                'random_state': 42,
                'verbosity': 0
            }
        else:
            # 3m/5m ç®€åŒ–
            base_params = {
                'n_estimators': trial.suggest_int('n_estimators', 100, 250),
                'max_depth': trial.suggest_int('max_depth', 2, 5),
                'learning_rate': trial.suggest_float('learning_rate', 0.05, 0.2, log=True),
                'subsample': trial.suggest_float('subsample', 0.6, 0.8),
                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 0.8),
                'reg_alpha': trial.suggest_float('reg_alpha', 0.5, 1.2),
                'reg_lambda': trial.suggest_float('reg_lambda', 0.5, 1.2),
                'min_child_weight': trial.suggest_int('min_child_weight', 3, 10),
                'random_state': 42,
                'verbosity': 0
            }
        
        # ğŸ® GPUåŠ é€Ÿï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if self.use_gpu:
            base_params['tree_method'] = 'hist'  # æ–°ç‰ˆæœ¬ä½¿ç”¨ hist
            base_params['device'] = 'cuda'  # ä½¿ç”¨ device å‚æ•°æŒ‡å®š GPU
        else:
            base_params['tree_method'] = 'hist'
        
        # ğŸ”‘ æ·»åŠ å›ºå®šå‚æ•°ï¼ˆå¤šåˆ†ç±»ä»»åŠ¡ï¼‰
        base_params['objective'] = 'multi:softprob'
        base_params['num_class'] = 3
        base_params['eval_metric'] = 'mlogloss'
        
        return base_params
    
    def _get_catboost_search_space(self, trial: optuna.Trial) -> Dict[str, Any]:
        """CatBoostæœç´¢ç©ºé—´"""
        if self.timeframe == "15m":
            base_params = {
                'iterations': trial.suggest_int('iterations', 200, 500),
                'depth': trial.suggest_int('depth', 4, 8),
                'learning_rate': trial.suggest_float('learning_rate', 0.02, 0.1, log=True),
                'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1.0, 5.0),
                'border_count': trial.suggest_int('border_count', 32, 128),
                'random_state': 42,
                'verbose': False,
                'allow_writing_files': False  # ç¦ç”¨è¾“å‡ºæ–‡ä»¶
            }
        else:
            # 3m/5m ç®€åŒ–
            base_params = {
                'iterations': trial.suggest_int('iterations', 100, 250),
                'depth': trial.suggest_int('depth', 2, 5),
                'learning_rate': trial.suggest_float('learning_rate', 0.05, 0.2, log=True),
                'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 3.0, 10.0),
                'border_count': trial.suggest_int('border_count', 32, 64),
                'random_state': 42,
                'verbose': False,
                'allow_writing_files': False  # ç¦ç”¨è¾“å‡ºæ–‡ä»¶
            }
        
        # ğŸ® GPUåŠ é€Ÿï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if self.use_gpu:
            base_params['task_type'] = 'GPU'
            base_params['devices'] = '0'
        
        # ğŸ”‘ æ·»åŠ å›ºå®šå‚æ•°ï¼ˆå¤šåˆ†ç±»ä»»åŠ¡ï¼‰
        base_params['loss_function'] = 'MultiClass'
        
        return base_params
    
    def _get_informer2_search_space(self, trial: optuna.Trial) -> Dict[str, Any]:
        """Informer-2æœç´¢ç©ºé—´ï¼ˆåŸºäºTransformerç†è®ºçš„æœ€ä½³å®è·µ + ç²¾ç¡®å¤æ‚åº¦åŒ¹é…ï¼‰"""
        
        # ğŸ”‘ åºåˆ—é•¿åº¦é…ç½®ï¼ˆä¸ensemble_ml_service.pyä¿æŒä¸€è‡´ï¼‰
        # ğŸ¯ ä¼˜åŒ–ï¼šå‡å°‘åºåˆ—é•¿åº¦ä»¥é™ä½å†…å­˜å ç”¨ï¼ˆå‡å°‘80-90%ï¼‰
        seq_len_config = {
            '3m': 96,   # 96 Ã— 3åˆ†é’Ÿ = 4.8å°æ—¶ï¼ˆè¶³å¤ŸçŸ­æœŸæ¨¡å¼è¯†åˆ«ï¼‰
            '5m': 96,   # 96 Ã— 5åˆ†é’Ÿ = 8å°æ—¶ï¼ˆä¸»æ—¶é—´æ¡†æ¶ï¼‰
            '15m': 64   # 64 Ã— 15åˆ†é’Ÿ = 16å°æ—¶ï¼ˆè¶‹åŠ¿ç¡®è®¤ï¼‰
        }
        
        seq_len = seq_len_config.get(self.timeframe, 96)
        
        # ğŸ¯ åŸºäºTransformerç†è®ºçš„æœ€ä½³å®è·µ
        # 1. d_modelä¸åºåˆ—é•¿åº¦çš„å…³ç³»ï¼šd_model â‰ˆ sqrt(seq_len) * 8-16
        # 2. n_headsä¸d_modelçš„å…³ç³»ï¼šn_heads = d_model / 64 (æ ‡å‡†æ¯”ä¾‹)
        # 3. n_layersä¸åºåˆ—é•¿åº¦çš„å…³ç³»ï¼šn_layers â‰ˆ log2(seq_len) + 1
        
        if self.timeframe == "15m":
            # 15m: çŸ­åºåˆ—(64)ï¼Œç²¾ç¡®å¤æ‚åº¦åŒ¹é…
            # d_model = sqrt(64) * 12 â‰ˆ 96 â†’ 128
            # n_heads = 128 / 64 = 2 â†’ 4,8 (æ¸è¿›å¼æœç´¢)
            # n_layers = log2(64) + 1 â‰ˆ 7 â†’ 2,3 (æ¸è¿›å¼æœç´¢)
            # ğŸ”¥ ä¿®å¤ï¼šé™ä½å­¦ä¹ ç‡ä¸Šé™ï¼Œé¿å…æ¢¯åº¦çˆ†ç‚¸å¯¼è‡´nan/inf
            base_params = {
                'd_model': trial.suggest_categorical('d_model', [128, 256]),      # ç²¾ç¡®åŒ¹é…
                'n_heads': trial.suggest_categorical('n_heads', [4, 8]),          # ç²¾ç¡®åŒ¹é…
                'n_layers': trial.suggest_int('n_layers', 2, 3),  # ç²¾ç¡®åŒ¹é…
                'epochs': trial.suggest_int('epochs', 20, 40),
                'batch_size': trial.suggest_categorical('batch_size', [128, 256, 512]),
                'lr': trial.suggest_float('lr', 0.0001, 0.002, log=True),  # é™ä½ä¸Šé™: 0.005â†’0.002
                'dropout': trial.suggest_float('dropout', 0.05, 0.2),
                'alpha': trial.suggest_float('alpha', 0.5, 2.0),  # GMADLå‚æ•°
                'beta': trial.suggest_float('beta', 0.3, 0.7)    # GMADLå‚æ•°
            }
        else:
            # 3m/5mï¼šä¸­åºåˆ—(96)
            # ğŸ”¥ ä¿®å¤ï¼šé™ä½å­¦ä¹ ç‡ä¸Šé™ï¼Œé¿å…æ¢¯åº¦çˆ†ç‚¸å¯¼è‡´nan/inf
            base_params = {
                'd_model': trial.suggest_categorical('d_model', [64, 128]),
                'n_heads': trial.suggest_categorical('n_heads', [2, 4, 8]),
                'n_layers': trial.suggest_int('n_layers', 1, 2),
                'epochs': trial.suggest_int('epochs', 10, 30),
                'batch_size': trial.suggest_categorical('batch_size', [64, 128, 256]),
                'lr': trial.suggest_float('lr', 0.0001, 0.002, log=True),  # é™ä½ä¸Šé™: 0.006â†’0.002
                'dropout': trial.suggest_float('dropout', 0.1, 0.3),
                'alpha': trial.suggest_float('alpha', 0.8, 1.8),
                'beta': trial.suggest_float('beta', 0.4, 0.6)
            }
        
        # æ·»åŠ åºåˆ—é•¿åº¦ä¿¡æ¯åˆ°å‚æ•°ä¸­ï¼ˆç”¨äºæ—¥å¿—è®°å½•ï¼‰
        base_params['seq_len'] = seq_len
        
        return base_params
    
    def objective(self, trial: optuna.Trial) -> float:
        """
        ä¼˜åŒ–ç›®æ ‡å‡½æ•°
        
        ä½¿ç”¨5æŠ˜æ—¶é—´åºåˆ—äº¤å‰éªŒè¯è¯„ä¼°è¶…å‚æ•°ç»„åˆ
        
        Args:
            trial: Optunaè¯•éªŒå¯¹è±¡
        
        Returns:
            è´Ÿçš„CVå¹³å‡å‡†ç¡®ç‡ï¼ˆOptunaé»˜è®¤æœ€å°åŒ–ï¼‰
        """
        # âœ… è¯¦ç»†æ—¥å¿—ï¼šè®°å½•Trialå¼€å§‹ä¿¡æ¯
        logger.info(f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
        logger.info(f"ğŸš€ å¼€å§‹Trial {trial.number} - æ¨¡å‹ç±»å‹: {self.model_type}, æ—¶é—´æ¡†æ¶: {self.timeframe}")
        logger.info(f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
        
        # è·å–æœç´¢ç©ºé—´
        try:
        if self.model_type == "lightgbm":
            params = self._get_lightgbm_search_space(trial)
        elif self.model_type == "xgboost":
            params = self._get_xgboost_search_space(trial)
        elif self.model_type == "catboost":
            params = self._get_catboost_search_space(trial)
        elif self.model_type == "informer2":
            params = self._get_informer2_search_space(trial)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹: {self.model_type}")
            
            # âœ… è¯¦ç»†æ—¥å¿—ï¼šè®°å½•æ‰€æœ‰è¶…å‚æ•°
            logger.info(f"ğŸ“‹ Trial {trial.number} è¶…å‚æ•°é…ç½®:")
            for key, value in params.items():
                if isinstance(value, float):
                    logger.info(f"   {key}: {value:.6f}")
                else:
                    logger.info(f"   {key}: {value}")
        except Exception as e:
            logger.error(f"âŒ Trial {trial.number}: è·å–æœç´¢ç©ºé—´å¤±è´¥: {e}")
            logger.error(f"   é”™è¯¯ç±»å‹: {type(e).__name__}")
            import traceback
            logger.error(f"   å †æ ˆè·Ÿè¸ª:\n{traceback.format_exc()}")
            raise
        
        # âœ… è¯¦ç»†æ—¥å¿—ï¼šè®°å½•è¾“å…¥æ•°æ®åŸºæœ¬ä¿¡æ¯
        n_samples = len(self.X) if isinstance(self.X, np.ndarray) else self.X.shape[0]
        logger.info(f"ğŸ“Š Trial {trial.number} è¾“å…¥æ•°æ®ç»Ÿè®¡:")
        logger.info(f"   æ€»æ ·æœ¬æ•°: {n_samples}")
        logger.info(f"   æ•°æ®å½¢çŠ¶: {self.X.shape}")
        logger.info(f"   æ•°æ®ç±»å‹: {type(self.X).__name__}, dtype: {self.X.dtype}")
        if isinstance(self.X, np.ndarray):
            logger.info(f"   æ•°æ®èŒƒå›´: [{self.X.min():.4f}, {self.X.max():.4f}]")
            logger.info(f"   æ•°æ®å‡å€¼: {self.X.mean():.4f}, æ ‡å‡†å·®: {self.X.std():.4f}")
            nan_count = np.isnan(self.X).sum()
            inf_count = np.isinf(self.X).sum()
            if nan_count > 0 or inf_count > 0:
                logger.warning(f"   âš ï¸ è¾“å…¥æ•°æ®åŒ…å«å¼‚å¸¸å€¼: NaN={nan_count}, INF={inf_count}")
        
        # æ—¶é—´åºåˆ—5æŠ˜äº¤å‰éªŒè¯
        tscv = TimeSeriesSplit(n_splits=5)
        cv_scores = []
        fold_fail_count = 0
        
        # ğŸ”‘ ä¿®å¤ï¼šå¯¹äº3Dåºåˆ—è¾“å…¥ï¼Œéœ€è¦åŸºäºæ ·æœ¬æ•°é‡è€Œä¸æ˜¯ç‰¹å¾è¿›è¡Œåˆ†å‰²
        
        for fold_idx, (train_idx, val_idx) in enumerate(tscv.split(np.arange(n_samples))):
            # âœ… è¯¦ç»†æ—¥å¿—ï¼šè®°å½•Foldå¼€å§‹ä¿¡æ¯
            logger.info(f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
            logger.info(f"ğŸ“¦ Trial {trial.number} Fold {fold_idx+1}/5 å¼€å§‹å¤„ç†...")
            logger.info(f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
            logger.debug(f"   è®­ç»ƒç´¢å¼•èŒƒå›´: [{train_idx.min()}, {train_idx.max()}], æ•°é‡: {len(train_idx)}")
            logger.debug(f"   éªŒè¯ç´¢å¼•èŒƒå›´: [{val_idx.min()}, {val_idx.max()}], æ•°é‡: {len(val_idx)}")
            
            # ğŸ”¥ å…³é”®ä¿®å¤ï¼šç¡®ä¿ç´¢å¼•è½¬æ¢ä¸ºnumpyæ•°ç»„ï¼ˆå…¼å®¹å†…å­˜æ˜ å°„ï¼‰
            train_idx = np.asarray(train_idx)
            val_idx = np.asarray(val_idx)
            
            # ğŸ”¥ å…³é”®ä¿®å¤ï¼šå¯¹äºå†…å­˜æ˜ å°„æ•°ç»„ï¼Œéœ€è¦å¤åˆ¶æ•°æ®åˆ°å†…å­˜
            if hasattr(self.X, 'filename') and self.X.filename:
                # å†…å­˜æ˜ å°„æ•°ç»„ï¼šå¤åˆ¶åˆ°å†…å­˜
                X_train = np.array(self.X[train_idx], dtype=np.float32)
                X_val = np.array(self.X[val_idx], dtype=np.float32)
            else:
                # æ™®é€šæ•°ç»„ï¼šç›´æ¥åˆ‡ç‰‡
                X_train, X_val = self.X[train_idx], self.X[val_idx]
            
            # ğŸ”‘ ä¿®å¤ï¼šç»Ÿä¸€è½¬æ¢ä¸ºnumpyæ•°ç»„ï¼ˆå…¼å®¹pandas Serieså’Œnumpyæ•°ç»„ï¼‰
            if isinstance(self.y, pd.Series):
                y_train = self.y.iloc[train_idx].values
                y_val = self.y.iloc[val_idx].values
            elif isinstance(self.y, np.ndarray):
                if hasattr(self.y, 'filename') and self.y.filename:
                    # å†…å­˜æ˜ å°„æ•°ç»„ï¼šå¤åˆ¶åˆ°å†…å­˜
                    y_train = np.array(self.y[train_idx], dtype=np.int64)
                    y_val = np.array(self.y[val_idx], dtype=np.int64)
                else:
                    y_train, y_val = self.y[train_idx], self.y[val_idx]
            else:
                # å…¶ä»–ç±»å‹ï¼šå°è¯•è½¬æ¢
                y_train = np.asarray(self.y)[train_idx]
                y_val = np.asarray(self.y)[val_idx]
            
            # âœ… è¯¦ç»†è¯Šæ–­ï¼šæ£€æŸ¥æ•°æ®åˆ†å‰²åçš„æƒ…å†µï¼ˆInformer2ä¸“ç”¨ï¼‰
            if self.model_type == "informer2":
                logger.info(f"ğŸ“Š Trial {trial.number} Fold {fold_idx+1}/5 æ•°æ®åˆ†å‰²ç»Ÿè®¡:")
                logger.info(f"   è®­ç»ƒé›†å½¢çŠ¶: {X_train.shape}, éªŒè¯é›†å½¢çŠ¶: {X_val.shape}")
                logger.info(f"   è®­ç»ƒæ ‡ç­¾å½¢çŠ¶: {y_train.shape}, éªŒè¯æ ‡ç­¾å½¢çŠ¶: {y_val.shape}")
                
                # è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯
                logger.debug(f"   è®­ç»ƒé›†ç»Ÿè®¡:")
                logger.debug(f"      æ•°æ®ç±»å‹: {X_train.dtype}, å†…å­˜å ç”¨: {X_train.nbytes / 1024**2:.2f} MB")
                logger.debug(f"      æ•°æ®èŒƒå›´: [{X_train.min():.4f}, {X_train.max():.4f}]")
                logger.debug(f"      æ•°æ®å‡å€¼: {X_train.mean():.4f}, æ ‡å‡†å·®: {X_train.std():.4f}")
                logger.debug(f"   æ ‡ç­¾ç»Ÿè®¡:")
                unique_labels, counts = np.unique(y_train, return_counts=True)
                label_dist = dict(zip(unique_labels, counts))
                logger.debug(f"      æ ‡ç­¾åˆ†å¸ƒ: {label_dist}")
                logger.debug(f"      æ ‡ç­¾èŒƒå›´: [{y_train.min()}, {y_train.max()}]")
                
                # æ£€æŸ¥åˆ†å‰²åæ•°æ®æ˜¯å¦ä¸ºç©º
                if len(X_train) == 0 or len(y_train) == 0:
                    logger.error(f"âŒ Trial {trial.number} Fold {fold_idx+1}: æ•°æ®åˆ†å‰²åè®­ç»ƒé›†ä¸ºç©ºï¼")
                    logger.error(f"   è®­ç»ƒé›†å½¢çŠ¶: {X_train.shape}, æ ‡ç­¾å½¢çŠ¶: {y_train.shape}")
                    logger.error(f"   è®­ç»ƒç´¢å¼•: {train_idx[:10]}..." if len(train_idx) > 10 else f"   è®­ç»ƒç´¢å¼•: {train_idx}")
                    raise ValueError(f"Fold {fold_idx+1}è®­ç»ƒé›†ä¸ºç©º")
                
                if len(X_val) == 0 or len(y_val) == 0:
                    logger.error(f"âŒ Trial {trial.number} Fold {fold_idx+1}: æ•°æ®åˆ†å‰²åéªŒè¯é›†ä¸ºç©ºï¼")
                    logger.error(f"   éªŒè¯é›†å½¢çŠ¶: {X_val.shape}, æ ‡ç­¾å½¢çŠ¶: {y_val.shape}")
                    logger.error(f"   éªŒè¯ç´¢å¼•: {val_idx[:10]}..." if len(val_idx) > 10 else f"   éªŒè¯ç´¢å¼•: {val_idx}")
                    raise ValueError(f"Fold {fold_idx+1}éªŒè¯é›†ä¸ºç©º")
                
                # æ£€æŸ¥æ•°æ®ç»´åº¦
                if len(X_train.shape) != 3:
                    logger.error(f"âŒ Trial {trial.number} Fold {fold_idx+1}: è®­ç»ƒæ•°æ®ç»´åº¦é”™è¯¯ï¼")
                    logger.error(f"   æœŸæœ›3D (n_samples, seq_len, n_features), å®é™…: {X_train.shape}")
                    logger.error(f"   åŸå§‹æ•°æ®å½¢çŠ¶: {self.X.shape}")
                    logger.error(f"   è®­ç»ƒç´¢å¼•æ•°é‡: {len(train_idx)}")
                    raise ValueError(f"è®­ç»ƒæ•°æ®ç»´åº¦é”™è¯¯: {X_train.shape}ï¼ŒæœŸæœ›3D")
                
                # æ£€æŸ¥åºåˆ—é•¿åº¦å’Œç‰¹å¾æ•°
                seq_len = X_train.shape[1]
                n_features = X_train.shape[2]
                logger.info(f"   åºåˆ—é•¿åº¦: {seq_len}, ç‰¹å¾æ•°: {n_features}")
                if seq_len != params.get('seq_len', 96):
                    logger.warning(f"   âš ï¸ åºåˆ—é•¿åº¦ä¸åŒ¹é…: æ•°æ®={seq_len}, å‚æ•°={params.get('seq_len', 96)}")
            
            # è®¡ç®—æ ·æœ¬æƒé‡ï¼ˆæœ‰æ•ˆæ ·æœ¬æ•° Ã— æ—¶é—´è¡°å‡ Ã— HOLDæƒ©ç½šï¼‰
            try:
                temp_svc = MLService()
                class_weights = temp_svc._compute_effective_sample_weights(y_train, self.timeframe)
            except Exception:
                class_weights = compute_sample_weight('balanced', y_train)
            # âœ… æ·»åŠ æ—¶é—´è¡°å‡æƒé‡ï¼ˆä¸åŸºç¡€æ¨¡å‹è®­ç»ƒä¿æŒä¸€è‡´ï¼‰
            time_decay = np.exp(-np.arange(len(X_train)) / (len(X_train) * 0.1))[::-1]
            # HOLDæƒ©ç½šè‡ªé€‚åº”
            hold_ratio_tmp = float((y_train == 1).sum()) / max(len(y_train), 1)
            if self.timeframe == '3m':
                hold_weight_tmp = float(max(0.35, min(0.70, 0.80 - 0.6 * hold_ratio_tmp)))
            else:
                hold_weight_tmp = float(max(0.50, min(0.75, 0.85 - 0.5 * hold_ratio_tmp)))
            hold_penalty_weights = np.where(y_train == 1, hold_weight_tmp, 1.0)
            sample_weights = class_weights * time_decay * hold_penalty_weights
            
            # è®­ç»ƒæ¨¡å‹
            try:
                # ğŸ® ç»Ÿä¸€GPUå†…å­˜ç®¡ç†ï¼šè®­ç»ƒå‰æ¸…ç†
                self.clear_gpu_memory()
                
                if self.model_type == "lightgbm":
                    try:
                        model = lgb.LGBMClassifier(**params)
                        # æ·»åŠ éªŒè¯é›†å’Œæ—©åœæœºåˆ¶
                        callbacks = [lgb.early_stopping(stopping_rounds=100, verbose=0)]
                        model.fit(
                            X_train, y_train,
                            sample_weight=sample_weights,
                            eval_set=[(X_val, y_val)],
                            callbacks=callbacks
                        )
                        
                        # ğŸ® ç»Ÿä¸€GPUå†…å­˜ç®¡ç†ï¼šè®­ç»ƒåæ¸…ç†
                        self.clear_gpu_memory()
                            
                    except Exception as e:
                        logger.error(f"âŒ LightGBMè®­ç»ƒå¤±è´¥: {e}")
                        # é™çº§åˆ°CPU
                        params['device'] = 'cpu'
                        model = lgb.LGBMClassifier(**params)
                        # æ·»åŠ éªŒè¯é›†å’Œæ—©åœæœºåˆ¶
                        callbacks = [lgb.early_stopping(stopping_rounds=100, verbose=0)]
                        model.fit(
                            X_train, y_train,
                            sample_weight=sample_weights,
                            eval_set=[(X_val, y_val)],
                            callbacks=callbacks
                        )
                        self.clear_gpu_memory()
                
                elif self.model_type == "xgboost":
                    try:
                        # ğŸ”‘ XGBoost 2.0+ APIå˜æ›´ï¼šcallbacksä¸èƒ½ä¼ å…¥fit()ï¼Œåªèƒ½åœ¨æ„é€ å‡½æ•°ä¸­é…ç½®
                        # XGBoost 1.6-1.9: callbackså¯ä¼ å…¥fit()
                        # XGBoost <1.6: ä½¿ç”¨early_stopping_roundså‚æ•°
                        xgb_version = tuple(map(int, xgb.__version__.split('.')[:2]))
                        
                        if xgb_version >= (2, 0):
                            # ğŸ”‘ XGBoost 2.0+ API: æ—©åœé€šè¿‡æ„é€ å‡½æ•°å‚æ•°æ§åˆ¶
                            params['early_stopping_rounds'] = 100
                            params['eval_metric'] = 'mlogloss'
                            model = xgb.XGBClassifier(**params)
                            model.fit(
                                X_train, y_train,
                                sample_weight=sample_weights,
                                eval_set=[(X_val, y_val)],
                                verbose=False
                            )
                        elif xgb_version >= (1, 6):
                            # XGBoost 1.6-1.9 API: callbackså¯ä¼ å…¥fit()
                            early_stop = xgb.callback.EarlyStopping(
                                rounds=100, 
                                save_best=True,
                                maximize=False
                            )
                            model = xgb.XGBClassifier(**params)
                            model.fit(
                                X_train, y_train,
                                sample_weight=sample_weights,
                                eval_set=[(X_val, y_val)],
                                callbacks=[early_stop],
                                verbose=False
                            )
                        else:
                            # XGBoost <1.6 API: ä½¿ç”¨early_stopping_roundså‚æ•°
                            logger.warning(f"âš ï¸ XGBoostç‰ˆæœ¬{xgb.__version__} < 1.6.0ï¼Œä½¿ç”¨æ—§ç‰ˆAPI")
                            model = xgb.XGBClassifier(**params)
                            model.fit(
                                X_train, y_train,
                                sample_weight=sample_weights,
                                eval_set=[(X_val, y_val)],
                                early_stopping_rounds=100,
                                verbose=False
                            )
                        
                        # ğŸ® ç»Ÿä¸€GPUå†…å­˜ç®¡ç†ï¼šè®­ç»ƒåæ¸…ç†
                        self.clear_gpu_memory()
                            
                    except Exception as e:
                        logger.error(f"âŒ XGBoostè®­ç»ƒå¤±è´¥: {e}")
                        logger.error(f"   XGBoostç‰ˆæœ¬: {xgb.__version__}")
                        import traceback
                        logger.error(traceback.format_exc())
                        
                        # é™çº§åˆ°CPUé‡è¯•
                        params['tree_method'] = 'hist'
                        params['device'] = 'cpu'
                        
                        try:
                            xgb_version = tuple(map(int, xgb.__version__.split('.')[:2]))
                            if xgb_version >= (2, 0):
                                # XGBoost 2.0+ API
                                params['early_stopping_rounds'] = 100
                                params['eval_metric'] = 'mlogloss'
                                model = xgb.XGBClassifier(**params)
                                model.fit(
                                    X_train, y_train,
                                    sample_weight=sample_weights,
                                    eval_set=[(X_val, y_val)],
                                    verbose=False
                                )
                            elif xgb_version >= (1, 6):
                                # XGBoost 1.6-1.9 API
                                early_stop = xgb.callback.EarlyStopping(
                                    rounds=100,
                                    save_best=True,
                                    maximize=False
                                )
                                model = xgb.XGBClassifier(**params)
                                model.fit(
                                    X_train, y_train,
                                    sample_weight=sample_weights,
                                    eval_set=[(X_val, y_val)],
                                    callbacks=[early_stop],
                                    verbose=False
                                )
                            else:
                                # XGBoost <1.6 API
                                model = xgb.XGBClassifier(**params)
                                model.fit(
                                    X_train, y_train,
                                    sample_weight=sample_weights,
                                    eval_set=[(X_val, y_val)],
                                    early_stopping_rounds=100,
                                    verbose=False
                                )
                            logger.info(f"âœ… XGBoosté™çº§åˆ°CPUåè®­ç»ƒæˆåŠŸ")
                        except Exception as e2:
                            logger.error(f"âŒ XGBoost CPUé™çº§ä¹Ÿå¤±è´¥: {e2}")
                            import traceback
                            logger.error(traceback.format_exc())
                            raise
                        
                        self.clear_gpu_memory()
                
                elif self.model_type == "catboost":
                    # æ£€æŸ¥GPUå†…å­˜å¯ç”¨æ€§
                    if torch.cuda.is_available():
                        gpu_status = self.monitor_gpu_memory()
                        if gpu_status.get('free', 0) > 500 * 1024**2:  # 500MB
                            params['task_type'] = 'GPU'
                            params['devices'] = '0'
                            logger.debug(f"ğŸš€ CatBoostä½¿ç”¨GPUè®­ç»ƒ (å¯ç”¨å†…å­˜: {gpu_status['free']/1024**3:.1f}GB)")
                        else:
                            params['task_type'] = 'CPU'
                            logger.warning(f"âš ï¸ GPUå†…å­˜ä¸è¶³({gpu_status['free']/1024**3:.1f}GB)ï¼Œåˆ‡æ¢åˆ°CPU")
                    else:
                        params['task_type'] = 'CPU'
                        logger.debug("ğŸ”„ GPUä¸å¯ç”¨ï¼ŒCatBoostä½¿ç”¨CPUè®­ç»ƒ")
                    
                    try:
                        model = cb.CatBoostClassifier(**params)
                        # æ·»åŠ éªŒè¯é›†å’Œæ—©åœæœºåˆ¶
                        model.fit(
                            X_train, y_train, 
                            sample_weight=sample_weights,
                            eval_set=(X_val, y_val),
                            early_stopping_rounds=100,  # æ—©åœè½®æ•°
                            verbose=False
                        )
                        
                        # ğŸ® ç»Ÿä¸€GPUå†…å­˜ç®¡ç†ï¼šè®­ç»ƒåæ¸…ç†
                        self.clear_gpu_memory()
                            
                    except Exception as e:
                        logger.error(f"âŒ CatBoost GPUè®­ç»ƒå¤±è´¥: {e}")
                        # é™çº§åˆ°CPU
                        params['task_type'] = 'CPU'
                        model = cb.CatBoostClassifier(**params)
                        # æ·»åŠ éªŒè¯é›†å’Œæ—©åœæœºåˆ¶
                        model.fit(
                            X_train, y_train, 
                            sample_weight=sample_weights,
                            eval_set=(X_val, y_val),
                            early_stopping_rounds=100,  # æ—©åœè½®æ•°
                            verbose=False
                        )
                        self.clear_gpu_memory()
                
                elif self.model_type == "informer2":
                    # Informer-2éœ€è¦ç‰¹æ®Šå¤„ç†ï¼ˆæ·±åº¦å­¦ä¹ æ¨¡å‹ + åºåˆ—è¾“å…¥ï¼‰
                    # ğŸ® ç»Ÿä¸€GPUå†…å­˜ç®¡ç†ï¼šè®­ç»ƒå‰æ¸…ç†
                    self.clear_gpu_memory()
                    
                    # ğŸ”‘ æ£€æŸ¥è¾“å…¥ç»´åº¦ï¼ˆ2Dæˆ–3Dï¼‰
                    if len(X_train.shape) == 2:
                        # 2Dè¾“å…¥ï¼šéœ€è¦æ„é€ åºåˆ—ï¼ˆè¿™ä¸åº”è¯¥å‘ç”Ÿï¼Œä½†ä½œä¸ºé™çº§å¤„ç†ï¼‰
                        logger.warning(f"âš ï¸ Informer-2æ”¶åˆ°2Dè¾“å…¥ï¼Œå°†è·³è¿‡æ­¤fold")
                        cv_scores.append(0.0)
                        fold_fail_count += 1
                        continue
                    
                    # 3Dåºåˆ—è¾“å…¥ï¼š(n_samples, seq_len, n_features)
                    n_features = X_train.shape[2]
                    
                    # âœ… å…³é”®ä¿®å¤ï¼šå¯¹3Dåºåˆ—æ•°æ®è¿›è¡Œå½’ä¸€åŒ–ï¼ˆé˜²æ­¢æ•°å€¼æº¢å‡ºï¼‰
                    logger.info(f"ğŸ”§ Trial {trial.number} Fold {fold_idx+1}/5 å¯¹åºåˆ—æ•°æ®è¿›è¡Œå½’ä¸€åŒ–...")
                    logger.info(f"   å½’ä¸€åŒ–å‰ç»Ÿè®¡: èŒƒå›´=[{X_train.min():.4f}, {X_train.max():.4f}], å‡å€¼={X_train.mean():.4f}, æ ‡å‡†å·®={X_train.std():.4f}")
                    
                    # æ–¹æ³•ï¼šå°†3Dæ•°æ®reshapeä¸º2Dï¼ŒæŒ‰ç‰¹å¾å½’ä¸€åŒ–ï¼Œå†reshapeå›3D
                    # è¿™æ ·æ¯ä¸ªç‰¹å¾åœ¨æ‰€æœ‰æ ·æœ¬å’Œæ—¶é—´æ­¥ä¸Šéƒ½è¢«å½’ä¸€åŒ–
                    original_shape_train = X_train.shape
                    original_shape_val = X_val.shape
                    
                    # Reshapeä¸º2D: (n_samples * seq_len, n_features)
                    X_train_2d = X_train.reshape(-1, n_features)
                    X_val_2d = X_val.reshape(-1, n_features)
                    
                    # ä½¿ç”¨StandardScalerå½’ä¸€åŒ–
                    scaler = StandardScaler()
                    X_train_2d_scaled = scaler.fit_transform(X_train_2d)
                    X_val_2d_scaled = scaler.transform(X_val_2d)
                    
                    # Reshapeå›3D: (n_samples, seq_len, n_features)
                    X_train = X_train_2d_scaled.reshape(original_shape_train).astype(np.float32)
                    X_val = X_val_2d_scaled.reshape(original_shape_val).astype(np.float32)
                    
                    logger.info(f"   âœ… å½’ä¸€åŒ–å®Œæˆ")
                    logger.info(f"   å½’ä¸€åŒ–åç»Ÿè®¡: èŒƒå›´=[{X_train.min():.4f}, {X_train.max():.4f}], å‡å€¼={X_train.mean():.4f}, æ ‡å‡†å·®={X_train.std():.4f}")
                    
                    # è½¬æ¢ä¸ºPyTorchå¼ é‡ï¼ˆå†…å­˜ä¼˜åŒ–ï¼‰
                    device = torch.device('cuda:0' if self.use_gpu and torch.cuda.is_available() else 'cpu')
                    
                    # ğŸ”¥ å…³é”®ä¿®å¤ï¼šç»Ÿä¸€è½¬æ¢ä¸ºnumpyæ•°ç»„ï¼ˆç¡®ä¿æ˜¯è¿ç»­å†…å­˜ï¼‰
                    if not isinstance(y_train, np.ndarray):
                        y_train_np = np.asarray(y_train, dtype=np.int64)
                    else:
                        y_train_np = y_train.astype(np.int64) if y_train.dtype != np.int64 else y_train
                    
                    if not isinstance(y_val, np.ndarray):
                        y_val_np = np.asarray(y_val, dtype=np.int64)
                    else:
                        y_val_np = y_val.astype(np.int64) if y_val.dtype != np.int64 else y_val
                    
                    # ğŸ”¥ å…³é”®ä¿®å¤ï¼šåˆ›å»ºå¼ é‡ç”¨äºå†…å­˜ç›‘æ§ï¼ˆä½†ä¸ç”¨äºè®­ç»ƒï¼‰
                    # DataLoaderä¼šè‡ªåŠ¨å¤„ç†æ•°æ®è½¬æ¢
                    train_memory_mb = (X_train.nbytes + y_train_np.nbytes) / (1024 ** 2)
                    logger.debug(f"   è®­ç»ƒé›†å†…å­˜: {train_memory_mb:.1f} MB")
                    
                    # ğŸš€ æ¢¯åº¦ç´¯ç§¯é…ç½®ï¼ˆè§£å†³GPU OOMé—®é¢˜ï¼‰
                    effective_batch_size = params['batch_size']
                    actual_batch_size = max(8, params['batch_size'] // 8)
                    accumulation_steps = effective_batch_size // actual_batch_size
                    
                    # ğŸ”¥ å…³é”®ä¿®å¤ï¼šç¡®ä¿æ•°æ®æ˜¯è¿ç»­çš„numpyæ•°ç»„ï¼ˆé¿å…å†…å­˜æ˜ å°„é—®é¢˜ï¼‰
                    if not X_train.flags['C_CONTIGUOUS']:
                        logger.debug(f"   è½¬æ¢X_trainä¸ºè¿ç»­æ•°ç»„")
                        X_train = np.ascontiguousarray(X_train)
                    if not y_train_np.flags['C_CONTIGUOUS']:
                        logger.debug(f"   è½¬æ¢y_trainä¸ºè¿ç»­æ•°ç»„")
                        y_train_np = np.ascontiguousarray(y_train_np)
                    
                    # åˆ›å»ºæ•°æ®åŠ è½½å™¨ï¼ˆä½¿ç”¨æ›´å°çš„ç‰©ç†æ‰¹æ¬¡ï¼‰
                    class NumpyTimeSeriesDataset(Dataset):
                        def __init__(self, X_np, y_np):
                            # ç¡®ä¿æ•°æ®æ˜¯è¿ç»­çš„numpyæ•°ç»„
                            self.X_np = np.ascontiguousarray(X_np) if not X_np.flags['C_CONTIGUOUS'] else X_np
                            self.y_np = np.ascontiguousarray(y_np) if not y_np.flags['C_CONTIGUOUS'] else y_np
                        def __len__(self):
                            return len(self.y_np)
                        def __getitem__(self, idx):
                            return (
                                torch.from_numpy(self.X_np[idx].copy()).to(dtype=torch.float32),
                                torch.tensor(self.y_np[idx], dtype=torch.long)
                            )

                    # ğŸ” ä¿®å¤E: è®­ç»ƒå‰æ•°æ®è´¨é‡æ£€æŸ¥ï¼ˆOptunaè¯•éªŒæ¨¡å¼ï¼‰
                    logger.info(f"ğŸ” Trial {trial.number} Fold {fold_idx+1}/5 æ‰§è¡Œè®­ç»ƒå‰æ•°æ®è´¨é‡æ£€æŸ¥...")
                    
                    # æ£€æŸ¥ç‰¹å¾æ•°æ®
                    nan_count = np.isnan(X_train).sum()
                    inf_count = np.isinf(X_train).sum()
                    if nan_count > 0:
                        logger.error(f"âŒ Trial {trial.number} Fold {fold_idx+1}: è®­ç»ƒæ•°æ®åŒ…å«{nan_count}ä¸ªNaNå€¼ï¼")
                        logger.error(f"   æ•°æ®å½¢çŠ¶: {X_train.shape}, NaNæ¯”ä¾‹: {100*nan_count/X_train.size:.2f}%")
                        logger.error(f"   NaNä½ç½®ç»Ÿè®¡ï¼ˆå‰10ä¸ªï¼‰:")
                        nan_positions = np.where(np.isnan(X_train))
                        for i in range(min(10, len(nan_positions[0]))):
                            logger.error(f"      ä½ç½®: ({nan_positions[0][i]}, {nan_positions[1][i]}, {nan_positions[2][i]})")
                        raise ValueError(f"è®­ç»ƒæ•°æ®åŒ…å«NaNå€¼ï¼š{nan_count}ä¸ªï¼ˆ{100*nan_count/X_train.size:.2f}%ï¼‰")
                    
                    if inf_count > 0:
                        logger.error(f"âŒ Trial {trial.number} Fold {fold_idx+1}: è®­ç»ƒæ•°æ®åŒ…å«{inf_count}ä¸ªINFå€¼ï¼")
                        logger.error(f"   æ•°æ®å½¢çŠ¶: {X_train.shape}, INFæ¯”ä¾‹: {100*inf_count/X_train.size:.2f}%")
                        logger.error(f"   INFä½ç½®ç»Ÿè®¡ï¼ˆå‰10ä¸ªï¼‰:")
                        inf_positions = np.where(np.isinf(X_train))
                        for i in range(min(10, len(inf_positions[0]))):
                            logger.error(f"      ä½ç½®: ({inf_positions[0][i]}, {inf_positions[1][i]}, {inf_positions[2][i]})")
                        raise ValueError(f"è®­ç»ƒæ•°æ®åŒ…å«INFå€¼ï¼š{inf_count}ä¸ªï¼ˆ{100*inf_count/X_train.size:.2f}%ï¼‰")
                    
                    # æ£€æŸ¥æ ‡ç­¾æ•°æ®
                    label_nan_count = np.isnan(y_train_np).sum() if np.isnan(y_train_np).any() else 0
                    label_inf_count = np.isinf(y_train_np).sum() if np.isinf(y_train_np).any() else 0
                    if label_nan_count > 0 or label_inf_count > 0:
                        logger.error(f"âŒ Trial {trial.number} Fold {fold_idx+1}: è®­ç»ƒæ ‡ç­¾åŒ…å«NaN/INFå€¼ï¼")
                        logger.error(f"   æ ‡ç­¾å½¢çŠ¶: {y_train_np.shape}, NaN: {label_nan_count}, INF: {label_inf_count}")
                        if label_nan_count > 0:
                            nan_indices = np.where(np.isnan(y_train_np))[0]
                            logger.error(f"   NaNæ ‡ç­¾ä½ç½®ï¼ˆå‰10ä¸ªï¼‰: {nan_indices[:10]}")
                        if label_inf_count > 0:
                            inf_indices = np.where(np.isinf(y_train_np))[0]
                            logger.error(f"   INFæ ‡ç­¾ä½ç½®ï¼ˆå‰10ä¸ªï¼‰: {inf_indices[:10]}")
                        raise ValueError(f"è®­ç»ƒæ ‡ç­¾åŒ…å«NaN/INFå€¼ï¼ˆNaN: {label_nan_count}, INF: {label_inf_count}ï¼‰")
                    
                    # æ£€æŸ¥æ ‡ç­¾èŒƒå›´
                    unique_labels = np.unique(y_train_np)
                    if not all(label in [0, 1, 2] for label in unique_labels):
                        logger.error(f"âŒ Trial {trial.number} Fold {fold_idx+1}: è®­ç»ƒæ ‡ç­¾åŒ…å«éæ³•å€¼ï¼")
                        logger.error(f"   æœŸæœ›æ ‡ç­¾: [0, 1, 2], å®é™…æ ‡ç­¾: {unique_labels.tolist()}")
                        logger.error(f"   æ ‡ç­¾ç»Ÿè®¡: {np.bincount(y_train_np.astype(int))}")
                        illegal_indices = np.where(~np.isin(y_train_np, [0, 1, 2]))[0]
                        logger.error(f"   éæ³•æ ‡ç­¾ä½ç½®ï¼ˆå‰10ä¸ªï¼‰: {illegal_indices[:10]}")
                        logger.error(f"   éæ³•æ ‡ç­¾å€¼ï¼ˆå‰10ä¸ªï¼‰: {y_train_np[illegal_indices[:10]]}")
                        raise ValueError(f"è®­ç»ƒæ ‡ç­¾åŒ…å«éæ³•å€¼ï¼š{unique_labels.tolist()}ï¼ŒæœŸæœ›[0,1,2]")
                    
                    # ç»Ÿè®¡æ•°æ®èŒƒå›´
                    logger.info(f"   âœ… Fold {fold_idx+1} æ•°æ®è´¨é‡æ£€æŸ¥é€šè¿‡")
                    logger.info(f"      ç‰¹å¾èŒƒå›´: [{X_train.min():.4f}, {X_train.max():.4f}]")
                    logger.info(f"      ç‰¹å¾å‡å€¼: {X_train.mean():.4f}, æ ‡å‡†å·®: {X_train.std():.4f}")
                    logger.info(f"      æ ‡ç­¾åˆ†å¸ƒ: {np.bincount(y_train_np.astype(int)).tolist()}")
                    logger.info(f"      æ ·æœ¬æ•°: {len(y_train_np)}")

                    train_dataset = NumpyTimeSeriesDataset(X_train, y_train_np)
                    train_loader = DataLoader(
                        train_dataset,
                        batch_size=actual_batch_size,
                        shuffle=True,
                        num_workers=0,
                        pin_memory=True if device.type == 'cuda' else False
                    )
                    
                    # åˆ›å»ºæ¨¡å‹ï¼ˆæ”¯æŒåºåˆ—è¾“å…¥ + æ¢¯åº¦æ£€æŸ¥ç‚¹ï¼‰
                    model = Informer2ForClassification(
                        n_features=n_features,  # ç‰¹å¾æ•°é‡ï¼ˆä»åºåˆ—çš„æœ€åä¸€ç»´è·å–ï¼‰
                        n_classes=3,  # ç±»åˆ«æ•°
                        d_model=params['d_model'],
                        n_heads=params['n_heads'],
                        n_layers=params['n_layers'],
                        dropout=params['dropout'],
                        use_distilling=True,  # å¯ç”¨è’¸é¦å±‚ï¼ˆå®Œæ•´Informeræ¶æ„ï¼‰
                        use_gradient_checkpointing=True  # ğŸ”¥ å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹ï¼ˆèŠ‚çœ50-70%å†…å­˜ï¼‰
                    ).to(device)
                    
                    # ğŸ” ä¿®å¤E: æ¨¡å‹æƒé‡åˆå§‹åŒ–æ£€æŸ¥
                    logger.info(f"ğŸ” Trial {trial.number} Fold {fold_idx+1}/5 æ£€æŸ¥æ¨¡å‹æƒé‡åˆå§‹åŒ–...")
                    has_nan_weights = False
                    has_inf_weights = False
                    weight_stats = {}
                    
                    for name, param in model.named_parameters():
                        param_nan = torch.isnan(param).sum().item()
                        param_inf = torch.isinf(param).sum().item()
                        param_total = param.numel()
                        
                        if param_nan > 0:
                            logger.error(f"âŒ æ¨¡å‹å‚æ•° {name} åŒ…å«{param_nan}ä¸ªNaNå€¼ï¼ˆå…±{param_total}ä¸ªå‚æ•°ï¼‰ï¼")
                            logger.error(f"   å‚æ•°å½¢çŠ¶: {param.shape}, å‚æ•°èŒƒå›´: [{param.min().item():.4f}, {param.max().item():.4f}]")
                            has_nan_weights = True
                        if param_inf > 0:
                            logger.error(f"âŒ æ¨¡å‹å‚æ•° {name} åŒ…å«{param_inf}ä¸ªINFå€¼ï¼ˆå…±{param_total}ä¸ªå‚æ•°ï¼‰ï¼")
                            logger.error(f"   å‚æ•°å½¢çŠ¶: {param.shape}, å‚æ•°èŒƒå›´: [{param.min().item():.4f}, {param.max().item():.4f}]")
                            has_inf_weights = True
                        
                        # è®°å½•å‚æ•°ç»Ÿè®¡
                        weight_stats[name] = {
                            'shape': list(param.shape),
                            'min': param.min().item(),
                            'max': param.max().item(),
                            'mean': param.mean().item(),
                            'std': param.std().item(),
                            'nan': param_nan,
                            'inf': param_inf
                        }
                    
                    if has_nan_weights or has_inf_weights:
                        logger.error("âŒ æ¨¡å‹æƒé‡åˆå§‹åŒ–å¼‚å¸¸ï¼Œè®­ç»ƒç»ˆæ­¢ï¼")
                        logger.error("   è¯¦ç»†å‚æ•°ç»Ÿè®¡:")
                        for name, stats in weight_stats.items():
                            if stats['nan'] > 0 or stats['inf'] > 0:
                                logger.error(f"      {name}: {stats}")
                        raise ValueError("æ¨¡å‹æƒé‡åˆå§‹åŒ–åŒ…å«NaN/INFå€¼")
                    
                    logger.info("   âœ… æ¨¡å‹æƒé‡åˆå§‹åŒ–æ­£å¸¸")
                    logger.debug(f"   æ¨¡å‹å‚æ•°ç»Ÿè®¡ï¼ˆå‰5ä¸ªï¼‰:")
                    for i, (name, stats) in enumerate(list(weight_stats.items())[:5]):
                        logger.debug(f"      {name}: shape={stats['shape']}, range=[{stats['min']:.4f}, {stats['max']:.4f}], mean={stats['mean']:.4f}")
                    
                    # å®šä¹‰æŸå¤±å‡½æ•°ï¼ˆä¸è®­ç»ƒæµç¨‹ä¿æŒä¸€è‡´ï¼‰
                    hold_ratio_opt = float((y_train_np == 1).sum()) / max(len(y_train_np), 1)
                    if self.timeframe == '3m':
                        hold_penalty_nn = float(max(0.35, min(0.70, 0.80 - 0.6 * hold_ratio_opt)))
                    else:
                        hold_penalty_nn = float(max(0.50, min(0.75, 0.85 - 0.5 * hold_ratio_opt)))

                    criterion = create_trade_loss(
                        use_gmadl=settings.USE_GMADL_LOSS,
                        hold_penalty=hold_penalty_nn,
                        alpha=params.get('alpha', settings.GMADL_ALPHA),
                        beta=params.get('beta', settings.GMADL_BETA)
                    )

                    if settings.USE_GMADL_LOSS:
                        logger.debug(
                            f"   æŸå¤±å‡½æ•°: GMADL + HOLDæƒ©ç½š (alpha={params.get('alpha', settings.GMADL_ALPHA):.2f}, beta={params.get('beta', settings.GMADL_BETA):.2f})"
                        )
                    else:
                        logger.debug("   æŸå¤±å‡½æ•°: äº¤å‰ç†µ + HOLDæƒ©ç½š (ç¨³å®šæ¨¡å¼)")
                    
                    # ğŸ”¥ å°è¯•ä½¿ç”¨8-bit Adamä¼˜åŒ–å™¨ï¼ˆèŠ‚çœ75%ä¼˜åŒ–å™¨å†…å­˜ï¼‰
                    optimizer_created = False
                    if self.use_gpu and device.type == 'cuda':
                        try:
                            if not BNB_AVAILABLE:
                                raise ImportError("bitsandbytesæœªå®‰è£…")
                            optimizer = bnb.optim.Adam8bit(
                                model.parameters(),
                                lr=params['lr'],
                                betas=(0.9, 0.999)
                            )
                            optimizer_created = True
                        except (ImportError, Exception):
                            pass
                    
                    if not optimizer_created:
                        optimizer = torch.optim.Adam(
                            model.parameters(),
                            lr=params['lr'],
                            weight_decay=1e-5,
                            betas=(0.9, 0.999)
                        )
                    
                    # âœ… ä¿®å¤C: æ·»åŠ Warmup + ReduceLROnPlateauç»„åˆè°ƒåº¦å™¨
                    # Warmupé…ç½®
                    warmup_epochs = 5  # å‰5ä¸ªepoch warmup
                    target_lr = params['lr']
                    
                    # ä¸»è°ƒåº¦å™¨ï¼šReduceLROnPlateauï¼ˆç”¨äºwarmupåçš„å­¦ä¹ ç‡è°ƒæ•´ï¼‰
                    # âœ… ä¿®å¤ï¼šç§»é™¤å·²åºŸå¼ƒçš„verboseå‚æ•°ï¼ˆPyTorchæ–°ç‰ˆæœ¬å·²åºŸå¼ƒï¼‰
                    scheduler = ReduceLROnPlateau(
                        optimizer,
                        mode='min',
                        factor=0.5,
                        patience=5,
                        min_lr=1e-6,
                        threshold=1e-4,
                        threshold_mode='rel',
                        cooldown=2
                    )
                    
                    logger.info(f"   âœ… å­¦ä¹ ç‡è°ƒåº¦: Warmup({warmup_epochs}è½®) + ReduceLROnPlateau")
                    logger.info(f"      ç›®æ ‡LR: {target_lr:.6f}, Warmupåè‡ªåŠ¨è°ƒæ•´")
                    
                    # âœ… å…³é”®ä¿®å¤ï¼šåˆå§‹åŒ–Warmupå­¦ä¹ ç‡ï¼ˆç¬¬ä¸€ä¸ªepochåº”è¯¥ä»target_lr/warmup_epochså¼€å§‹ï¼‰
                    # æ³¨æ„ï¼šä¼˜åŒ–å™¨åˆ›å»ºæ—¶å·²ç»è®¾ç½®ä¸ºtarget_lrï¼Œéœ€è¦åœ¨è®­ç»ƒå‰è°ƒæ•´ä¸ºWarmupåˆå§‹å€¼
                    initial_warmup_lr = target_lr / warmup_epochs  # ç¬¬ä¸€ä¸ªepochçš„åˆå§‹å­¦ä¹ ç‡
                    for param_group in optimizer.param_groups:
                        param_group['lr'] = initial_warmup_lr
                    logger.info(f"   âœ… Warmupåˆå§‹å­¦ä¹ ç‡å·²è®¾ç½®: {initial_warmup_lr:.6f} (ç›®æ ‡LRçš„1/{warmup_epochs})")
                    logger.debug(f"   ä¼˜åŒ–å™¨å‚æ•°ç»„æ•°é‡: {len(optimizer.param_groups)}")
                    for i, pg in enumerate(optimizer.param_groups):
                        logger.debug(f"      å‚æ•°ç»„{i}: lr={pg['lr']:.6f}, weight_decay={pg.get('weight_decay', 0)}")
                    
                    # ğŸš€ åŠ¨æ€æ··åˆç²¾åº¦é…ç½®ï¼ˆä½¿ç”¨æ–°çš„é…ç½®å™¨å’Œç›‘æ§å™¨ï¼‰
                    use_amp = device.type == 'cuda' and torch.cuda.is_available()
                    if settings.USE_GMADL_LOSS and use_amp:
                        logger.debug("   âš ï¸ GMADLå¼€å¯ â†’ Optunaè¯•éªŒç¦ç”¨AMPæ”¹ç”¨FP32è®­ç»ƒ")
                        use_amp = False
                    
                    scaler = None
                    scaler_monitor = None
                    
                    if use_amp:
                        # ğŸ”¥ ä½¿ç”¨åŠ¨æ€GradScaleré…ç½®å™¨
                        num_params = sum(p.numel() for p in model.parameters())
                        scaler_config = DynamicGradScalerConfig(num_params)
                        scaler = scaler_config.create_scaler('cuda')
                        
                        # ğŸ”¥ åˆ›å»ºGradScalerç›‘æ§å™¨
                        scaler_monitor = GradScalerMonitor(scaler, scaler_config.init_scale)
                        
                        torch.backends.cuda.matmul.allow_tf32 = True
                        torch.backends.cudnn.allow_tf32 = True
                        logger.debug(f"   æ··åˆç²¾åº¦è®­ç»ƒ: å¯ç”¨ï¼ˆåŠ¨æ€ç¼©æ”¾ç­–ç•¥ + ç›‘æ§å™¨ï¼‰")
                    else:
                        logger.debug("   æ··åˆç²¾åº¦è®­ç»ƒ: ç¦ç”¨ï¼ˆCPUç¯å¢ƒæˆ–GMADLæ¨¡å¼ï¼‰")
                    
                    # è®­ç»ƒæ¨¡å‹ï¼ˆå¸¦æ¢¯åº¦ç´¯ç§¯å’Œæ··åˆç²¾åº¦ï¼‰
                    model.train()
                    nan_inf_count = 0  # ç»Ÿè®¡nan/infå‡ºç°æ¬¡æ•°
                    max_nan_inf_tolerance = 30  # âœ… ä¿®å¤F: ç¬¦åˆæ–‡æ¡£è¦æ±‚
                    consecutive_nan_inf = 0
                    max_consecutive_nan_inf = 8  # âœ… ä¿®å¤F: ä»5æ”¹ä¸º8ï¼ˆç¬¦åˆæ–‡æ¡£ï¼‰
                    
                    logger.info(f"ğŸš‚ Trial {trial.number} Fold {fold_idx+1}/5 å¼€å§‹è®­ç»ƒ...")
                    logger.info(f"   è®­ç»ƒé…ç½®:")
                    logger.info(f"      æ€»Epochæ•°: {params['epochs']}")
                    logger.info(f"      æ‰¹æ¬¡å¤§å°: {actual_batch_size} (æœ‰æ•ˆæ‰¹æ¬¡: {effective_batch_size}, ç´¯ç§¯æ­¥æ•°: {accumulation_steps})")
                    logger.info(f"      è®¾å¤‡: {device}")
                    logger.info(f"      æ··åˆç²¾åº¦: {'å¯ç”¨' if use_amp else 'ç¦ç”¨'}")
                    logger.info(f"      æ—©æœŸç»ˆæ­¢é˜ˆå€¼: è¿ç»­{max_consecutive_nan_inf}æ¬¡ æˆ– ç´¯è®¡{max_nan_inf_tolerance}æ¬¡")
                    logger.info(f"      æ€»æ‰¹æ¬¡æ•°: {len(train_loader)}")
                    
                    for epoch in range(params['epochs']):
                        optimizer.zero_grad()
                        
                        # âœ… ä¿®å¤C: åˆå§‹åŒ–epochç»Ÿè®¡
                        epoch_loss = 0.0
                        correct = 0
                        total = 0
                        processed_batches = 0
                        epoch_nan_inf_count = 0
                        
                        # âœ… è¯¦ç»†æ—¥å¿—ï¼šè®°å½•epochå¼€å§‹
                        if epoch == 0:
                            logger.info(f"   ğŸ“ Epoch {epoch+1}/{params['epochs']} å¼€å§‹ï¼ˆç¬¬ä¸€ä¸ªepochï¼Œå°†è®°å½•è¯¦ç»†è¯Šæ–­ä¿¡æ¯ï¼‰...")
                        elif epoch % 5 == 0:
                            logger.info(f"   ğŸ“ Epoch {epoch+1}/{params['epochs']} å¼€å§‹...")
                        
                        for i, (batch_X, batch_y) in enumerate(train_loader):
                            # ğŸ¯ æ··åˆç²¾åº¦å‰å‘ä¼ æ’­
                            # å°†æ‰¹æ¬¡ç§»åŠ¨åˆ°ç›®æ ‡è®¾å¤‡
                            batch_X = batch_X.to(device, non_blocking=True)
                            batch_y = batch_y.to(device, non_blocking=True)
                            
                            # âœ… è¯¦ç»†è¯Šæ–­ï¼šç¬¬ä¸€ä¸ªbatchçš„å®Œæ•´ä¿¡æ¯ï¼ˆæ— è®ºæ˜¯å¦æœ‰é”™è¯¯ï¼‰
                            if i == 0 and epoch == 0:  # åªåœ¨ç¬¬ä¸€ä¸ªbatchçš„ç¬¬ä¸€ä¸ªepochæ£€æŸ¥
                                logger.info(f"   ğŸ” ç¬¬ä¸€ä¸ªBatchè¯¦ç»†è¯Šæ–­:")
                                logger.info(f"      Batchå½¢çŠ¶: {batch_X.shape}")
                                logger.info(f"      è¾“å…¥èŒƒå›´: [{batch_X.min().item():.4f}, {batch_X.max().item():.4f}]")
                                logger.info(f"      è¾“å…¥å‡å€¼: {batch_X.mean().item():.4f}, æ ‡å‡†å·®: {batch_X.std().item():.4f}")
                                batch_nan = torch.isnan(batch_X).sum().item()
                                batch_inf = torch.isinf(batch_X).sum().item()
                                if batch_nan > 0 or batch_inf > 0:
                                    logger.error(f"      âŒ ç¬¬ä¸€ä¸ªbatchè¾“å…¥æ•°æ®å¼‚å¸¸ï¼")
                                    logger.error(f"         NaN: {batch_nan}, INF: {batch_inf}")
                                    logger.error(f"         NaNä½ç½®ï¼ˆå‰5ä¸ªï¼‰:")
                                    nan_pos = torch.where(torch.isnan(batch_X))
                                    for j in range(min(5, len(nan_pos[0]))):
                                        logger.error(f"           ä½ç½®: ({nan_pos[0][j]}, {nan_pos[1][j]}, {nan_pos[2][j]})")
                                    raise ValueError(f"Batchè¾“å…¥æ•°æ®åŒ…å«NaN/INFï¼ˆNaN: {batch_nan}, INF: {batch_inf}ï¼‰")
                                else:
                                    logger.info(f"      âœ… è¾“å…¥æ•°æ®æ­£å¸¸ï¼ˆæ— NaN/INFï¼‰")
                                
                                logger.info(f"      æ ‡ç­¾å½¢çŠ¶: {batch_y.shape}")
                                logger.info(f"      æ ‡ç­¾åˆ†å¸ƒ: {torch.bincount(batch_y.long()).tolist()}")
                                logger.info(f"      æ ‡ç­¾èŒƒå›´: [{batch_y.min().item()}, {batch_y.max().item()}]")
                            
                            if use_amp:
                                with torch.amp.autocast('cuda'):
                                    outputs = model(batch_X)
                                    # ç»Ÿä¸€dtypeä¸lossè¾“å…¥ï¼šlogitsç”¨float32ï¼Œtargetsç”¨long
                                    loss = criterion(outputs.float(), batch_y.long()) / accumulation_steps
                            else:
                                outputs = model(batch_X)
                                loss = criterion(outputs.float(), batch_y.long()) / accumulation_steps
                            
                            # âœ… è¯¦ç»†è¯Šæ–­ï¼šç¬¬ä¸€ä¸ªbatchçš„æ¨¡å‹è¾“å‡ºå’ŒæŸå¤±ï¼ˆæ— è®ºæ˜¯å¦æœ‰é”™è¯¯ï¼‰
                            if i == 0 and epoch == 0:
                                logger.info(f"      ğŸ¤– æ¨¡å‹è¾“å‡ºç»Ÿè®¡:")
                                logger.info(f"         è¾“å‡ºå½¢çŠ¶: {outputs.shape}")
                                logger.info(f"         è¾“å‡ºèŒƒå›´: [{outputs.min().item():.4f}, {outputs.max().item():.4f}]")
                                logger.info(f"         è¾“å‡ºå‡å€¼: {outputs.mean().item():.4f}, æ ‡å‡†å·®: {outputs.std().item():.4f}")
                                output_nan = torch.isnan(outputs).sum().item()
                                output_inf = torch.isinf(outputs).sum().item()
                                if output_nan > 0 or output_inf > 0:
                                    logger.error(f"         âŒ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/INF: NaN={output_nan}, INF={output_inf}")
                                else:
                                    logger.info(f"         âœ… æ¨¡å‹è¾“å‡ºæ­£å¸¸ï¼ˆæ— NaN/INFï¼‰")
                                
                                logger.info(f"      ğŸ“‰ æŸå¤±ç»Ÿè®¡:")
                                logger.info(f"         æŸå¤±å€¼: {loss.item():.6f}")
                                if torch.isnan(loss) or torch.isinf(loss):
                                    logger.error(f"         âŒ æŸå¤±å€¼å¼‚å¸¸ï¼")
                                else:
                                    logger.info(f"         âœ… æŸå¤±å€¼æ­£å¸¸")
                            
                            # ğŸ” æ£€æµ‹æ•°å€¼ä¸ç¨³å®šï¼ˆå¢å¼ºè¯Šæ–­ï¼‰
                            if torch.isnan(loss) or torch.isinf(loss):
                                nan_inf_count += 1
                                consecutive_nan_inf += 1
                                epoch_nan_inf_count += 1
                                
                                # âœ… å…³é”®ä¿®å¤ï¼šæ£€æµ‹åˆ°NaN/INFæ—¶ï¼Œç«‹å³è·³è¿‡åå‘ä¼ æ’­ï¼Œé¿å…æ±¡æŸ“æ¢¯åº¦
                                optimizer.zero_grad()
                                
                                # âœ… è¯¦ç»†è¯Šæ–­ï¼šè®°å½•ç¬¬ä¸€ä¸ªNaN/INFçš„è¯¦ç»†ä¿¡æ¯
                                if nan_inf_count == 1:
                                    logger.error(f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
                                    logger.error(f"âŒ Trial {trial.number} Fold {fold_idx+1}: ç¬¬ä¸€ä¸ªNaN/INFæŸå¤±æ£€æµ‹ï¼")
                                    logger.error(f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
                                    logger.error(f"   ğŸ“ ä½ç½®ä¿¡æ¯:")
                                    logger.error(f"      Epoch: {epoch+1}/{params['epochs']}, Batch: {i+1}/{len(train_loader)}")
                                    logger.error(f"      ç´¯è®¡å¤„ç†æ‰¹æ¬¡æ•°: {processed_batches}")
                                    
                                    logger.error(f"   ğŸ“Š è¾“å…¥æ•°æ®ç»Ÿè®¡:")
                                    logger.error(f"      è¾“å…¥å½¢çŠ¶: {batch_X.shape}")
                                    logger.error(f"      è¾“å…¥èŒƒå›´: min={batch_X.min().item():.4f}, max={batch_X.max().item():.4f}")
                                    logger.error(f"      è¾“å…¥å‡å€¼: {batch_X.mean().item():.4f}, æ ‡å‡†å·®: {batch_X.std().item():.4f}")
                                    batch_nan = torch.isnan(batch_X).sum().item()
                                    batch_inf = torch.isinf(batch_X).sum().item()
                                    if batch_nan > 0 or batch_inf > 0:
                                        logger.error(f"      âš ï¸ è¾“å…¥åŒ…å«å¼‚å¸¸å€¼: NaN={batch_nan}, INF={batch_inf}")
                                    
                                    logger.error(f"   ğŸ·ï¸ æ ‡ç­¾ç»Ÿè®¡:")
                                    logger.error(f"      æ ‡ç­¾å½¢çŠ¶: {batch_y.shape}")
                                    logger.error(f"      æ ‡ç­¾åˆ†å¸ƒ: {torch.bincount(batch_y.long()).tolist()}")
                                    logger.error(f"      æ ‡ç­¾èŒƒå›´: [{batch_y.min().item()}, {batch_y.max().item()}]")
                                    
                                    logger.error(f"   ğŸ¤– æ¨¡å‹è¾“å‡º(logits)ç»Ÿè®¡:")
                                    logger.error(f"      è¾“å‡ºå½¢çŠ¶: {outputs.shape}")
                                    logger.error(f"      è¾“å‡ºèŒƒå›´: min={outputs.min().item():.4f}, max={outputs.max().item():.4f}")
                                    logger.error(f"      è¾“å‡ºå‡å€¼: {outputs.mean().item():.4f}, æ ‡å‡†å·®: {outputs.std().item():.4f}")
                                    
                                    # æ£€æŸ¥æ¨¡å‹è¾“å‡º
                                    output_nan = torch.isnan(outputs).sum().item()
                                    output_inf = torch.isinf(outputs).sum().item()
                                    if output_nan > 0 or output_inf > 0:
                                        logger.error(f"      âŒ æ¨¡å‹è¾“å‡ºåŒ…å«NaN/INFï¼")
                                        logger.error(f"         NaNæ•°é‡: {output_nan}, INFæ•°é‡: {output_inf}")
                                        logger.error(f"         NaNä½ç½®ï¼ˆå‰5ä¸ªï¼‰:")
                                        nan_pos = torch.where(torch.isnan(outputs))
                                        for j in range(min(5, len(nan_pos[0]))):
                                            logger.error(f"           æ ·æœ¬{nan_pos[0][j]}, ç±»åˆ«{nan_pos[1][j]}")
                                        if output_inf > 0:
                                            inf_pos = torch.where(torch.isinf(outputs))
                                            logger.error(f"         INFä½ç½®ï¼ˆå‰5ä¸ªï¼‰:")
                                            for j in range(min(5, len(inf_pos[0]))):
                                                logger.error(f"           æ ·æœ¬{inf_pos[0][j]}, ç±»åˆ«{inf_pos[1][j]}")
                                    else:
                                        logger.error(f"      âœ… æ¨¡å‹è¾“å‡ºæ­£å¸¸ï¼ˆæ— NaN/INFï¼‰")
                                    
                                    logger.error(f"   ğŸ“‰ æŸå¤±å‡½æ•°ç»Ÿè®¡:")
                                    logger.error(f"      æŸå¤±å€¼: {loss.item()}")
                                    logger.error(f"      æŸå¤±ç±»å‹: {type(loss).__name__}")
                                    logger.error(f"      æŸå¤±è®¾å¤‡: {loss.device}")
                                    
                                    logger.error(f"   âš™ï¸ è®­ç»ƒé…ç½®:")
                                    logger.error(f"      å½“å‰å­¦ä¹ ç‡: {optimizer.param_groups[0]['lr']:.6f}")
                                    logger.error(f"      æ··åˆç²¾åº¦: {'å¯ç”¨' if use_amp else 'ç¦ç”¨'}")
                                    if use_amp and scaler is not None:
                                        logger.error(f"      ç¼©æ”¾å™¨çŠ¶æ€: scale={scaler.get_scale():.4f}")
                                    logger.error(f"      æ¢¯åº¦ç´¯ç§¯æ­¥æ•°: {accumulation_steps}")
                                    
                                    logger.error(f"   ğŸ” æ¨¡å‹å‚æ•°æ£€æŸ¥ï¼ˆå‰5ä¸ªï¼‰:")
                                    for j, (name, param) in enumerate(list(model.named_parameters())[:5]):
                                        param_nan = torch.isnan(param).sum().item()
                                        param_inf = torch.isinf(param).sum().item()
                                        if param.numel() > 0:
                                            param_min = param.min().item()
                                            param_max = param.max().item()
                                        else:
                                            param_min = float('nan')
                                            param_max = float('nan')
                                        
                                        if param_nan > 0 or param_inf > 0:
                                            logger.error(f"      {name}: NaN={param_nan}, INF={param_inf}, range=[{param_min:.4f}, {param_max:.4f}], shape={list(param.shape)}")
                                        else:
                                            logger.error(f"      {name}: æ­£å¸¸, range=[{param_min:.4f}, {param_max:.4f}], shape={list(param.shape)}")
                                    
                                    # âœ… å…³é”®è¯Šæ–­ï¼šæ£€æŸ¥æ¢¯åº¦çŠ¶æ€
                                    try:
                                        total_grad_norm = 0.0
                                        grad_count = 0
                                        has_nan_grad = False
                                        for name, param in model.named_parameters():
                                            if param.grad is not None:
                                                grad_nan = torch.isnan(param.grad).sum().item()
                                                grad_inf = torch.isinf(param.grad).sum().item()
                                                if grad_nan > 0 or grad_inf > 0:
                                                    logger.error(f"      âš ï¸ {name} æ¢¯åº¦åŒ…å«NaN/INF: NaN={grad_nan}, INF={grad_inf}")
                                                    has_nan_grad = True
                                                else:
                                                    grad_norm = param.grad.norm().item()
                                                    total_grad_norm += grad_norm ** 2
                                                    grad_count += 1
                                        if grad_count > 0:
                                            total_grad_norm = total_grad_norm ** 0.5
                                            logger.error(f"   ğŸ“Š æ€»æ¢¯åº¦èŒƒæ•°: {total_grad_norm:.4f} (æ¥è‡ª{grad_count}ä¸ªå‚æ•°)")
                                        if has_nan_grad:
                                            logger.error(f"   âš ï¸ æ£€æµ‹åˆ°æ¢¯åº¦ä¸­åŒ…å«NaN/INFï¼Œè¿™å¯èƒ½æ˜¯å¯¼è‡´æ¨¡å‹è¾“å‡ºNaNçš„æ ¹æœ¬åŸå› ï¼")
                                    except Exception as grad_error:
                                        logger.error(f"   âš ï¸ æ¢¯åº¦æ£€æŸ¥å¤±è´¥: {grad_error}")
                                    
                                    logger.error(f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
                                
                                # Optunaè¯•éªŒä¸­å‡ºç°nan/infç›´æ¥prune
                                if consecutive_nan_inf >= max_consecutive_nan_inf or nan_inf_count >= max_nan_inf_tolerance:
                                    logger.error(f"âŒ Trial {trial.number} Fold {fold_idx+1}: è§¦å‘pruneæ¡ä»¶ï¼")
                                    logger.error(f"   è¿ç»­NaN/INF: {consecutive_nan_inf}/{max_consecutive_nan_inf}, ç´¯è®¡: {nan_inf_count}/{max_nan_inf_tolerance}")
                                    raise optuna.TrialPruned()
                                
                                # âœ… å·²åœ¨ä¸Šæ–¹æ‰§è¡Œäº†optimizer.zero_grad()ï¼Œè¿™é‡Œç›´æ¥è·³è¿‡
                                continue
                            
                            consecutive_nan_inf = 0
                            
                            # âœ… ä¿®å¤C: ç´¯ç§¯losså’Œaccuracyç»Ÿè®¡
                            epoch_loss += loss.item() * accumulation_steps  # åå½’ä¸€åŒ–ï¼ˆå› ä¸ºlossé™¤ä»¥äº†accumulation_stepsï¼‰
                            processed_batches += 1
                            
                            # è®¡ç®—å‡†ç¡®ç‡
                            with torch.no_grad():
                                pred = torch.argmax(outputs, dim=1)
                                correct += (pred == batch_y).sum().item()
                                total += batch_y.size(0)
                            
                            # ğŸ¯ æ··åˆç²¾åº¦åå‘ä¼ æ’­
                            if use_amp:
                                scaler.scale(loss).backward()
                            else:
                                loss.backward()
                            
                            # ğŸ¯ æ¢¯åº¦ç´¯ç§¯
                            if (i + 1) % accumulation_steps == 0 or (i + 1) == len(train_loader):
                                if use_amp:
                                    scaler.unscale_(optimizer)
                                
                                # âœ… å…³é”®ä¿®å¤ï¼šæ›´ä¸¥æ ¼çš„æ¢¯åº¦è£å‰ªï¼ˆé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸ï¼‰
                                grad_norm = torch.nn.utils.clip_grad_norm_(
                                    model.parameters(), 
                                    max_norm=0.5,  # âœ… ä»1.0é™ä½åˆ°0.5ï¼Œæ›´ä¸¥æ ¼
                                    norm_type=2.0
                                )
                                
                                # âœ… å…³é”®ä¿®å¤ï¼šæ£€æŸ¥æ¢¯åº¦è£å‰ªåçš„æ¢¯åº¦èŒƒæ•°
                                if torch.isnan(grad_norm) or torch.isinf(grad_norm) or grad_norm > 10.0:
                                    logger.warning(f"âš ï¸ Trial {trial.number} Fold {fold_idx+1} Epoch {epoch+1} Batch {i+1}: æ¢¯åº¦å¼‚å¸¸ (grad_norm={grad_norm:.4f})ï¼Œè·³è¿‡æ­¤batch")
                                    optimizer.zero_grad()
                                    continue
                                
                                # âœ… å…³é”®ä¿®å¤ï¼šå®šæœŸæ£€æŸ¥æ¨¡å‹å‚æ•°æ˜¯å¦å˜å¾—ä¸ç¨³å®šï¼ˆæ¯100ä¸ªbatchæ£€æŸ¥ä¸€æ¬¡ï¼‰
                                if (i + 1) % (accumulation_steps * 100) == 0:
                                    has_unstable_params = False
                                    for name, param in model.named_parameters():
                                        if param.numel() > 0:
                                            param_max = param.abs().max().item()
                                            if param_max > 1e6:  # å‚æ•°ç»å¯¹å€¼è¶…è¿‡100ä¸‡
                                                logger.warning(f"âš ï¸ Trial {trial.number} Fold {fold_idx+1} Epoch {epoch+1} Batch {i+1}: å‚æ•°{name}å¼‚å¸¸å¤§ (max_abs={param_max:.2e})")
                                                has_unstable_params = True
                                            if torch.isnan(param).any() or torch.isinf(param).any():
                                                logger.error(f"âŒ Trial {trial.number} Fold {fold_idx+1} Epoch {epoch+1} Batch {i+1}: å‚æ•°{name}åŒ…å«NaN/INFï¼")
                                                has_unstable_params = True
                                    
                                    if has_unstable_params:
                                        logger.error(f"âŒ æ£€æµ‹åˆ°æ¨¡å‹å‚æ•°ä¸ç¨³å®šï¼Œè®­ç»ƒç»ˆæ­¢ï¼")
                                        raise ValueError("æ¨¡å‹å‚æ•°å˜å¾—ä¸ç¨³å®šï¼ŒåŒ…å«NaN/INFæˆ–å¼‚å¸¸å¤§çš„å€¼")
                                
                                if use_amp:
                                    # ğŸ”¥ æ··åˆç²¾åº¦è®­ç»ƒæ¢¯åº¦æ›´æ–°æµç¨‹ï¼ˆä½¿ç”¨ç›‘æ§å™¨ï¼‰
                                    scaler.step(optimizer)
                                    scaler.update()
                                    
                                    # ğŸ”¥ ä½¿ç”¨ç›‘æ§å™¨æ£€æŸ¥scaleå’Œæº¢å‡º
                                    if scaler_monitor:
                                        # è®°å½•å½“å‰scale
                                        scale_exceeded = scaler_monitor.record_scale(epoch, i)
                                        
                                        # æ£€æŸ¥æ˜¯å¦æœ‰æº¢å‡ºï¼ˆé€šè¿‡æ£€æŸ¥scaleæ˜¯å¦å‡å°æ¥åˆ¤æ–­ï¼‰
                                        has_overflow = scaler.get_scale() < scaler_monitor.scale_history[-2] if len(scaler_monitor.scale_history) > 1 else False
                                        
                                        # æ£€æŸ¥æº¢å‡ºå¹¶åˆ¤æ–­æ˜¯å¦éœ€è¦é‡ç½®
                                        need_reset = scaler_monitor.check_overflow(has_overflow, epoch, i)
                                        
                                        # å¦‚æœscaleè¶…è¿‡é˜ˆå€¼æˆ–è¿ç»­æº¢å‡ºï¼Œè§¦å‘é‡ç½®
                                        if need_reset or scale_exceeded:
                                            if settings.GRAD_SCALER_AUTO_RESET:
                                                scaler_monitor.reset_scale()
                                                logger.warning(f"ğŸ”„ Trial {trial.number} Fold {fold_idx+1} Epoch {epoch+1} Batch {i+1}: Scaleå·²è‡ªåŠ¨é‡ç½®")
                                            else:
                                                logger.warning(f"âš ï¸ Trial {trial.number} Fold {fold_idx+1} Epoch {epoch+1} Batch {i+1}: æ£€æµ‹åˆ°å¼‚å¸¸ä½†è‡ªåŠ¨é‡ç½®å·²ç¦ç”¨")
                                        
                                        # æ¯100ä¸ªbatchè®°å½•ä¸€æ¬¡scaleç»Ÿè®¡
                                        if (i + 1) % (accumulation_steps * 100) == 0:
                                            stats = scaler_monitor.get_statistics()
                                            logger.debug(f"ğŸ“Š Scaleç»Ÿè®¡: å½“å‰={stats['current_scale']:.2f}, å¹³å‡={stats['avg_scale']:.2f}, æœ€å¤§={stats['max_scale']:.2f}")
                                            backoff_factor=0.5,     # æ£€æµ‹åˆ°æº¢å‡ºæ—¶å›é€€
                                            growth_interval=2000,   # æ›´è°¨æ…çš„å¢é•¿é—´éš”ï¼ˆä»1000å¢åŠ ï¼‰
                                            enabled=True
                                        )
                                        logger.warning(
                                            f"   ç¼©æ”¾å™¨å·²å¼ºåˆ¶é‡ç½®: {current_scale:.2f} -> {new_init_scale:.2f} "
                                            f"(æ¨¡å‹å‚æ•°: {num_params/1e6:.1f}M)"
                                        )
                                    elif current_scale > 1e5:  # è­¦å‘Šé˜ˆå€¼ï¼šè®°å½•æ—¥å¿—
                                        logger.warning(
                                            f"âš ï¸ Trial {trial.number} Fold {fold_idx+1} Epoch {epoch+1} Batch {i+1}: "
                                            f"ç¼©æ”¾å™¨scaleè¾ƒå¤§ ({current_scale:.2f})ï¼ŒæŒç»­ç›‘æ§ä¸­"
                                        )
                                else:
                                    optimizer.step()
                                
                                optimizer.zero_grad()
                                
                                # å®šæœŸæ¸…ç†GPUç¼“å­˜
                                if (i + 1) % (accumulation_steps * 10) == 0 and device.type == 'cuda':
                                    torch.cuda.empty_cache()
                        
                        # âœ… ä¿®å¤F: Epochçº§åˆ«æ£€æŸ¥
                        total_batches = len(train_loader)
                        
                        if processed_batches == 0:
                            logger.error(f"âŒ Epoch {epoch+1}: æ²¡æœ‰ä»»ä½•batchæˆåŠŸå¤„ç†ï¼ˆå…¨éƒ¨{total_batches}ä¸ªbatchå‡ä¸ºnan/infï¼‰ï¼Œè®­ç»ƒç»ˆæ­¢ï¼")
                            raise ValueError(f"Epoch {epoch+1}æ‰€æœ‰batchå‡å‡ºç°nan/infï¼Œè®­ç»ƒæ— æ³•ç»§ç»­")
                        
                        if epoch_nan_inf_count > total_batches * 0.5:
                            logger.error(f"âŒ Epoch {epoch+1}: {epoch_nan_inf_count}/{total_batches} batchå‡ºç°nan/inf "
                                        f"({100*epoch_nan_inf_count/total_batches:.1f}%ï¼Œè¶…è¿‡50%é˜ˆå€¼ï¼‰ï¼Œè®­ç»ƒç»ˆæ­¢ï¼")
                            raise ValueError(f"Epoch {epoch+1}è¶…è¿‡50%çš„batchå‡ºç°nan/infï¼Œè®­ç»ƒè´¨é‡æ— æ³•ä¿è¯")
                        
                        if epoch_nan_inf_count > total_batches * 0.3:
                            logger.warning(f"âš ï¸ Epoch {epoch+1}: {epoch_nan_inf_count}/{total_batches} batchå‡ºç°nan/inf "
                                          f"({100*epoch_nan_inf_count/total_batches:.1f}%ï¼‰ï¼Œæ•°å€¼ç¨³å®šæ€§é—®é¢˜ï¼")
                        
                        # âœ… ä¿®å¤C: è®¡ç®—å¹³å‡losså’Œaccuracy
                        avg_loss = epoch_loss / max(processed_batches, 1)
                        accuracy = 100.0 * correct / max(total, 1)
                        
                        # âœ… ä¿®å¤C: å­¦ä¹ ç‡è°ƒåº¦ï¼ˆç®€åŒ–çš„Warmup + ReduceLROnPlateauï¼‰
                        if epoch < warmup_epochs:
                            # Warmupé˜¶æ®µï¼šçº¿æ€§å¢é•¿å­¦ä¹ ç‡
                            # epoch 0: target_lr * 1/5, epoch 1: target_lr * 2/5, ...
                            warmup_lr = target_lr * (epoch + 1) / warmup_epochs
                            for param_group in optimizer.param_groups:
                                param_group['lr'] = warmup_lr
                            phase = "Warmup"
                            current_lr = warmup_lr
                        else:
                            # ä¸»è°ƒåº¦é˜¶æ®µï¼šæ ¹æ®lossè‡ªåŠ¨è°ƒæ•´
                            scheduler.step(avg_loss)
                            phase = "Main"
                            current_lr = optimizer.param_groups[0]['lr']
                        
                        # æ‰“å°epochä¿¡æ¯ï¼ˆå¸¦å­¦ä¹ ç‡ï¼‰
                        logger.debug(
                            f"   Epoch [{epoch+1}/{params['epochs']}] "
                            f"Loss: {avg_loss:.4f}, Acc: {accuracy:.2f}%, "
                            f"LR: {current_lr:.6f} ({phase})"
                        )
                        
                        # ğŸ”¥ Epochç»“æŸåæ£€æŸ¥scaleå¼‚å¸¸
                        if use_amp and scaler_monitor:
                            need_reset = scaler_monitor.check_epoch_abnormal(epoch)
                            if need_reset and settings.GRAD_SCALER_AUTO_RESET:
                                scaler_monitor.reset_scale()
                                logger.warning(f"ğŸ”„ Trial {trial.number} Fold {fold_idx+1} Epoch {epoch+1}: è¿ç»­epochå¼‚å¸¸ï¼ŒScaleå·²é‡ç½®")
                            
                            # è®°å½•epochçš„scaleç»Ÿè®¡
                            if epoch % 5 == 0 or epoch == params['epochs'] - 1:
                                stats = scaler_monitor.get_statistics()
                                logger.info(f"ğŸ“Š Epoch {epoch+1} Scaleç»Ÿè®¡: å½“å‰={stats['current_scale']:.2f}, æº¢å‡ºæ¬¡æ•°={stats['overflow_count']}")
                        
                        # æ¯ä¸ªepochç»“æŸåæ¸…ç†GPUç¼“å­˜
                        if device.type == 'cuda':
                            torch.cuda.empty_cache()
                    
                    # ğŸ”¥ å…³é”®ä¿®å¤ï¼šç¡®ä¿éªŒè¯æ•°æ®ä¹Ÿæ˜¯è¿ç»­æ•°ç»„
                    if not X_val.flags['C_CONTIGUOUS']:
                        logger.debug(f"   è½¬æ¢X_valä¸ºè¿ç»­æ•°ç»„")
                        X_val = np.ascontiguousarray(X_val)
                    if not y_val_np.flags['C_CONTIGUOUS']:
                        logger.debug(f"   è½¬æ¢y_valä¸ºè¿ç»­æ•°ç»„")
                        y_val_np = np.ascontiguousarray(y_val_np)
                    
                    # è¯„ä¼°æ¨¡å¼
                    model.eval()
                    with torch.no_grad():
                        # ğŸ”¥ å…³é”®ä¿®å¤ï¼šä½¿ç”¨copy()é¿å…å†…å­˜æ˜ å°„é—®é¢˜
                        X_val_tensor = torch.from_numpy(X_val.copy()).to(device, dtype=torch.float32)
                        val_outputs = model(X_val_tensor)
                        y_pred = torch.argmax(val_outputs, dim=1).cpu().numpy()
                    
                    # ğŸ® ç»Ÿä¸€GPUå†…å­˜ç®¡ç†ï¼šè®­ç»ƒåæ¸…ç†
                    self.clear_gpu_memory()
                    
                    # åˆ é™¤æ¨¡å‹å’Œå¼ é‡é‡Šæ”¾å†…å­˜
                    del model, X_val_tensor
                    self.clear_gpu_memory()
                
                # é¢„æµ‹å¹¶è¯„ä¼°
                if self.model_type != "informer2":
                    y_pred = model.predict(X_val)
                acc = accuracy_score(y_val, y_pred)
                cv_scores.append(acc)
                
            except Exception as e:
                fold_fail_count += 1
                # âœ… æå‡æ—¥å¿—çº§åˆ«å¹¶æ·»åŠ è¯¦ç»†é”™è¯¯ä¿¡æ¯
                logger.error(f"âŒ Trial {trial.number} Fold {fold_idx+1} å¤±è´¥: {e}")
                import traceback
                logger.error(f"   é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
                # å¤±è´¥çš„trialè¿”å›å¾ˆå·®çš„åˆ†æ•°
                cv_scores.append(0.0)
        
        # è®¡ç®—å¹³å‡CVå‡†ç¡®ç‡
        mean_cv_acc = np.mean(cv_scores)
        if fold_fail_count > 0:
            logger.info(f"   Trial {trial.number} æ±‡æ€»ï¼šå¤±è´¥fold={fold_fail_count}/5ï¼ŒCV={mean_cv_acc:.4f}")
        
        # æ¯10æ¬¡è¯•éªŒæŠ¥å‘Šä¸€æ¬¡è¿›åº¦
        if trial.number % 10 == 0:
            logger.info(f"   Trial {trial.number}: CVå‡†ç¡®ç‡={mean_cv_acc:.4f}")
        
        # è¿”å›è´Ÿå€¼ï¼ˆOptunaæœ€å°åŒ–ç›®æ ‡ï¼‰
        return -mean_cv_acc
    
    def optimize(
        self,
        n_trials: int = 100,
        timeout: int = 1800,
        show_progress: bool = True
    ) -> Dict[str, Any]:
        """
        æ‰§è¡Œè¶…å‚æ•°ä¼˜åŒ–
        
        Args:
            n_trials: è¯•éªŒæ¬¡æ•°ï¼ˆé»˜è®¤100æ¬¡ï¼‰
            timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼Œé»˜è®¤30åˆ†é’Ÿï¼‰
            show_progress: æ˜¯å¦æ˜¾ç¤ºè¿›åº¦æ¡
        
        Returns:
            æœ€ä½³å‚æ•°å­—å…¸
        """
        logger.info(f"ğŸš€ å¼€å§‹è¶…å‚æ•°ä¼˜åŒ–: {self.timeframe} - {self.model_type}")
        logger.info(f"   è¯•éªŒæ¬¡æ•°: {n_trials}, è¶…æ—¶: {timeout}ç§’ (~{timeout//60}åˆ†é’Ÿ)")
        
        # åˆ›å»ºstudyï¼ˆé™é»˜æ¨¡å¼ï¼Œé¿å…è¿‡å¤šæ—¥å¿—ï¼‰
        optuna.logging.set_verbosity(optuna.logging.WARNING)
        
        study = optuna.create_study(
            direction='minimize',  # æœ€å°åŒ–è´Ÿå‡†ç¡®ç‡
            sampler=TPESampler(seed=42)
        )
        
        # æ‰§è¡Œä¼˜åŒ–
        try:
            study.optimize(
                self.objective,
                n_trials=n_trials,
                timeout=timeout,
                show_progress_bar=show_progress,
                n_jobs=1  # å•çº¿ç¨‹ï¼ˆé¿å…å¹¶å‘é—®é¢˜ï¼‰
            )
        except KeyboardInterrupt:
            logger.warning("âš ï¸ ä¼˜åŒ–è¢«ç”¨æˆ·ä¸­æ–­")
        
        # ä¿å­˜æœ€ä½³å‚æ•°
        self.best_params = study.best_params
        self.best_score = -study.best_value  # è½¬å›æ­£å‡†ç¡®ç‡
        
        logger.info(f"âœ… {self.timeframe} è¶…å‚æ•°ä¼˜åŒ–å®Œæˆ!")
        logger.info(f"   æœ€ä½³CVå‡†ç¡®ç‡: {self.best_score:.4f} ({self.best_score*100:.2f}%)")
        logger.info(f"   æœ€ä½³å‚æ•°: {self.best_params}")
        logger.info(f"   æ€»è¯•éªŒæ¬¡æ•°: {len(study.trials)}")
        
        # æ˜¾ç¤ºå‚æ•°é‡è¦æ€§ï¼ˆTop 5ï¼‰
        try:
            importances = optuna.importance.get_param_importances(study)
            logger.info(f"   å‚æ•°é‡è¦æ€§ï¼ˆTop 5ï¼‰:")
            for i, (param, importance) in enumerate(list(importances.items())[:5]):
                logger.info(f"      {i+1}. {param}: {importance:.4f}")
        except:
            pass
        
        return self.best_params
    
    def get_optimized_params(self) -> Dict[str, Any]:
        """
        è·å–ä¼˜åŒ–åçš„å‚æ•°
        
        Returns:
            æœ€ä½³å‚æ•°å­—å…¸ï¼Œå¦‚æœæœªä¼˜åŒ–åˆ™è¿”å›None
        """
        return self.best_params

