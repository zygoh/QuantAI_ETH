"""
æ¨¡å‹ç¨³å®šæ€§å¢å¼ºæ¨¡å—
é€šè¿‡baggingå’Œæ¨¡å‹å¤šæ ·æ€§æå‡ç³»ç»Ÿç¨³å®šæ€§

æ ¸å¿ƒåŠŸèƒ½ï¼š
1. Baggingé›†æˆç­–ç•¥
2. æ¨¡å‹å¤šæ ·æ€§å¢å¼º
3. ç¨³å®šæ€§æŒ‡æ ‡ç›‘æ§
4. åŠ¨æ€æƒé‡è°ƒæ•´

ä½œè€…: QuantAI-ETH Team
ç‰ˆæœ¬: v3.0
"""

import logging
import numpy as np
import pandas as pd
from typing import Dict, List, Tuple, Optional, Any
from dataclasses import dataclass
from sklearn.model_selection import TimeSeriesSplit
from sklearn.metrics import accuracy_score
import lightgbm as lgb
import xgboost as xgb
import catboost as cb
from sklearn.utils import resample

logger = logging.getLogger(__name__)


@dataclass
class ModelStabilityMetrics:
    """æ¨¡å‹ç¨³å®šæ€§æŒ‡æ ‡"""
    cv_stability: float
    model_diversity: float
    prediction_consistency: float
    bagging_effectiveness: float
    stability_score: float


class ModelStabilityEnhancer:
    """
    æ¨¡å‹ç¨³å®šæ€§å¢å¼ºå™¨
    
    æ ¸å¿ƒåŠŸèƒ½ï¼š
    1. Baggingé›†æˆç­–ç•¥
    2. æ¨¡å‹å¤šæ ·æ€§å¢å¼º
    3. ç¨³å®šæ€§æŒ‡æ ‡ç›‘æ§
    4. åŠ¨æ€æƒé‡è°ƒæ•´
    """
    
    def __init__(self):
        # Baggingå‚æ•°
        self.n_bagging_models = 5  # Baggingæ¨¡å‹æ•°é‡
        self.bootstrap_ratio = 0.8  # è‡ªåŠ©é‡‡æ ·æ¯”ä¾‹
        self.feature_sampling_ratio = 0.8  # ç‰¹å¾é‡‡æ ·æ¯”ä¾‹
        
        # å¤šæ ·æ€§å‚æ•°
        self.diversity_threshold = 0.3  # å¤šæ ·æ€§é˜ˆå€¼
        self.stability_threshold = 0.8  # ç¨³å®šæ€§é˜ˆå€¼
        
        # å†å²è®°å½•
        self.stability_history: List[ModelStabilityMetrics] = []
        
        logger.info("âœ… æ¨¡å‹ç¨³å®šæ€§å¢å¼ºå™¨åˆå§‹åŒ–å®Œæˆ")
    
    def create_bagging_models(
        self,
        X: np.ndarray,
        y: np.ndarray,
        model_type: str,
        base_params: Dict[str, Any],
        n_models: int = None
    ) -> List[Any]:
        """
        åˆ›å»ºBaggingæ¨¡å‹é›†åˆ
        
        Args:
            X: ç‰¹å¾æ•°æ®
            y: æ ‡ç­¾æ•°æ®
            model_type: æ¨¡å‹ç±»å‹
            base_params: åŸºç¡€å‚æ•°
            n_models: æ¨¡å‹æ•°é‡
        
        Returns:
            List[Any]: Baggingæ¨¡å‹åˆ—è¡¨
        """
        try:
            if n_models is None:
                n_models = self.n_bagging_models
            
            bagging_models = []
            
            for i in range(n_models):
                # 1. è‡ªåŠ©é‡‡æ ·
                n_samples = int(len(X) * self.bootstrap_ratio)
                bootstrap_indices = resample(
                    range(len(X)), 
                    n_samples=n_samples, 
                    random_state=42 + i
                )
                
                X_bootstrap = X[bootstrap_indices]
                y_bootstrap = y[bootstrap_indices]
                
                # 2. ç‰¹å¾é‡‡æ ·
                if len(X.shape) == 2:  # 2Dæ•°æ®
                    n_features = X.shape[1]
                    n_selected_features = int(n_features * self.feature_sampling_ratio)
                    feature_indices = resample(
                        range(n_features),
                        n_samples=n_selected_features,
                        random_state=42 + i
                    )
                    X_bootstrap = X_bootstrap[:, feature_indices]
                elif len(X.shape) == 3:  # 3Dæ•°æ®ï¼ˆåºåˆ—ï¼‰
                    n_features = X.shape[2]
                    n_selected_features = int(n_features * self.feature_sampling_ratio)
                    feature_indices = resample(
                        range(n_features),
                        n_samples=n_selected_features,
                        random_state=42 + i
                    )
                    X_bootstrap = X_bootstrap[:, :, feature_indices]
                
                # 3. è®­ç»ƒæ¨¡å‹
                model = self._create_single_model(model_type, base_params, i)
                
                if model_type == "lightgbm":
                    model.fit(X_bootstrap, y_bootstrap)
                elif model_type == "xgboost":
                    model.fit(X_bootstrap, y_bootstrap)
                elif model_type == "catboost":
                    model.fit(X_bootstrap, y_bootstrap, verbose=False)
                
                bagging_models.append({
                    'model': model,
                    'feature_indices': feature_indices if len(X.shape) == 2 else None,
                    'bootstrap_indices': bootstrap_indices
                })
                
                logger.debug(f"âœ… Baggingæ¨¡å‹ {i+1}/{n_models} è®­ç»ƒå®Œæˆ")
            
            logger.info(f"ğŸ¯ åˆ›å»ºäº† {len(bagging_models)} ä¸ªBaggingæ¨¡å‹")
            return bagging_models
            
        except Exception as e:
            logger.error(f"âŒ Baggingæ¨¡å‹åˆ›å»ºå¤±è´¥: {e}")
            return []
    
    def _create_single_model(self, model_type: str, base_params: Dict[str, Any], seed: int) -> Any:
        """åˆ›å»ºå•ä¸ªæ¨¡å‹"""
        try:
            params = base_params.copy()
            
            if model_type == "lightgbm":
                params['random_state'] = seed
                params['verbose'] = -1
                return lgb.LGBMClassifier(**params)
            elif model_type == "xgboost":
                params['random_state'] = seed
                params['verbosity'] = 0
                return xgb.XGBClassifier(**params)
            elif model_type == "catboost":
                params['random_seed'] = seed
                params['verbose'] = False
                return cb.CatBoostClassifier(**params)
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹: {model_type}")
                
        except Exception as e:
            logger.error(f"âŒ å•æ¨¡å‹åˆ›å»ºå¤±è´¥: {e}")
            return None
    
    def predict_with_bagging(
        self,
        bagging_models: List[Dict],
        X: np.ndarray,
        return_proba: bool = True
    ) -> Tuple[np.ndarray, np.ndarray]:
        """
        ä½¿ç”¨Baggingæ¨¡å‹è¿›è¡Œé¢„æµ‹
        
        Args:
            bagging_models: Baggingæ¨¡å‹åˆ—è¡¨
            X: ç‰¹å¾æ•°æ®
            return_proba: æ˜¯å¦è¿”å›æ¦‚ç‡
        
        Returns:
            Tuple[np.ndarray, np.ndarray]: (é¢„æµ‹ç»“æœ, é¢„æµ‹æ¦‚ç‡)
        """
        try:
            if not bagging_models:
                raise ValueError("Baggingæ¨¡å‹åˆ—è¡¨ä¸ºç©º")
            
            predictions = []
            probabilities = []
            
            for model_info in bagging_models:
                model = model_info['model']
                feature_indices = model_info.get('feature_indices')
                
                # ç‰¹å¾é€‰æ‹©
                if feature_indices is not None:
                    if len(X.shape) == 2:
                        X_selected = X[:, feature_indices]
                    else:  # 3Dæ•°æ®
                        X_selected = X[:, :, feature_indices]
                else:
                    X_selected = X
                
                # é¢„æµ‹
                if return_proba:
                    proba = model.predict_proba(X_selected)
                    probabilities.append(proba)
                
                pred = model.predict(X_selected)
                predictions.append(pred)
            
            # é›†æˆé¢„æµ‹
            predictions = np.array(predictions)
            ensemble_pred = np.round(np.mean(predictions, axis=0)).astype(int)
            
            if return_proba and probabilities:
                probabilities = np.array(probabilities)
                ensemble_proba = np.mean(probabilities, axis=0)
            else:
                ensemble_proba = None
            
            logger.debug(f"ğŸ¯ Baggingé¢„æµ‹å®Œæˆ: {len(bagging_models)}ä¸ªæ¨¡å‹é›†æˆ")
            
            return ensemble_pred, ensemble_proba
            
        except Exception as e:
            logger.error(f"âŒ Baggingé¢„æµ‹å¤±è´¥: {e}")
            return np.array([]), np.array([])
    
    def calculate_model_diversity(
        self,
        predictions_list: List[np.ndarray]
    ) -> float:
        """
        è®¡ç®—æ¨¡å‹å¤šæ ·æ€§
        
        Args:
            predictions_list: é¢„æµ‹ç»“æœåˆ—è¡¨
        
        Returns:
            float: å¤šæ ·æ€§åˆ†æ•°
        """
        try:
            if len(predictions_list) < 2:
                return 0.0
            
            n_models = len(predictions_list)
            n_samples = len(predictions_list[0])
            
            # è®¡ç®—æ¨¡å‹é—´çš„ä¸ä¸€è‡´åº¦
            disagreements = 0
            total_comparisons = 0
            
            for i in range(n_models):
                for j in range(i + 1, n_models):
                    pred_i = predictions_list[i]
                    pred_j = predictions_list[j]
                    
                    # è®¡ç®—ä¸ä¸€è‡´çš„æ ·æœ¬æ•°
                    disagreement = np.sum(pred_i != pred_j)
                    disagreements += disagreement
                    total_comparisons += n_samples
            
            # å¤šæ ·æ€§åˆ†æ•°ï¼ˆä¸ä¸€è‡´åº¦æ¯”ä¾‹ï¼‰
            diversity = disagreements / total_comparisons if total_comparisons > 0 else 0.0
            
            logger.debug(f"ğŸ” æ¨¡å‹å¤šæ ·æ€§: {diversity:.3f}")
            return diversity
            
        except Exception as e:
            logger.error(f"âŒ æ¨¡å‹å¤šæ ·æ€§è®¡ç®—å¤±è´¥: {e}")
            return 0.0
    
    def calculate_prediction_consistency(
        self,
        predictions_list: List[np.ndarray],
        true_labels: np.ndarray
    ) -> float:
        """
        è®¡ç®—é¢„æµ‹ä¸€è‡´æ€§
        
        Args:
            predictions_list: é¢„æµ‹ç»“æœåˆ—è¡¨
            true_labels: çœŸå®æ ‡ç­¾
        
        Returns:
            float: ä¸€è‡´æ€§åˆ†æ•°
        """
        try:
            if not predictions_list or len(true_labels) == 0:
                return 0.0
            
            # è®¡ç®—æ¯ä¸ªæ¨¡å‹çš„å‡†ç¡®ç‡
            accuracies = []
            for pred in predictions_list:
                if len(pred) == len(true_labels):
                    acc = accuracy_score(true_labels, pred)
                    accuracies.append(acc)
            
            if not accuracies:
                return 0.0
            
            # ä¸€è‡´æ€§åˆ†æ•°ï¼ˆå‡†ç¡®ç‡çš„æ ‡å‡†å·®ï¼Œè¶Šå°è¶Šä¸€è‡´ï¼‰
            consistency = 1.0 - np.std(accuracies)
            
            logger.debug(f"ğŸ” é¢„æµ‹ä¸€è‡´æ€§: {consistency:.3f}")
            return max(0.0, consistency)
            
        except Exception as e:
            logger.error(f"âŒ é¢„æµ‹ä¸€è‡´æ€§è®¡ç®—å¤±è´¥: {e}")
            return 0.0
    
    def calculate_bagging_effectiveness(
        self,
        individual_accuracies: List[float],
        ensemble_accuracy: float
    ) -> float:
        """
        è®¡ç®—Baggingæœ‰æ•ˆæ€§
        
        Args:
            individual_accuracies: å•ä¸ªæ¨¡å‹å‡†ç¡®ç‡
            ensemble_accuracy: é›†æˆæ¨¡å‹å‡†ç¡®ç‡
        
        Returns:
            float: Baggingæœ‰æ•ˆæ€§åˆ†æ•°
        """
        try:
            if not individual_accuracies:
                return 0.0
            
            # å•ä¸ªæ¨¡å‹å¹³å‡å‡†ç¡®ç‡
            avg_individual_acc = np.mean(individual_accuracies)
            
            # Baggingæœ‰æ•ˆæ€§ï¼ˆé›†æˆæå‡ï¼‰
            effectiveness = ensemble_accuracy - avg_individual_acc
            
            logger.debug(f"ğŸ” Baggingæœ‰æ•ˆæ€§: {effectiveness:.3f}")
            return max(0.0, effectiveness)
            
        except Exception as e:
            logger.error(f"âŒ Baggingæœ‰æ•ˆæ€§è®¡ç®—å¤±è´¥: {e}")
            return 0.0
    
    def calculate_stability_metrics(
        self,
        X: np.ndarray,
        y: np.ndarray,
        bagging_models: List[Dict],
        cv_folds: int = 5
    ) -> ModelStabilityMetrics:
        """
        è®¡ç®—æ¨¡å‹ç¨³å®šæ€§æŒ‡æ ‡
        
        Args:
            X: ç‰¹å¾æ•°æ®
            y: æ ‡ç­¾æ•°æ®
            bagging_models: Baggingæ¨¡å‹åˆ—è¡¨
            cv_folds: äº¤å‰éªŒè¯æŠ˜æ•°
        
        Returns:
            ModelStabilityMetrics: ç¨³å®šæ€§æŒ‡æ ‡
        """
        try:
            # 1. äº¤å‰éªŒè¯ç¨³å®šæ€§
            cv_stability = self._calculate_cv_stability(X, y, bagging_models, cv_folds)
            
            # 2. æ¨¡å‹å¤šæ ·æ€§
            predictions_list = []
            for model_info in bagging_models:
                model = model_info['model']
                feature_indices = model_info.get('feature_indices')
                
                if feature_indices is not None:
                    if len(X.shape) == 2:
                        X_selected = X[:, feature_indices]
                    else:
                        X_selected = X[:, :, feature_indices]
                else:
                    X_selected = X
                
                pred = model.predict(X_selected)
                predictions_list.append(pred)
            
            model_diversity = self.calculate_model_diversity(predictions_list)
            
            # 3. é¢„æµ‹ä¸€è‡´æ€§
            prediction_consistency = self.calculate_prediction_consistency(predictions_list, y)
            
            # 4. Baggingæœ‰æ•ˆæ€§
            individual_accuracies = []
            for pred in predictions_list:
                if len(pred) == len(y):
                    acc = accuracy_score(y, pred)
                    individual_accuracies.append(acc)
            
            ensemble_pred, _ = self.predict_with_bagging(bagging_models, X, return_proba=False)
            ensemble_accuracy = accuracy_score(y, ensemble_pred) if len(ensemble_pred) == len(y) else 0.0
            
            bagging_effectiveness = self.calculate_bagging_effectiveness(individual_accuracies, ensemble_accuracy)
            
            # 5. ç»¼åˆç¨³å®šæ€§åˆ†æ•°
            stability_score = (
                cv_stability * 0.3 +
                model_diversity * 0.2 +
                prediction_consistency * 0.3 +
                bagging_effectiveness * 0.2
            )
            
            metrics = ModelStabilityMetrics(
                cv_stability=cv_stability,
                model_diversity=model_diversity,
                prediction_consistency=prediction_consistency,
                bagging_effectiveness=bagging_effectiveness,
                stability_score=stability_score
            )
            
            logger.info(f"ğŸ“Š ç¨³å®šæ€§æŒ‡æ ‡: CVç¨³å®šæ€§={cv_stability:.3f}, "
                       f"æ¨¡å‹å¤šæ ·æ€§={model_diversity:.3f}, "
                       f"é¢„æµ‹ä¸€è‡´æ€§={prediction_consistency:.3f}, "
                       f"Baggingæœ‰æ•ˆæ€§={bagging_effectiveness:.3f}, "
                       f"ç»¼åˆç¨³å®šæ€§={stability_score:.3f}")
            
            return metrics
            
        except Exception as e:
            logger.error(f"âŒ ç¨³å®šæ€§æŒ‡æ ‡è®¡ç®—å¤±è´¥: {e}")
            return ModelStabilityMetrics(
                cv_stability=0.0,
                model_diversity=0.0,
                prediction_consistency=0.0,
                bagging_effectiveness=0.0,
                stability_score=0.0
            )
    
    def _calculate_cv_stability(
        self,
        X: np.ndarray,
        y: np.ndarray,
        bagging_models: List[Dict],
        cv_folds: int
    ) -> float:
        """è®¡ç®—äº¤å‰éªŒè¯ç¨³å®šæ€§"""
        try:
            tscv = TimeSeriesSplit(n_splits=cv_folds)
            cv_scores = []
            
            for train_idx, val_idx in tscv.split(X):
                X_val = X[val_idx]
                y_val = y[val_idx]
                
                # ä½¿ç”¨Baggingæ¨¡å‹é¢„æµ‹
                ensemble_pred, _ = self.predict_with_bagging(bagging_models, X_val, return_proba=False)
                
                if len(ensemble_pred) == len(y_val):
                    score = accuracy_score(y_val, ensemble_pred)
                    cv_scores.append(score)
            
            if not cv_scores:
                return 0.0
            
            # ç¨³å®šæ€§ = 1 - å˜å¼‚ç³»æ•°
            cv_mean = np.mean(cv_scores)
            cv_std = np.std(cv_scores)
            stability = 1.0 - (cv_std / cv_mean) if cv_mean > 0 else 0.0
            
            return max(0.0, stability)
            
        except Exception as e:
            logger.error(f"âŒ CVç¨³å®šæ€§è®¡ç®—å¤±è´¥: {e}")
            return 0.0
    
    def get_stability_recommendations(
        self,
        metrics: ModelStabilityMetrics
    ) -> List[str]:
        """
        è·å–ç¨³å®šæ€§æ”¹è¿›å»ºè®®
        
        Args:
            metrics: ç¨³å®šæ€§æŒ‡æ ‡
        
        Returns:
            List[str]: æ”¹è¿›å»ºè®®
        """
        recommendations = []
        
        if metrics.cv_stability < self.stability_threshold:
            recommendations.append("CVç¨³å®šæ€§è¾ƒä½ï¼Œå»ºè®®å¢åŠ æ­£åˆ™åŒ–å‚æ•°")
        
        if metrics.model_diversity < self.diversity_threshold:
            recommendations.append("æ¨¡å‹å¤šæ ·æ€§ä¸è¶³ï¼Œå»ºè®®å¢åŠ ç‰¹å¾é‡‡æ ·æ¯”ä¾‹")
        
        if metrics.prediction_consistency < 0.7:
            recommendations.append("é¢„æµ‹ä¸€è‡´æ€§è¾ƒä½ï¼Œå»ºè®®è°ƒæ•´æ¨¡å‹å‚æ•°")
        
        if metrics.bagging_effectiveness < 0.05:
            recommendations.append("Baggingæ•ˆæœä¸æ˜æ˜¾ï¼Œå»ºè®®å¢åŠ æ¨¡å‹æ•°é‡")
        
        if metrics.stability_score < 0.6:
            recommendations.append("ç»¼åˆç¨³å®šæ€§è¾ƒä½ï¼Œå»ºè®®å…¨é¢ä¼˜åŒ–æ¨¡å‹é…ç½®")
        
        return recommendations
