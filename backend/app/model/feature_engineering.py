"""
ç‰¹å¾å·¥ç¨‹æ¨¡å—
"""
import logging
import traceback
from typing import Dict, List, Any, Optional
import pandas as pd
import numpy as np
from datetime import datetime
import ta

logger = logging.getLogger(__name__)

class FeatureEngineer:
    """ç‰¹å¾å·¥ç¨‹å™¨"""
    
    def __init__(self):
        self.feature_columns = []
    
    def create_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """åˆ›å»ºæ‰€æœ‰ç‰¹å¾"""
        try:
            if df.empty:
                return df
            
            logger.info(f"ğŸ”§ å¼€å§‹ç‰¹å¾å·¥ç¨‹: {len(df)}è¡ŒåŸå§‹æ•°æ®")
            
            # âœ… è¯¦ç»†è¯Šæ–­ï¼šè®°å½•åŸå§‹æ•°æ®çŠ¶æ€
            logger.info(f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
            logger.info(f"ğŸ“Š ç‰¹å¾å·¥ç¨‹ - åŸå§‹æ•°æ®è¯¦ç»†è¯Šæ–­")
            logger.info(f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
            logger.info(f"   æ•°æ®å½¢çŠ¶: {df.shape}")
            logger.info(f"   åˆ—å: {list(df.columns)}")
            
            # è¯¦ç»†æ£€æŸ¥å…³é”®å­—æ®µ
            if 'close' in df.columns:
                close_stats = {
                    'count': len(df['close']),
                    'non_null': df['close'].notna().sum(),
                    'null': df['close'].isna().sum(),
                    'zero': (df['close'] == 0).sum(),
                    'negative': (df['close'] < 0).sum(),
                    'min': df['close'].min() if df['close'].notna().any() else None,
                    'max': df['close'].max() if df['close'].notna().any() else None,
                    'mean': df['close'].mean() if df['close'].notna().any() else None,
                    'inf': np.isinf(df['close']).sum() if df['close'].notna().any() else 0
                }
                logger.info(f"   ğŸ“ˆ closeä»·æ ¼ç»Ÿè®¡:")
                logger.info(f"      æ€»æ•°: {close_stats['count']}, éç©º: {close_stats['non_null']}, ç©ºå€¼: {close_stats['null']}")
                logger.info(f"      é›¶å€¼: {close_stats['zero']}, è´Ÿå€¼: {close_stats['negative']}, æ— ç©·å¤§: {close_stats['inf']}")
                if close_stats['non_null'] > 0:
                    logger.info(f"      èŒƒå›´: [{close_stats['min']:.4f}, {close_stats['max']:.4f}], å‡å€¼: {close_stats['mean']:.4f}")
                
                # âœ… è¯¦ç»†è®°å½•é›¶å€¼ä½ç½®
                if close_stats['zero'] > 0:
                    zero_indices = df[df['close'] == 0].index.tolist()
                    logger.error(f"   âŒ å‘ç°{close_stats['zero']}ä¸ªcloseä¸º0çš„ä½ç½®:")
                    for idx in zero_indices[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
                        row = df.loc[idx]
                        logger.error(f"      ç´¢å¼•{idx}: close=0, open={row.get('open', 'N/A')}, high={row.get('high', 'N/A')}, low={row.get('low', 'N/A')}, volume={row.get('volume', 'N/A')}")
                    if len(zero_indices) > 10:
                        logger.error(f"      ... è¿˜æœ‰{len(zero_indices) - 10}ä¸ªé›¶å€¼æœªæ˜¾ç¤º")
            
            if 'volume' in df.columns:
                volume_stats = {
                    'count': len(df['volume']),
                    'non_null': df['volume'].notna().sum(),
                    'null': df['volume'].isna().sum(),
                    'zero': (df['volume'] == 0).sum(),
                    'negative': (df['volume'] < 0).sum(),
                    'min': df['volume'].min() if df['volume'].notna().any() else None,
                    'max': df['volume'].max() if df['volume'].notna().any() else None,
                    'mean': df['volume'].mean() if df['volume'].notna().any() else None,
                    'inf': np.isinf(df['volume']).sum() if df['volume'].notna().any() else 0
                }
                logger.info(f"   ğŸ“Š volumeæˆäº¤é‡ç»Ÿè®¡:")
                logger.info(f"      æ€»æ•°: {volume_stats['count']}, éç©º: {volume_stats['non_null']}, ç©ºå€¼: {volume_stats['null']}")
                logger.info(f"      é›¶å€¼: {volume_stats['zero']}, è´Ÿå€¼: {volume_stats['negative']}, æ— ç©·å¤§: {volume_stats['inf']}")
                if volume_stats['non_null'] > 0:
                    logger.info(f"      èŒƒå›´: [{volume_stats['min']:.4f}, {volume_stats['max']:.4f}], å‡å€¼: {volume_stats['mean']:.4f}")
                
                # âœ… è¯¦ç»†è®°å½•é›¶å€¼ä½ç½®
                if volume_stats['zero'] > 0:
                    zero_indices = df[df['volume'] == 0].index.tolist()
                    logger.warning(f"   âš ï¸ å‘ç°{volume_stats['zero']}ä¸ªvolumeä¸º0çš„ä½ç½®ï¼ˆå‰10ä¸ªï¼‰:")
                    for idx in zero_indices[:10]:
                        row = df.loc[idx]
                        logger.error(f"      ç´¢å¼•{idx}:row={row}")
                        logger.warning(f"      ç´¢å¼•{idx}: volume=0, close={row.get('close', 'N/A')}")
            
            # âœ… å…³é”®ä¿®å¤ï¼šæ•°æ®è´¨é‡éªŒè¯ï¼ˆé˜²æ­¢close/volumeä¸º0å¯¼è‡´infï¼‰
            if 'close' in df.columns:
                zero_close_count = (df['close'] == 0).sum()
                if zero_close_count > 0:
                    logger.error(f"âŒ æ£€æµ‹åˆ°{zero_close_count}ä¸ªcloseä»·æ ¼ä¸º0ï¼Œå°†æ›¿æ¢ä¸ºNaN")
                    logger.error(f"   æ›¿æ¢å‰ï¼Œæ£€æŸ¥è¿™äº›è¡Œçš„å…¶ä»–å­—æ®µ:")
                    zero_close_rows = df[df['close'] == 0]
                    for idx, row in zero_close_rows.head(5).iterrows():
                        logger.error(f"      ç´¢å¼•{idx}: open={row.get('open', 'N/A')}, high={row.get('high', 'N/A')}, low={row.get('low', 'N/A')}, volume={row.get('volume', 'N/A')}")
                    df.loc[df['close'] == 0, 'close'] = np.nan
                    # å¦‚æœcloseä¸º0ï¼Œå¯¹åº”çš„high/low/openä¹Ÿåº”è¯¥ä¸ºNaN
                    df.loc[df['close'].isna(), ['high', 'low', 'open']] = np.nan
                    logger.info(f"   âœ… å·²å°†{zero_close_count}ä¸ªclose=0æ›¿æ¢ä¸ºNaN")
            
            if 'volume' in df.columns:
                zero_volume_count = (df['volume'] == 0).sum()
                if zero_volume_count > 0:
                    logger.warning(f"âš ï¸ æ£€æµ‹åˆ°{zero_volume_count}ä¸ªvolumeä¸º0ï¼ˆå¯èƒ½æ˜¯å¼‚å¸¸æ•°æ®æˆ–æä½æµåŠ¨æ€§ï¼‰")
                    # æ³¨æ„ï¼švolumeä¸º0åœ¨ç°å®ä¸­å¯èƒ½å­˜åœ¨ï¼ˆæä½æµåŠ¨æ€§ï¼‰ï¼Œä½†ä¸ºäº†è®¡ç®—ç¨³å®šæ€§ï¼Œæˆ‘ä»¬æ ‡è®°ä¸ºNaN
                    # å¯ä»¥æ ¹æ®ä¸šåŠ¡éœ€æ±‚å†³å®šæ˜¯å¦æ›¿æ¢
            
            # å¤„ç† timestampï¼šå¦‚æœæ˜¯ indexï¼Œé‡ç½®ä¸ºåˆ—
            if df.index.name == 'timestamp' or 'timestamp' not in df.columns:
                df = df.reset_index()
            
            # ğŸ”¥ ç¡®ä¿ timestamp åˆ—æ˜¯ç»Ÿä¸€çš„ datetime ç±»å‹ï¼ˆé¿å…æ··åˆç±»å‹å¯¼è‡´æ’åºå¤±è´¥ï¼‰
            if 'timestamp' in df.columns:
                if not pd.api.types.is_datetime64_any_dtype(df['timestamp']):
                    df['timestamp'] = pd.to_datetime(df['timestamp'])
            
            # ç¡®ä¿æ•°æ®æŒ‰æ—¶é—´æ’åº
            df = df.sort_values('timestamp').reset_index(drop=True)
            
            # âœ… è¯¦ç»†è¿½è¸ªï¼šåœ¨æ¯ä¸ªç‰¹å¾æ·»åŠ æ­¥éª¤åæ£€æŸ¥inf
            inf_tracker = {}  # è¿½è¸ªæ¯ä¸ªæ­¥éª¤äº§ç”Ÿçš„inf
            
            # åŸºç¡€ä»·æ ¼ç‰¹å¾
            logger.debug(f"   ğŸ”§ æ­¥éª¤1: æ·»åŠ ä»·æ ¼ç‰¹å¾...")
            df_before = df.copy()
            df = self._add_price_features(df)
            inf_after_price = sum(np.isinf(df[col]).sum() for col in df.columns if col != 'timestamp' and pd.api.types.is_numeric_dtype(df[col]))
            if inf_after_price > 0:
                inf_tracker['_add_price_features'] = inf_after_price
                logger.warning(f"      âš ï¸ ä»·æ ¼ç‰¹å¾åäº§ç”Ÿ{inf_after_price}ä¸ªinfå€¼")
            
            # æŠ€æœ¯æŒ‡æ ‡ç‰¹å¾
            logger.debug(f"   ğŸ”§ æ­¥éª¤2: æ·»åŠ æŠ€æœ¯æŒ‡æ ‡ç‰¹å¾...")
            df = self._add_technical_indicators(df)
            inf_after_tech = sum(np.isinf(df[col]).sum() for col in df.columns if col != 'timestamp' and pd.api.types.is_numeric_dtype(df[col]))
            if inf_after_tech > inf_after_price:
                new_inf = inf_after_tech - inf_after_price
                inf_tracker['_add_technical_indicators'] = new_inf
                logger.warning(f"      âš ï¸ æŠ€æœ¯æŒ‡æ ‡ç‰¹å¾æ–°å¢{new_inf}ä¸ªinfå€¼ï¼ˆç´¯è®¡{inf_after_tech}ï¼‰")
            
            # æˆäº¤é‡ç‰¹å¾
            logger.debug(f"   ğŸ”§ æ­¥éª¤3: æ·»åŠ æˆäº¤é‡ç‰¹å¾...")
            df = self._add_volume_features(df)
            inf_after_volume = sum(np.isinf(df[col]).sum() for col in df.columns if col != 'timestamp' and pd.api.types.is_numeric_dtype(df[col]))
            if inf_after_volume > inf_after_tech:
                new_inf = inf_after_volume - inf_after_tech
                inf_tracker['_add_volume_features'] = new_inf
                logger.warning(f"      âš ï¸ æˆäº¤é‡ç‰¹å¾æ–°å¢{new_inf}ä¸ªinfå€¼ï¼ˆç´¯è®¡{inf_after_volume}ï¼‰")
            
            # æ—¶é—´ç‰¹å¾
            logger.debug(f"   ğŸ”§ æ­¥éª¤4: æ·»åŠ æ—¶é—´ç‰¹å¾...")
            df = self._add_time_features(df)
            
            # å¸‚åœºå¾®è§‚ç»“æ„ç‰¹å¾
            logger.debug(f"   ğŸ”§ æ­¥éª¤5: æ·»åŠ å¸‚åœºå¾®è§‚ç»“æ„ç‰¹å¾...")
            df = self._add_microstructure_features(df)
            inf_after_micro = sum(np.isinf(df[col]).sum() for col in df.columns if col != 'timestamp' and pd.api.types.is_numeric_dtype(df[col]))
            if inf_after_micro > inf_after_volume:
                new_inf = inf_after_micro - inf_after_volume
                inf_tracker['_add_microstructure_features'] = new_inf
                logger.warning(f"      âš ï¸ å¾®è§‚ç»“æ„ç‰¹å¾æ–°å¢{new_inf}ä¸ªinfå€¼ï¼ˆç´¯è®¡{inf_after_micro}ï¼‰")
            
            # æ³¢åŠ¨ç‡ç‰¹å¾
            logger.debug(f"   ğŸ”§ æ­¥éª¤6: æ·»åŠ æ³¢åŠ¨ç‡ç‰¹å¾...")
            df = self._add_volatility_features(df)
            inf_after_vol = sum(np.isinf(df[col]).sum() for col in df.columns if col != 'timestamp' and pd.api.types.is_numeric_dtype(df[col]))
            if inf_after_vol > inf_after_micro:
                new_inf = inf_after_vol - inf_after_micro
                inf_tracker['_add_volatility_features'] = new_inf
                logger.warning(f"      âš ï¸ æ³¢åŠ¨ç‡ç‰¹å¾æ–°å¢{new_inf}ä¸ªinfå€¼ï¼ˆç´¯è®¡{inf_after_vol}ï¼‰")
            
            # åŠ¨é‡ç‰¹å¾
            logger.debug(f"   ğŸ”§ æ­¥éª¤7: æ·»åŠ åŠ¨é‡ç‰¹å¾...")
            df = self._add_momentum_features(df)
            
            # ğŸ†• å¸‚åœºæƒ…ç»ªç‰¹å¾
            logger.debug(f"   ğŸ”§ æ­¥éª¤8: æ·»åŠ å¸‚åœºæƒ…ç»ªç‰¹å¾...")
            df = self._add_sentiment_features(df)
            inf_after_sentiment = sum(np.isinf(df[col]).sum() for col in df.columns if col != 'timestamp' and pd.api.types.is_numeric_dtype(df[col]))
            if inf_after_sentiment > inf_after_vol:
                new_inf = inf_after_sentiment - inf_after_vol
                inf_tracker['_add_sentiment_features'] = new_inf
                logger.warning(f"      âš ï¸ å¸‚åœºæƒ…ç»ªç‰¹å¾æ–°å¢{new_inf}ä¸ªinfå€¼ï¼ˆç´¯è®¡{inf_after_sentiment}ï¼‰")
            
            # ğŸ†• å¤šæ—¶é—´æ¡†æ¶ç‰¹å¾èåˆ
            logger.debug(f"   ğŸ”§ æ­¥éª¤9: æ·»åŠ å¤šæ—¶é—´æ¡†æ¶ç‰¹å¾...")
            df = self._add_multi_timeframe_features(df)
            
            # ğŸ†• é«˜çº§ç‰¹å¾ï¼ˆPhase 2ä¼˜åŒ–ï¼‰
            logger.debug(f"   ğŸ”§ æ­¥éª¤10: æ·»åŠ é«˜çº§ç‰¹å¾...")
            df = self._add_trend_strength_features(df)
            df = self._add_support_resistance_features(df)
            df = self._add_advanced_momentum_features(df)
            df = self._add_pattern_features(df)
            df = self._add_order_flow_features(df)
            df = self._add_swing_features(df)
            
            # âœ… è¾“å‡ºinfè¿½è¸ªæ€»ç»“
            if inf_tracker:
                logger.warning(f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
                logger.warning(f"ğŸ“Š Infå€¼äº§ç”Ÿæ­¥éª¤è¿½è¸ª:")
                for step, count in sorted(inf_tracker.items(), key=lambda x: x[1], reverse=True):
                    logger.warning(f"   {step}: {count}ä¸ªinfå€¼")
                logger.warning(f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
            
            # ğŸ”¥ ç¬¬ä¸€æ­¥ï¼šå¤„ç†æ— ç©·å¤§å€¼ï¼ˆinfï¼‰- å¿…é¡»åœ¨NaNå¤„ç†å‰å®Œæˆï¼ˆå¢å¼ºè¯Šæ–­ï¼‰
            inf_count = 0
            inf_details = {}  # è®°å½•æ¯ä¸ªåˆ—äº§ç”Ÿinfçš„è¯¦ç»†ä¿¡æ¯
            
            for col in df.columns:
                if col != 'timestamp' and pd.api.types.is_numeric_dtype(df[col]):
                    inf_mask = np.isinf(df[col])
                    if inf_mask.any():
                        col_inf_count = inf_mask.sum()
                        inf_count += col_inf_count
                        
                        # âœ… è¯¦ç»†è¯Šæ–­ï¼šè®°å½•infçš„è¯¦ç»†ä¿¡æ¯
                        inf_indices = df[inf_mask].index.tolist()
                        inf_values = df.loc[inf_mask, col].tolist()
                        
                        # è®°å½•å‰10ä¸ªinfçš„è¯¦ç»†ä¿¡æ¯
                        sample_indices = inf_indices[:10]
                        sample_values = inf_values[:10]
                        
                        # è·å–infå‰åçš„å€¼ï¼ˆç”¨äºåˆ†æåŸå› ï¼‰
                        detail_info = []
                        for idx in sample_indices:
                            idx_pos = df.index.get_loc(idx)
                            prev_val = df[col].iloc[idx_pos - 1] if idx_pos > 0 else None
                            curr_val = df.loc[idx, col]
                            next_val = df[col].iloc[idx_pos + 1] if idx_pos < len(df) - 1 else None
                            
                            # æ£€æŸ¥æ˜¯å¦æ˜¯pct_changeäº§ç”Ÿçš„infï¼ˆå‰ä¸€ä¸ªå€¼ä¸º0æˆ–NaNï¼‰
                            if col in ['price_change', 'price_change_2', 'price_change_3', 'price_change_5', 
                                     'price_change_10', 'price_change_20', 'volume_change']:
                                if idx_pos > 0:
                                    base_col = 'close' if 'price' in col else 'volume'
                                    if base_col in df.columns:
                                        base_val = df[base_col].iloc[idx_pos - 1]
                                        detail_info.append({
                                            'index': idx,
                                            'inf_value': curr_val,
                                            f'{base_col}_prev': base_val,
                                            f'{base_col}_curr': df[base_col].iloc[idx_pos] if idx_pos < len(df) else None,
                                            'reason': f'{base_col}_prev={base_val} (å¯èƒ½æ˜¯0æˆ–NaNå¯¼è‡´pct_changeäº§ç”Ÿinf)'
                                        })
                                    else:
                                        detail_info.append({
                                            'index': idx,
                                            'inf_value': curr_val,
                                            'prev': prev_val,
                                            'next': next_val
                                        })
                                else:
                                    detail_info.append({
                                        'index': idx,
                                        'inf_value': curr_val,
                                        'reason': 'ç¬¬ä¸€ä¸ªå€¼ï¼Œæ— æ³•æ£€æŸ¥å‰å€¼'
                                    })
                            else:
                                detail_info.append({
                                    'index': idx,
                                    'inf_value': curr_val,
                                    'prev': prev_val,
                                    'next': next_val
                                })
                        
                        inf_details[col] = {
                            'count': col_inf_count,
                            'total_in_column': len(df[col]),
                            'percentage': 100.0 * col_inf_count / len(df[col]),
                            'samples': detail_info
                        }
                        
                        # å°†infæ›¿æ¢ä¸ºNaNï¼ˆåç»­ç»Ÿä¸€å¤„ç†ï¼‰
                        df.loc[inf_mask, col] = np.nan
            
            if inf_count > 0:
                logger.warning(f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
                logger.warning(f"âš ï¸ æ£€æµ‹åˆ°{inf_count}ä¸ªæ— ç©·å¤§å€¼ï¼ˆinfï¼‰ï¼Œå·²æ›¿æ¢ä¸ºNaN")
                logger.warning(f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
                logger.warning(f"ğŸ“Š Infå€¼è¯¦ç»†ç»Ÿè®¡ï¼ˆæŒ‰åˆ—ï¼‰:")
                for col, details in sorted(inf_details.items(), key=lambda x: x[1]['count'], reverse=True):
                    logger.warning(f"   {col}:")
                    logger.warning(f"      æ€»æ•°é‡: {details['count']}ä¸ª ({details['percentage']:.2f}%)")
                    logger.warning(f"      åˆ—æ€»æ•°: {details['total_in_column']}ä¸ª")
                    logger.warning(f"      è¯¦ç»†æ ·æœ¬ï¼ˆå‰{min(len(details['samples']), 5)}ä¸ªï¼‰:")
                    for i, sample in enumerate(details['samples'][:5]):
                        logger.warning(f"         æ ·æœ¬{i+1}:")
                        logger.warning(f"            è¡Œç´¢å¼•: {sample['index']}")
                        logger.warning(f"            Infå€¼: {sample['inf_value']}")
                        if 'reason' in sample:
                            logger.warning(f"            åŸå› : {sample['reason']}")
                        if 'close_prev' in sample:
                            logger.warning(f"            closeå‰å€¼: {sample['close_prev']}, closeå½“å‰å€¼: {sample['close_curr']}")
                        if 'volume_prev' in sample:
                            logger.warning(f"            volumeå‰å€¼: {sample['volume_prev']}, volumeå½“å‰å€¼: {sample['volume_curr']}")
                        if 'prev' in sample and 'next' in sample:
                            logger.warning(f"            å‰å€¼: {sample['prev']}, åå€¼: {sample['next']}")
                logger.warning(f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
            
            # ğŸ”¥ ç¬¬äºŒæ­¥ï¼šå¤„ç†è¿‡å¤§å€¼ï¼ˆå¯èƒ½å¯¼è‡´ç¼©æ”¾æ—¶æº¢å‡ºï¼‰
            large_value_threshold = 1e15  # é˜²æ­¢åç»­ç¼©æ”¾æ—¶æº¢å‡º
            large_count = 0
            for col in df.columns:
                if col != 'timestamp' and pd.api.types.is_numeric_dtype(df[col]):
                    large_mask = np.abs(df[col]) > large_value_threshold
                    if large_mask.any():
                        large_count += large_mask.sum()
                        df.loc[large_mask, col] = np.nan
            
            if large_count > 0:
                logger.warning(f"âš ï¸ æ£€æµ‹åˆ°{large_count}ä¸ªè¿‡å¤§å€¼ï¼ˆ>1e15ï¼‰ï¼Œå·²æ›¿æ¢ä¸ºNaN")
            
            # ğŸ”¥ ç¬¬ä¸‰æ­¥ï¼šå¤„ç†NaNå€¼ï¼ˆè®­ç»ƒç”¨dropnaï¼Œé¢„æµ‹ç”¨fillnaï¼‰
            rows_before = len(df)
            
            # å…ˆå°è¯•åˆ é™¤NaN
            df_clean = df.dropna()
            
            # å¦‚æœåˆ é™¤åæ•°æ®é‡<50è¡Œï¼Œè¯´æ˜æ˜¯é¢„æµ‹åœºæ™¯ï¼Œæ”¹ç”¨å¡«å……
            if len(df_clean) < 50 and rows_before >= 100:
                logger.debug(f"âš ï¸ é¢„æµ‹åœºæ™¯æ£€æµ‹ï¼šdropnaä¼šå¯¼è‡´æ•°æ®è¿‡å°‘ï¼ˆ{rows_before}â†’{len(df_clean)}ï¼‰ï¼Œæ”¹ç”¨fillna")
                # ä½¿ç”¨å‰å‘å¡«å……
                df = df.ffill()
                # å¦‚æœå‰å‘å¡«å……åä»æœ‰NaNï¼ˆå¼€å¤´çš„è¡Œï¼‰ï¼Œç”¨åå‘å¡«å……
                df = df.bfill()
                
                # âœ… å…³é”®ä¿®å¤ï¼šå¯¹äºclose/volumeç­‰å…³é”®å­—æ®µï¼Œä½¿ç”¨æ›´åˆç†çš„å¡«å……ç­–ç•¥
                # è€Œä¸æ˜¯ç®€å•åœ°ç”¨0å¡«å……ï¼ˆé¿å…å¯¼è‡´pct_changeäº§ç”Ÿinfï¼‰
                if 'close' in df.columns:
                    # closeä»·æ ¼ï¼šå¦‚æœä»æœ‰NaNï¼Œä½¿ç”¨å‰ä¸€ä¸ªæœ‰æ•ˆå€¼æˆ–åä¸€ä¸ªæœ‰æ•ˆå€¼
                    # å¦‚æœå®Œå…¨æ²¡æœ‰æœ‰æ•ˆå€¼ï¼Œä¿ç•™NaNï¼ˆä¸è¦ç”¨0ï¼‰
                    if df['close'].isna().any():
                        # å°è¯•ç”¨open/high/lowçš„å¹³å‡å€¼å¡«å……
                        for idx in df[df['close'].isna()].index:
                            if not df.loc[idx, ['open', 'high', 'low']].isna().all():
                                df.loc[idx, 'close'] = df.loc[idx, ['open', 'high', 'low']].mean()
                
                # å¯¹äºå…¶ä»–å­—æ®µï¼Œå¦‚æœä»æœ‰NaNï¼Œç”¨0å¡«å……ï¼ˆä½†close/volumeå·²å¤„ç†ï¼‰
                # ä½†ç¡®ä¿close/volumeä¸ä¼šä¸º0
                for col in df.columns:
                    if col not in ['timestamp', 'close', 'volume']:
                        df[col] = df[col].fillna(0)
                    elif col == 'volume':
                        # volumeä¸º0å¯ä»¥æ¥å—ï¼Œä½†NaNä¿ç•™ï¼ˆé¿å…å½±å“è®¡ç®—ï¼‰
                        pass
                
                # æœ€åæ£€æŸ¥ï¼šç¡®ä¿closeä¸ä¸º0
                if 'close' in df.columns:
                    zero_close = (df['close'] == 0).sum()
                    if zero_close > 0:
                        logger.warning(f"âš ï¸ é¢„æµ‹åœºæ™¯ï¼šä»æœ‰{zero_close}ä¸ªcloseä¸º0ï¼Œå°†æ›¿æ¢ä¸ºNaN")
                        df.loc[df['close'] == 0, 'close'] = np.nan
                
                logger.debug(f"âœ… ç‰¹å¾å·¥ç¨‹å®Œæˆï¼ˆé¢„æµ‹æ¨¡å¼ï¼‰: {len(df)}è¡Œï¼Œç‰¹å¾æ•°: {len(df.columns)}")
            else:
                # è®­ç»ƒåœºæ™¯ï¼Œæ­£å¸¸åˆ é™¤NaN
                df = df_clean
                rows_dropped = rows_before - len(df)
                if rows_dropped > 0:
                    logger.info(f"âœ… ç‰¹å¾å·¥ç¨‹å®Œæˆ: {len(df)}è¡Œï¼ˆå› NaN/Infä¸¢å¼ƒ{rows_dropped}è¡Œï¼‰ï¼Œç‰¹å¾æ•°: {len(df.columns)}")
                else:
                    logger.info(f"âœ… ç‰¹å¾å·¥ç¨‹å®Œæˆ: {len(df)}è¡Œï¼Œç‰¹å¾æ•°: {len(df.columns)}")

            
            return df
            
        except Exception as e:
            logger.error(f"âŒ ç‰¹å¾å·¥ç¨‹å¤±è´¥: {e}")
            logger.error(traceback.format_exc())
            return df
    
    def _add_price_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """æ·»åŠ ä»·æ ¼ç‰¹å¾ - ä¼˜åŒ–æ€§èƒ½"""
        try:
            logger.debug(f"   ğŸ“Š _add_price_features: å¼€å§‹å¤„ç†ï¼Œè¾“å…¥æ•°æ®å½¢çŠ¶: {df.shape}")
            logger.debug(f"      closeç»Ÿè®¡: min={df['close'].min():.4f}, max={df['close'].max():.4f}, "
                        f"é›¶å€¼={(df['close'] == 0).sum()}, NaN={df['close'].isna().sum()}")
            new_features = {}
            
            # ä»·æ ¼å˜åŒ–ç‡ï¼ˆä¿®å¤ï¼špct_changeåœ¨é™¤æ•°ä¸º0æ—¶ä¼šäº§ç”Ÿinfï¼‰
            # âœ… è¯¦ç»†è¯Šæ–­ï¼šæ£€æŸ¥closeæ•°æ®è´¨é‡
            close_zero_count = (df['close'] == 0).sum()
            close_nan_count = df['close'].isna().sum()
            if close_zero_count > 0 or close_nan_count > 0:
                logger.warning(f"âš ï¸ _add_price_features: closeæ•°æ®å¼‚å¸¸ - é›¶å€¼={close_zero_count}, NaN={close_nan_count}")
                if close_zero_count > 0:
                    zero_indices = df[df['close'] == 0].index.tolist()[:5]
                    logger.warning(f"   close=0çš„ä½ç½®ï¼ˆå‰5ä¸ªï¼‰: {zero_indices}")
            
            # âœ… å…³é”®ä¿®å¤ï¼šåœ¨pct_changeä¹‹å‰ï¼Œå°†close=0æ›¿æ¢ä¸ºNaNï¼ˆåŒé‡ä¿æŠ¤ï¼‰
            # å¦‚æœå…¥å£å¤„ç†å¤±è´¥ï¼Œè¿™é‡Œå†æ¬¡å¤„ç†
            if close_zero_count > 0:
                logger.warning(f"âš ï¸ _add_price_features: ä»æœ‰{close_zero_count}ä¸ªclose=0ï¼Œä¸´æ—¶æ›¿æ¢ä¸ºNaNä»¥é¿å…pct_changeäº§ç”Ÿinf")
                close_for_pct = df['close'].replace(0, np.nan)
            else:
                close_for_pct = df['close']
            
            price_change = close_for_pct.pct_change(fill_method=None)  # âœ… ä¿®å¤ï¼šæ˜ç¡®æŒ‡å®šfill_method=Noneé¿å…FutureWarning
            
            # âœ… è¯¦ç»†è¯Šæ–­ï¼šæ£€æŸ¥pct_changeäº§ç”Ÿçš„inf
            inf_mask = np.isinf(price_change)
            if inf_mask.any():
                inf_count = inf_mask.sum()
                logger.error(f"âŒ _add_price_features: price_changeäº§ç”Ÿ{inf_count}ä¸ªinfå€¼ï¼")
                inf_indices = price_change[inf_mask].index.tolist()[:5]
                for idx in inf_indices:
                    idx_pos = df.index.get_loc(idx)
                    prev_close = df['close'].iloc[idx_pos - 1] if idx_pos > 0 else None
                    curr_close = df['close'].iloc[idx_pos]
                    inf_value = price_change.iloc[idx_pos]
                    logger.error(f"   ä½ç½®{idx}: closeå‰å€¼={prev_close}, closeå½“å‰å€¼={curr_close}, pct_change={inf_value}")
                    if prev_close == 0:
                        logger.error(f"      âŒ åŸå› ç¡®è®¤ï¼šå‰ä¸€ä¸ªcloseå€¼ä¸º0ï¼Œå¯¼è‡´pct_changeäº§ç”Ÿinf")
                    elif prev_close is None or np.isnan(prev_close):
                        logger.error(f"      âŒ åŸå› ç¡®è®¤ï¼šå‰ä¸€ä¸ªcloseå€¼ä¸ºNaNï¼Œå¯¼è‡´pct_changeäº§ç”Ÿinf")
                    else:
                        logger.error(f"      âš ï¸ åŸå› ä¸æ˜ï¼šå‰ä¸€ä¸ªcloseå€¼={prev_close}ï¼ˆé0éNaNï¼‰ï¼Œä½†ä»äº§ç”Ÿinf")
            
            # âœ… ä¿®å¤ï¼šæ›¿æ¢infå€¼ï¼ˆå½“closeä»å‰ä¸€ä¸ª0å€¼å˜åŒ–æ—¶ï¼‰
            price_change = price_change.replace([np.inf, -np.inf], np.nan)
            new_features['price_change'] = price_change
            new_features['price_change_abs'] = price_change.abs()
            
            # ä»·æ ¼èŒƒå›´ï¼ˆé¿å…é™¤ä»¥é›¶ï¼‰
            close_safe = df['close'].replace(0, np.nan)  # é¿å…é™¤ä»¥0
            
            # âœ… è¯¦ç»†è¯Šæ–­ï¼šæ£€æŸ¥close_safeæ›¿æ¢åçš„æƒ…å†µ
            close_safe_zero_after = (close_safe == 0).sum()
            if close_safe_zero_after > 0:
                logger.error(f"âŒ _add_price_features: close_safeä»æœ‰{close_safe_zero_after}ä¸ª0å€¼ï¼ˆæ›¿æ¢å¤±è´¥ï¼‰")
            
            new_features['price_range'] = (df['high'] - df['low']) / close_safe
            
            # âœ… è¯¦ç»†è¯Šæ–­ï¼šæ£€æŸ¥price_rangeæ˜¯å¦äº§ç”Ÿinf
            inf_mask_price_range = np.isinf(new_features['price_range'])
            if inf_mask_price_range.any():
                inf_count = inf_mask_price_range.sum()
                logger.error(f"âŒ _add_price_features: price_rangeäº§ç”Ÿ{inf_count}ä¸ªinfå€¼ï¼")
                inf_indices = new_features['price_range'][inf_mask_price_range].index.tolist()[:3]
                for idx in inf_indices:
                    idx_pos = df.index.get_loc(idx)
                    logger.error(f"   ä½ç½®{idx}: high={df['high'].iloc[idx_pos]}, low={df['low'].iloc[idx_pos]}, close={df['close'].iloc[idx_pos]}, close_safe={close_safe.iloc[idx_pos]}")
            
            # æ³¨ï¼šupper_shadow å’Œ lower_shadow åœ¨å¸‚åœºå¾®è§‚ç»“æ„ç‰¹å¾ä¸­æ·»åŠ ï¼ˆæ›´å¥½çš„å½’ä¸€åŒ–ï¼‰
            
            # å¼€ç›˜ä»·ä¸æ”¶ç›˜ä»·å…³ç³»ï¼ˆé¿å…é™¤ä»¥é›¶ï¼‰
            new_features['open_close_ratio'] = df['open'] / close_safe
            
            # âœ… è¯¦ç»†è¯Šæ–­ï¼šæ£€æŸ¥open_close_ratioæ˜¯å¦äº§ç”Ÿinf
            inf_mask_open_close = np.isinf(new_features['open_close_ratio'])
            if inf_mask_open_close.any():
                inf_count = inf_mask_open_close.sum()
                logger.error(f"âŒ _add_price_features: open_close_ratioäº§ç”Ÿ{inf_count}ä¸ªinfå€¼ï¼")
            
            new_features['body_size'] = abs(df['close'] - df['open']) / close_safe
            
            # âœ… è¯¦ç»†è¯Šæ–­ï¼šæ£€æŸ¥body_sizeæ˜¯å¦äº§ç”Ÿinf
            inf_mask_body = np.isinf(new_features['body_size'])
            if inf_mask_body.any():
                inf_count = inf_mask_body.sum()
                logger.error(f"âŒ _add_price_features: body_sizeäº§ç”Ÿ{inf_count}ä¸ªinfå€¼ï¼")
            
            # ä»·æ ¼ä½ç½®ï¼ˆé¿å…é™¤ä»¥é›¶ï¼‰
            price_range_safe = df['high'] - df['low']
            price_range_safe = price_range_safe.replace(0, np.nan)  # é›¶èŒƒå›´è®¾ä¸ºNaN
            new_features['close_position'] = (df['close'] - df['low']) / price_range_safe
            
            # å¤šå‘¨æœŸä»·æ ¼å˜åŒ–ï¼ˆä¿®å¤ï¼špct_changeå¯èƒ½äº§ç”Ÿinfï¼‰
            # âœ… ä½¿ç”¨é¢„å¤„ç†åçš„close_for_pctï¼ˆå·²å¤„ç†0å€¼ï¼‰
            for period in [2, 3, 5, 10, 20]:
                pct_chg = close_for_pct.pct_change(period, fill_method=None)  # âœ… ä¿®å¤ï¼šæ˜ç¡®æŒ‡å®šfill_method=Noneé¿å…FutureWarning
                
                # âœ… è¯¦ç»†è¯Šæ–­ï¼šæ£€æŸ¥æ¯ä¸ªperiodçš„infæƒ…å†µï¼ˆç†è®ºä¸Šä¸åº”è¯¥æœ‰ï¼‰
                inf_mask = np.isinf(pct_chg)
                if inf_mask.any():
                    inf_count = inf_mask.sum()
                    logger.error(f"âŒ _add_price_features: price_change_{period}ä»äº§ç”Ÿ{inf_count}ä¸ªinfå€¼ï¼ˆå¼‚å¸¸ï¼ï¼‰")
                    # åªè®°å½•å‰3ä¸ªinfçš„è¯¦ç»†ä¿¡æ¯
                    inf_indices = pct_chg[inf_mask].index.tolist()[:3]
                    for idx in inf_indices:
                        idx_pos = df.index.get_loc(idx)
                        prev_close = df['close'].iloc[idx_pos - period] if idx_pos >= period else None
                        curr_close = df['close'].iloc[idx_pos]
                        prev_close_for_pct = close_for_pct.iloc[idx_pos - period] if idx_pos >= period else None
                        logger.error(f"   ä½ç½®{idx}: {period}å‘¨æœŸå‰close={prev_close}, å½“å‰close={curr_close}")
                        logger.error(f"      {period}å‘¨æœŸå‰close_for_pct={prev_close_for_pct}")
                        if prev_close == 0:
                            logger.error(f"      âŒ åŸå› ï¼š{period}å‘¨æœŸå‰close=0ï¼Œä½†é¢„å¤„ç†å¯èƒ½å¤±è´¥")
                else:
                    if close_zero_count > 0:
                        logger.debug(f"   âœ… price_change_{period}é€šè¿‡é¢„å¤„ç†é¿å…äº†infäº§ç”Ÿ")
                
                pct_chg = pct_chg.replace([np.inf, -np.inf], np.nan)  # âœ… åŒé‡ä¿æŠ¤ï¼šæ›¿æ¢inf
                new_features[f'price_change_{period}'] = pct_chg
                # é¿å…é™¤ä»¥é›¶ï¼ˆlowå¯èƒ½ä¸º0ï¼‰
                rolling_low_min = df['low'].rolling(period).min()
                rolling_low_safe = rolling_low_min.replace(0, np.nan)  # é¿å…é™¤ä»¥0
                new_features[f'high_low_ratio_{period}'] = df['high'].rolling(period).max() / rolling_low_safe
            
            # âœ… ä»·æ ¼åŠ é€Ÿåº¦ï¼ˆä¸€é˜¶ã€ä¸‰é˜¶ã€äº”é˜¶ï¼‰
            new_features['price_acceleration'] = price_change - price_change.shift(1)  # ä¸€é˜¶åŠ é€Ÿåº¦ï¼ˆåŸºç¡€ç‰ˆæœ¬ï¼‰
            new_features['price_acceleration_3'] = price_change - price_change.shift(3)
            new_features['price_acceleration_5'] = price_change - price_change.shift(5)
            
            # æ³¨ï¼šconsecutive_up, consecutive_down åœ¨å¸‚åœºæƒ…ç»ªç‰¹å¾ä¸­æ·»åŠ ï¼ˆæ›´å¥½çš„å®ç°ï¼‰
            
            # âœ… ä»·æ ¼åŠ¨é‡å¼ºåº¦
            new_features['price_momentum_strength'] = price_change.abs().rolling(5).mean()
            new_features['price_momentum_direction'] = price_change.rolling(5).mean() / (price_change.rolling(5).std() + 1e-8)
            
            # ä¸€æ¬¡æ€§æ·»åŠ æ‰€æœ‰ç‰¹å¾
            df = pd.concat([df, pd.DataFrame(new_features, index=df.index)], axis=1)
            
            return df
            
        except Exception as e:
            logger.error(f"æ·»åŠ ä»·æ ¼ç‰¹å¾å¤±è´¥: {e}")
            return df
    
    def _add_technical_indicators(self, df: pd.DataFrame) -> pd.DataFrame:
        """æ·»åŠ æŠ€æœ¯æŒ‡æ ‡ç‰¹å¾ - ä¼˜åŒ–æ€§èƒ½"""
        try:
            new_features = {}
            
            # RSI
            for period in [14, 21, 30]:
                new_features[f'rsi_{period}'] = ta.momentum.RSIIndicator(df['close'], window=period).rsi()
            
            # MACD
            macd = ta.trend.MACD(df['close'])
            new_features['macd'] = macd.macd()
            new_features['macd_signal'] = macd.macd_signal()
            new_features['macd_histogram'] = macd.macd_diff()
            
            # Bollinger Bands
            for period in [20, 50]:
                bb = ta.volatility.BollingerBands(df['close'], window=period)
                bb_upper = bb.bollinger_hband()
                bb_lower = bb.bollinger_lband()
                bb_middle = bb.bollinger_mavg()
                
                new_features[f'bb_upper_{period}'] = bb_upper
                new_features[f'bb_lower_{period}'] = bb_lower
                new_features[f'bb_middle_{period}'] = bb_middle
                # é¿å…é™¤ä»¥é›¶
                bb_middle_safe = bb_middle.replace(0, np.nan)
                bb_range_safe = (bb_upper - bb_lower).replace(0, np.nan)
                new_features[f'bb_width_{period}'] = (bb_upper - bb_lower) / bb_middle_safe
                new_features[f'bb_position_{period}'] = (df['close'] - bb_lower) / bb_range_safe
            
            # ç§»åŠ¨å¹³å‡çº¿
            sma_dict = {}
            ema_dict = {}
            for period in [5, 10, 20, 50, 100, 200]:
                sma = ta.trend.SMAIndicator(df['close'], window=period).sma_indicator()
                ema = ta.trend.EMAIndicator(df['close'], window=period).ema_indicator()
                
                sma_dict[period] = sma
                ema_dict[period] = ema
                
                new_features[f'sma_{period}'] = sma
                new_features[f'ema_{period}'] = ema
                # é¿å…é™¤ä»¥é›¶ï¼ˆè™½ç„¶sma/emaé€šå¸¸ä¸ä¸º0ï¼Œä½†ä¸ºå®‰å…¨èµ·è§ï¼‰
                sma_safe = sma.replace(0, np.nan)
                ema_safe = ema.replace(0, np.nan)
                new_features[f'price_sma_ratio_{period}'] = df['close'] / sma_safe
                new_features[f'price_ema_ratio_{period}'] = df['close'] / ema_safe
            
            # ç§»åŠ¨å¹³å‡çº¿äº¤å‰
            new_features['sma_5_20_cross'] = np.where(sma_dict[5] > sma_dict[20], 1, 0)
            new_features['sma_10_50_cross'] = np.where(sma_dict[10] > sma_dict[50], 1, 0)
            new_features['ema_5_20_cross'] = np.where(ema_dict[5] > ema_dict[20], 1, 0)
            
            # Stochastic
            stoch = ta.momentum.StochasticOscillator(df['high'], df['low'], df['close'])
            new_features['stoch_k'] = stoch.stoch()
            new_features['stoch_d'] = stoch.stoch_signal()
            
            # Williams %R
            new_features['williams_r'] = ta.momentum.WilliamsRIndicator(df['high'], df['low'], df['close']).williams_r()
            
            # CCI (Commodity Channel Index)
            new_features['cci'] = ta.trend.CCIIndicator(df['high'], df['low'], df['close']).cci()
            
            # ADX (Average Directional Index)
            adx = ta.trend.ADXIndicator(df['high'], df['low'], df['close'])
            new_features['adx'] = adx.adx()
            new_features['adx_pos'] = adx.adx_pos()
            new_features['adx_neg'] = adx.adx_neg()
            
            # Parabolic SAR
            psar = ta.trend.PSARIndicator(df['high'], df['low'], df['close']).psar()
            new_features['psar'] = psar
            new_features['psar_signal'] = np.where(df['close'] > psar, 1, 0)
            
            # ä¸€æ¬¡æ€§æ·»åŠ æ‰€æœ‰ç‰¹å¾
            df = pd.concat([df, pd.DataFrame(new_features, index=df.index)], axis=1)
            
            return df
            
        except Exception as e:
            logger.error(f"æ·»åŠ æŠ€æœ¯æŒ‡æ ‡å¤±è´¥: {e}")
            return df
    
    def _add_volume_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """æ·»åŠ æˆäº¤é‡ç‰¹å¾ - ä¼˜åŒ–æ€§èƒ½"""
        try:
            new_features = {}
            
            # æˆäº¤é‡å˜åŒ–
            # âœ… è¯¦ç»†è¯Šæ–­ï¼šæ£€æŸ¥volumeæ•°æ®è´¨é‡
            volume_zero_count = (df['volume'] == 0).sum()
            volume_nan_count = df['volume'].isna().sum()
            if volume_zero_count > 0:
                logger.warning(f"âš ï¸ _add_volume_features: æ£€æµ‹åˆ°{volume_zero_count}ä¸ªvolumeä¸º0ï¼ˆå¯èƒ½å¯¼è‡´pct_changeäº§ç”Ÿinfï¼‰")
                logger.warning(f"   è¿™äº›é›¶å€¼å°†è¢«ä¸´æ—¶æ›¿æ¢ä¸ºNaNï¼Œé¿å…pct_changeäº§ç”Ÿinf")
                # âœ… å…³é”®ä¿®å¤ï¼šåœ¨pct_changeä¹‹å‰ï¼Œå°†volume=0æ›¿æ¢ä¸ºNaN
                # è¿™æ ·pct_changeå°±ä¸ä¼šäº§ç”Ÿinfï¼ˆå› ä¸ºNaNçš„pct_changeç»“æœæ˜¯NaNï¼Œä¸æ˜¯infï¼‰
                volume_for_pct = df['volume'].replace(0, np.nan)
            else:
                volume_for_pct = df['volume']
            
            volume_change = volume_for_pct.pct_change(fill_method=None)  # âœ… ä¿®å¤ï¼šæ˜ç¡®æŒ‡å®šfill_method=Noneé¿å…FutureWarning
            
            # âœ… è¯¦ç»†è¯Šæ–­ï¼šæ£€æŸ¥volume_changeæ˜¯å¦ä»æœ‰infï¼ˆç†è®ºä¸Šä¸åº”è¯¥æœ‰ï¼‰
            inf_mask = np.isinf(volume_change)
            if inf_mask.any():
                inf_count = inf_mask.sum()
                logger.error(f"âŒ _add_volume_features: volume_changeä»äº§ç”Ÿ{inf_count}ä¸ªinfå€¼ï¼ˆå¼‚å¸¸ï¼ï¼‰")
                inf_indices = volume_change[inf_mask].index.tolist()[:5]
                for idx in inf_indices:
                    idx_pos = df.index.get_loc(idx)
                    prev_volume = df['volume'].iloc[idx_pos - 1] if idx_pos > 0 else None
                    curr_volume = df['volume'].iloc[idx_pos]
                    logger.error(f"   ä½ç½®{idx}: volumeå‰å€¼={prev_volume}, volumeå½“å‰å€¼={curr_volume}")
                    logger.error(f"      volume_for_pctå‰å€¼={volume_for_pct.iloc[idx_pos - 1] if idx_pos > 0 else None}, "
                               f"volume_for_pctå½“å‰å€¼={volume_for_pct.iloc[idx_pos]}")
            else:
                # âœ… ä¿®å¤æˆåŠŸï¼šæ²¡æœ‰äº§ç”Ÿinf
                if volume_zero_count > 0:
                    logger.info(f"   âœ… é€šè¿‡é¢„å¤„ç†ï¼ˆvolume=0â†’NaNï¼‰æˆåŠŸé¿å…äº†infäº§ç”Ÿ")
            
            # âœ… åŒé‡ä¿æŠ¤ï¼šå³ä½¿ä»æœ‰infï¼Œä¹Ÿæ›¿æ¢ä¸ºNaN
            volume_change = volume_change.replace([np.inf, -np.inf], np.nan)
            # ğŸ”‘ ä¿®å¤éå¹³ç¨³ç‰¹å¾ï¼šç§»é™¤ç»å¯¹å€¼volume_smaï¼Œåªä¿ç•™æ¯”ç‡ç‰¹å¾
            # è®¡ç®—volume_sma_20ç”¨äºæ¯”ç‡è®¡ç®—ï¼ˆä¸æ·»åŠ åˆ°ç‰¹å¾ä¸­ï¼‰
            volume_sma_20 = df['volume'].rolling(20).mean()
            # é¿å…é™¤ä»¥é›¶ï¼ˆvolume_sma_20å¯èƒ½ä¸º0ï¼‰
            volume_sma_20_safe = volume_sma_20.replace(0, np.nan)
            
            new_features['volume_change'] = volume_change
            # âœ… ç§»é™¤éå¹³ç¨³ç»å¯¹å€¼ç‰¹å¾ï¼švolume_sma_5, volume_sma_20
            # âœ… åªä¿ç•™æ¯”ç‡ç‰¹å¾ï¼švolume_ratioï¼ˆå·²è½¬æ¢ä¸ºç›¸å¯¹å€¼ï¼Œå¯¹æ¨¡å‹æ›´å‹å¥½ï¼‰
            new_features['volume_ratio'] = df['volume'] / volume_sma_20_safe
            
            # ä»·é‡å…³ç³»
            new_features['price_volume_trend'] = df['price_change'] * volume_change
            
            # OBV (On Balance Volume)
            obv = ta.volume.OnBalanceVolumeIndicator(df['close'], df['volume']).on_balance_volume()
            new_features['obv'] = obv
            new_features['obv_sma'] = obv.rolling(20).mean()
            
            # Volume Price Trend
            new_features['vpt'] = ta.volume.VolumePriceTrendIndicator(df['close'], df['volume']).volume_price_trend()
            
            # Accumulation/Distribution Line
            new_features['ad_line'] = ta.volume.AccDistIndexIndicator(df['high'], df['low'], df['close'], df['volume']).acc_dist_index()
            
            # Chaikin Money Flow
            new_features['cmf'] = ta.volume.ChaikinMoneyFlowIndicator(df['high'], df['low'], df['close'], df['volume']).chaikin_money_flow()
            
            # Volume Weighted Average Price (VWAP)ï¼ˆé¿å…é™¤ä»¥é›¶ï¼‰
            volume_rolling_sum = df['volume'].rolling(20).sum()
            
            # âœ… è¯¦ç»†è¯Šæ–­ï¼šæ£€æŸ¥volume_rolling_sum
            volume_rolling_sum_zero = (volume_rolling_sum == 0).sum()
            if volume_rolling_sum_zero > 0:
                logger.warning(f"âš ï¸ _add_volume_features: volume_rolling_sumæœ‰{volume_rolling_sum_zero}ä¸ª0å€¼")
                zero_indices = volume_rolling_sum[volume_rolling_sum == 0].index.tolist()[:5]
                for idx in zero_indices:
                    idx_pos = df.index.get_loc(idx)
                    volume_window = df['volume'].iloc[max(0, idx_pos-19):idx_pos+1]
                    logger.warning(f"   ä½ç½®{idx}: volume_rolling_sum=0")
                    logger.warning(f"      volumeçª—å£: æ€»æ•°={len(volume_window)}, é›¶å€¼={(volume_window == 0).sum()}, "
                                 f"NaN={volume_window.isna().sum() if hasattr(volume_window, 'isna') else 0}")
                    if len(volume_window) > 0:
                        logger.warning(f"      volumeèŒƒå›´: [{volume_window.min():.4f}, {volume_window.max():.4f}]")
            
            volume_rolling_sum_safe = volume_rolling_sum.replace(0, np.nan)  # é¿å…é™¤ä»¥0
            
            # âœ… è¯¦ç»†è¯Šæ–­ï¼šæ£€æŸ¥æ›¿æ¢åçš„æƒ…å†µ
            volume_rolling_sum_safe_zero_after = (volume_rolling_sum_safe == 0).sum()
            if volume_rolling_sum_safe_zero_after > 0:
                logger.error(f"âŒ _add_volume_features: volume_rolling_sum_safeä»æœ‰{volume_rolling_sum_safe_zero_after}ä¸ª0å€¼ï¼ˆæ›¿æ¢å¤±è´¥ï¼‰")
            
            # è®¡ç®—vwap
            numerator = (df['close'] * df['volume']).rolling(20).sum()
            vwap = numerator / volume_rolling_sum_safe
            
            # âœ… è¯¦ç»†è¯Šæ–­ï¼šæ£€æŸ¥vwapæ˜¯å¦äº§ç”Ÿinf
            inf_mask_vwap = np.isinf(vwap)
            if inf_mask_vwap.any():
                inf_count = inf_mask_vwap.sum()
                logger.error(f"âŒ _add_volume_features: vwapäº§ç”Ÿ{inf_count}ä¸ªinfå€¼ï¼")
                inf_indices = vwap[inf_mask_vwap].index.tolist()[:5]
                for idx in inf_indices:
                    idx_pos = df.index.get_loc(idx)
                    logger.error(f"   ä½ç½®{idx}:")
                    logger.error(f"      numerator={numerator.iloc[idx_pos]}, volume_rolling_sum={volume_rolling_sum.iloc[idx_pos]}")
                    logger.error(f"      volume_rolling_sum_safe={volume_rolling_sum_safe.iloc[idx_pos]}")
                    logger.error(f"      vwap={vwap.iloc[idx_pos]}")
                    # æ£€æŸ¥çª—å£å†…çš„è¯¦ç»†æ•°æ®
                    volume_window = df['volume'].iloc[max(0, idx_pos-19):idx_pos+1]
                    close_window = df['close'].iloc[max(0, idx_pos-19):idx_pos+1]
                    logger.error(f"      volumeçª—å£ï¼ˆå‰5ä¸ªï¼‰: {volume_window.head(5).tolist()}")
                    logger.error(f"      closeçª—å£ï¼ˆå‰5ä¸ªï¼‰: {close_window.head(5).tolist()}")
            
            new_features['vwap'] = vwap
            # é¿å…é™¤ä»¥é›¶ï¼ˆvwapå¯èƒ½ä¸ºNaNï¼‰
            vwap_safe = vwap.replace(0, np.nan).replace(np.nan, 1.0)  # å¦‚æœvwapä¸ºNaNï¼Œç”¨1.0é¿å…inf
            
            # âœ… è¯¦ç»†è¯Šæ–­ï¼šæ£€æŸ¥vwap_safeæ›¿æ¢åçš„æƒ…å†µ
            vwap_safe_zero_after = (vwap_safe == 0).sum()
            if vwap_safe_zero_after > 0:
                logger.error(f"âŒ _add_volume_features: vwap_safeä»æœ‰{vwap_safe_zero_after}ä¸ª0å€¼ï¼ˆæ›¿æ¢å¤±è´¥ï¼‰")
            
            new_features['price_vwap_ratio'] = df['close'] / vwap_safe
            
            # âœ… è¯¦ç»†è¯Šæ–­ï¼šæ£€æŸ¥price_vwap_ratioæ˜¯å¦äº§ç”Ÿinf
            inf_mask_vwap_ratio = np.isinf(new_features['price_vwap_ratio'])
            if inf_mask_vwap_ratio.any():
                inf_count = inf_mask_vwap_ratio.sum()
                logger.error(f"âŒ _add_volume_features: price_vwap_ratioäº§ç”Ÿ{inf_count}ä¸ªinfå€¼ï¼")
                inf_indices = new_features['price_vwap_ratio'][inf_mask_vwap_ratio].index.tolist()[:5]
                for idx in inf_indices:
                    idx_pos = df.index.get_loc(idx)
                    logger.error(f"   ä½ç½®{idx}:")
                    logger.error(f"      close={df['close'].iloc[idx_pos]}, vwap={vwap.iloc[idx_pos]}")
                    logger.error(f"      vwap_safe={vwap_safe.iloc[idx_pos]}, price_vwap_ratio={new_features['price_vwap_ratio'].iloc[idx_pos]}")
                    if vwap_safe.iloc[idx_pos] == 0:
                        logger.error(f"      âŒ åŸå› ç¡®è®¤ï¼švwap_safe=0ï¼ˆæ›¿æ¢å¤±è´¥ï¼‰")
            
            # âœ… æˆäº¤é‡çªç ´ï¼ˆæ•æ‰æ”¾é‡ä¿¡å·ï¼‰ï¼ˆé¿å…é™¤ä»¥é›¶ï¼‰
            volume_ma_5 = df['volume'].rolling(5).mean()
            volume_ma_20 = df['volume'].rolling(20).mean()
            
            # âœ… è¯¦ç»†è¯Šæ–­ï¼šæ£€æŸ¥volume_ma_20
            volume_ma_20_zero = (volume_ma_20 == 0).sum()
            if volume_ma_20_zero > 0:
                logger.warning(f"âš ï¸ _add_volume_features: volume_ma_20æœ‰{volume_ma_20_zero}ä¸ª0å€¼")
                zero_indices = volume_ma_20[volume_ma_20 == 0].index.tolist()[:3]
                for idx in zero_indices:
                    idx_pos = df.index.get_loc(idx)
                    volume_window = df['volume'].iloc[max(0, idx_pos-19):idx_pos+1]
                    logger.warning(f"   ä½ç½®{idx}: volume_ma_20=0, volumeçª—å£ç»Ÿè®¡: é›¶å€¼={(volume_window == 0).sum()}/{len(volume_window)}")
            
            volume_ma_20_safe = volume_ma_20.replace(0, np.nan)  # é¿å…é™¤ä»¥0
            
            # âœ… è¯¦ç»†è¯Šæ–­ï¼šæ£€æŸ¥volume_ma_20_safeæ›¿æ¢åçš„æƒ…å†µ
            volume_ma_20_safe_zero_after = (volume_ma_20_safe == 0).sum()
            if volume_ma_20_safe_zero_after > 0:
                logger.error(f"âŒ _add_volume_features: volume_ma_20_safeä»æœ‰{volume_ma_20_safe_zero_after}ä¸ª0å€¼ï¼ˆæ›¿æ¢å¤±è´¥ï¼‰")
            
            new_features['volume_spike'] = df['volume'] / volume_ma_20_safe
            
            # âœ… è¯¦ç»†è¯Šæ–­ï¼šæ£€æŸ¥volume_spikeæ˜¯å¦äº§ç”Ÿinf
            inf_mask_spike = np.isinf(new_features['volume_spike'])
            if inf_mask_spike.any():
                inf_count = inf_mask_spike.sum()
                logger.error(f"âŒ _add_volume_features: volume_spikeäº§ç”Ÿ{inf_count}ä¸ªinfå€¼ï¼")
                inf_indices = new_features['volume_spike'][inf_mask_spike].index.tolist()[:3]
                for idx in inf_indices:
                    idx_pos = df.index.get_loc(idx)
                    logger.error(f"   ä½ç½®{idx}: volume={df['volume'].iloc[idx_pos]}, volume_ma_20={volume_ma_20.iloc[idx_pos]}, volume_ma_20_safe={volume_ma_20_safe.iloc[idx_pos]}")
            
            new_features['volume_trend'] = volume_ma_5 / volume_ma_20_safe
            
            # âœ… è¯¦ç»†è¯Šæ–­ï¼šæ£€æŸ¥volume_trendæ˜¯å¦äº§ç”Ÿinf
            inf_mask_trend = np.isinf(new_features['volume_trend'])
            if inf_mask_trend.any():
                inf_count = inf_mask_trend.sum()
                logger.error(f"âŒ _add_volume_features: volume_trendäº§ç”Ÿ{inf_count}ä¸ªinfå€¼ï¼")
            
            # âœ… ä»·æ ¼-æˆäº¤é‡èƒŒç¦»ï¼ˆé‡è¦ä¿¡å·ï¼‰ï¼ˆä¿®å¤ï¼špct_changeå¯èƒ½äº§ç”Ÿinfï¼‰
            # âœ… ä½¿ç”¨é¢„å¤„ç†åçš„close_for_pctå’Œvolume_for_pctï¼ˆå·²å¤„ç†0å€¼ï¼‰
            close_for_pct_corr = df['close'].replace(0, np.nan) if (df['close'] == 0).sum() > 0 else df['close']
            volume_for_pct_corr = df['volume'].replace(0, np.nan) if (df['volume'] == 0).sum() > 0 else df['volume']
            
            price_change_1 = close_for_pct_corr.pct_change(1, fill_method=None)  # âœ… ä¿®å¤ï¼šæ˜ç¡®æŒ‡å®šfill_method=Noneé¿å…FutureWarning
            price_change_1 = price_change_1.replace([np.inf, -np.inf], np.nan)  # âœ… åŒé‡ä¿æŠ¤
            
            price_change_5 = close_for_pct_corr.pct_change(5, fill_method=None)  # âœ… ä¿®å¤ï¼šæ˜ç¡®æŒ‡å®šfill_method=Noneé¿å…FutureWarning
            price_change_5 = price_change_5.replace([np.inf, -np.inf], np.nan)  # âœ… åŒé‡ä¿æŠ¤
            
            volume_change_5 = volume_for_pct_corr.pct_change(5, fill_method=None)  # âœ… ä¿®å¤ï¼šæ˜ç¡®æŒ‡å®šfill_method=Noneé¿å…FutureWarning
            volume_change_5 = volume_change_5.replace([np.inf, -np.inf], np.nan)  # âœ… åŒé‡ä¿æŠ¤
            new_features['price_volume_correlation'] = price_change_5 * volume_change_5  # åŒå‘ä¸ºæ­£ï¼ŒèƒŒç¦»ä¸ºè´Ÿï¼ˆè¿ç»­å€¼ï¼‰
            
            # âœ… æˆäº¤é‡åŠ æƒä»·æ ¼å˜åŒ–ï¼ˆç»“åˆé‡ä»·ï¼‰ï¼ˆé¿å…é™¤ä»¥é›¶ï¼‰
            # volume_ma_20_safeå·²åœ¨ä¸Šé¢å®šä¹‰ï¼ˆLine 317ï¼‰ï¼Œç›´æ¥ä½¿ç”¨
            new_features['volume_weighted_price_change'] = price_change_1 * (df['volume'] / volume_ma_20_safe)
            
            # ä¸€æ¬¡æ€§æ·»åŠ æ‰€æœ‰ç‰¹å¾
            df = pd.concat([df, pd.DataFrame(new_features, index=df.index)], axis=1)
            
            return df
            
        except Exception as e:
            logger.error(f"æ·»åŠ æˆäº¤é‡ç‰¹å¾å¤±è´¥: {e}")
            return df
    
    def _add_time_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """æ·»åŠ æ—¶é—´ç‰¹å¾ - ä¼˜åŒ–æ€§èƒ½"""
        try:
            # ç¡®ä¿ timestamp æ˜¯ datetime ç±»å‹
            if 'timestamp' in df.columns:
                if not pd.api.types.is_datetime64_any_dtype(df['timestamp']):
                    df['timestamp'] = pd.to_datetime(df['timestamp'])
                datetime_col = df['timestamp']
            else:
                # timestamp å¯èƒ½åœ¨ index ä¸­
                logger.warning("timestamp åˆ—ä¸å­˜åœ¨ï¼Œè·³è¿‡æ—¶é—´ç‰¹å¾")
                return df
            
            new_features = {}
            
            # åŸºç¡€æ—¶é—´ç‰¹å¾
            hour = datetime_col.dt.hour
            day_of_week = datetime_col.dt.dayofweek
            month = datetime_col.dt.month
            
            new_features['hour'] = hour
            new_features['day_of_week'] = day_of_week
            new_features['day_of_month'] = datetime_col.dt.day
            new_features['month'] = month
            new_features['quarter'] = datetime_col.dt.quarter
            
            # å‘¨æœŸæ€§ç¼–ç 
            new_features['hour_sin'] = np.sin(2 * np.pi * hour / 24)
            new_features['hour_cos'] = np.cos(2 * np.pi * hour / 24)
            new_features['day_sin'] = np.sin(2 * np.pi * day_of_week / 7)
            new_features['day_cos'] = np.cos(2 * np.pi * day_of_week / 7)
            new_features['month_sin'] = np.sin(2 * np.pi * month / 12)
            new_features['month_cos'] = np.cos(2 * np.pi * month / 12)
            
            # äº¤æ˜“æ—¶æ®µ
            new_features['is_asian_session'] = ((hour >= 0) & (hour < 8)).astype(int)
            new_features['is_european_session'] = ((hour >= 8) & (hour < 16)).astype(int)
            new_features['is_american_session'] = ((hour >= 16) & (hour < 24)).astype(int)
            
            # å‘¨æœ«æ ‡è¯†
            new_features['is_weekend'] = (day_of_week >= 5).astype(int)
            
            # ä¸€æ¬¡æ€§æ·»åŠ æ‰€æœ‰ç‰¹å¾
            df = pd.concat([df, pd.DataFrame(new_features, index=df.index)], axis=1)
            
            return df
            
        except Exception as e:
            logger.error(f"æ·»åŠ æ—¶é—´ç‰¹å¾å¤±è´¥: {e}")
            return df
    
    def _add_microstructure_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """æ·»åŠ å¸‚åœºå¾®è§‚ç»“æ„ç‰¹å¾ - å¢å¼ºç‰ˆï¼ˆä¼˜åŒ–ç›®æ ‡ï¼šå‡†ç¡®ç‡+3-5%ï¼‰"""
        try:
            new_features = {}
            
            # 1. ä¹°å–å‹åŠ›æŒ‡æ ‡ï¼ˆåŸºç¡€ï¼‰
            price_range = df['high'] - df['low'] + 1e-10  # é¿å…é™¤é›¶
            new_features['buying_pressure'] = (df['close'] - df['low']) / price_range
            new_features['selling_pressure'] = (df['high'] - df['close']) / price_range
            
            # 2. ğŸ†• ä»·æ ¼ä½ç½®ç™¾åˆ†æ¯”ï¼ˆæ•æ‰æ”¯æ’‘é˜»åŠ›ï¼‰
            for period in [5, 20, 50]:
                rolling_high = df['high'].rolling(period).max()
                rolling_low = df['low'].rolling(period).min()
                price_position = (df['close'] - rolling_low) / (rolling_high - rolling_low + 1e-10)
                new_features[f'price_position_{period}'] = price_position
                # è¶…ä¹°è¶…å–æ ‡è¯†
                new_features[f'overbought_{period}'] = (price_position > 0.8).astype(int)
                new_features[f'oversold_{period}'] = (price_position < 0.2).astype(int)
            
            # 3. ğŸ†• Kçº¿å½¢æ€ç‰¹å¾ï¼ˆå®ä½“å’Œå½±çº¿ï¼‰
            body = abs(df['close'] - df['open'])
            new_features['body_range'] = body / (price_range + 1e-10)
            new_features['upper_shadow'] = (df['high'] - df[['open', 'close']].max(axis=1)) / (price_range + 1e-10)
            new_features['lower_shadow'] = (df[['open', 'close']].min(axis=1) - df['low']) / (price_range + 1e-10)
            
            # 4. ğŸ†• Kçº¿å¼ºåº¦ï¼ˆçœ‹æ¶¨/çœ‹è·ŒåŠ›é‡ï¼‰
            new_features['bullish_candle'] = (df['close'] > df['open']).astype(int)
            new_features['strong_bullish'] = ((df['close'] - df['open']) / (price_range + 1e-10) > 0.6).astype(int)
            new_features['strong_bearish'] = ((df['open'] - df['close']) / (price_range + 1e-10) > 0.6).astype(int)
            new_features['doji'] = (body / (price_range + 1e-10) < 0.1).astype(int)  # åå­—æ˜Ÿ
            
            # 5. ğŸ†• è¿ç»­Kçº¿å½¢æ€ï¼ˆè¶‹åŠ¿å»¶ç»­ï¼‰
            bullish = (df['close'] > df['open']).astype(int)
            new_features['consecutive_bull'] = bullish.groupby((bullish != bullish.shift()).cumsum()).cumsum()
            new_features['consecutive_bear'] = (1 - bullish).groupby((bullish == bullish.shift()).cumsum()).cumsum()
            
            # 6. ä»·æ ¼æ•ˆç‡ï¼ˆå·²æœ‰ï¼Œä¿ç•™ï¼‰
            for period in [5, 10, 20]:
                price_change = df['close'].diff(period)
                sum_abs_changes = df['close'].diff().abs().rolling(period).sum()
                new_features[f'price_efficiency_{period}'] = price_change.abs() / (sum_abs_changes + 1e-10)
            
            # 7. ğŸ†• ä»·æ ¼åŠ é€Ÿåº¦ï¼ˆæ•æ‰æ‹ç‚¹ï¼‰
            close_for_returns = df['close'].replace(0, np.nan) if (df['close'] == 0).sum() > 0 else df['close']
            returns = close_for_returns.pct_change(fill_method=None)  # âœ… ä¿®å¤ï¼šæ˜ç¡®æŒ‡å®šfill_method=Noneé¿å…FutureWarning
            # âœ… ä¿®å¤ï¼šæ›¿æ¢infå€¼
            returns = returns.replace([np.inf, -np.inf], np.nan)
            # æ³¨ï¼šprice_acceleration å·²åœ¨ä»·æ ¼ç‰¹å¾ä¸­å®šä¹‰ï¼Œè¿™é‡Œæ·»åŠ æ›´é«˜é˜¶çš„
            new_features['price_jerk'] = returns.diff().diff()  # åŠ åŠ é€Ÿåº¦ï¼ˆä¸‰é˜¶å¯¼æ•°ï¼‰
            
            # 8. åˆ†å½¢ç»´åº¦ï¼ˆå·²æœ‰ï¼Œä¿ç•™ï¼‰
            for period in [10, 20]:
                new_features[f'fractal_dimension_{period}'] = self._calculate_fractal_dimension(df['close'], period)
            
            # 9. HurstæŒ‡æ•°ï¼ˆå·²æœ‰ï¼Œä¿ç•™ï¼‰
            for period in [20, 50]:
                new_features[f'hurst_exponent_{period}'] = self._calculate_hurst_exponent(df['close'], period)
            
            # 10. ğŸ†• çœŸå®æ³¢åŠ¨èŒƒå›´å æ¯”ï¼ˆæ•æ‰å¼‚å¸¸æ³¢åŠ¨ï¼‰
            atr_14 = ta.volatility.AverageTrueRange(df['high'], df['low'], df['close'], window=14).average_true_range()
            new_features['range_to_atr'] = price_range / (atr_14 + 1e-10)
            new_features['body_to_atr'] = body / (atr_14 + 1e-10)
            
            # ä¸€æ¬¡æ€§æ·»åŠ æ‰€æœ‰ç‰¹å¾
            df = pd.concat([df, pd.DataFrame(new_features, index=df.index)], axis=1)
            
            
            return df
            
        except Exception as e:
            logger.error(f"âŒ æ·»åŠ å¸‚åœºå¾®è§‚ç»“æ„ç‰¹å¾å¤±è´¥: {e}")
            logger.error(traceback.format_exc())
            return df
    
    def _add_volatility_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """æ·»åŠ æ³¢åŠ¨ç‡ç‰¹å¾ - ä¼˜åŒ–æ€§èƒ½"""
        try:
            new_features = {}
            
            # å†å²æ³¢åŠ¨ç‡
            close_for_returns = df['close'].replace(0, np.nan) if (df['close'] == 0).sum() > 0 else df['close']
            returns = close_for_returns.pct_change(fill_method=None)  # âœ… ä¿®å¤ï¼šæ˜ç¡®æŒ‡å®šfill_method=Noneé¿å…FutureWarning
            # âœ… ä¿®å¤ï¼šæ›¿æ¢infå€¼
            returns = returns.replace([np.inf, -np.inf], np.nan)
            for period in [5, 10, 20, 50]:
                new_features[f'volatility_{period}'] = returns.rolling(period).std() * np.sqrt(252)
            
            # ATR (Average True Range)
            for period in [14, 20]:
                atr = ta.volatility.AverageTrueRange(df['high'], df['low'], df['close'], window=period).average_true_range()
                new_features[f'atr_{period}'] = atr
                new_features[f'atr_ratio_{period}'] = atr / df['close']
            
            # Keltner Channels
            kc = ta.volatility.KeltnerChannel(df['high'], df['low'], df['close'])
            kc_upper = kc.keltner_channel_hband()
            kc_lower = kc.keltner_channel_lband()
            kc_middle = kc.keltner_channel_mband()
            
            new_features['kc_upper'] = kc_upper
            new_features['kc_lower'] = kc_lower
            new_features['kc_middle'] = kc_middle
            # é¿å…é™¤ä»¥é›¶
            kc_range_safe = (kc_upper - kc_lower).replace(0, np.nan)
            new_features['kc_position'] = (df['close'] - kc_lower) / kc_range_safe
            
            # Donchian Channels
            dc = ta.volatility.DonchianChannel(df['high'], df['low'], df['close'])
            new_features['dc_upper'] = dc.donchian_channel_hband()
            new_features['dc_lower'] = dc.donchian_channel_lband()
            new_features['dc_middle'] = dc.donchian_channel_mband()
            
            # ä¸€æ¬¡æ€§æ·»åŠ æ‰€æœ‰ç‰¹å¾
            df = pd.concat([df, pd.DataFrame(new_features, index=df.index)], axis=1)
            
            return df
            
        except Exception as e:
            logger.error(f"æ·»åŠ æ³¢åŠ¨ç‡ç‰¹å¾å¤±è´¥: {e}")
            return df
    
    def _add_momentum_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """æ·»åŠ åŠ¨é‡ç‰¹å¾ - ä¼˜åŒ–æ€§èƒ½"""
        try:
            new_features = {}
            
            # ROC (Rate of Change)
            for period in [5, 10, 20]:
                new_features[f'roc_{period}'] = ta.momentum.ROCIndicator(df['close'], window=period).roc()
            
            # Momentum
            for period in [5, 10, 20]:
                new_features[f'momentum_{period}'] = df['close'] / df['close'].shift(period) - 1
            
            # TSI (True Strength Index)
            new_features['tsi'] = ta.momentum.TSIIndicator(df['close']).tsi()
            
            # Ultimate Oscillator
            new_features['uo'] = ta.momentum.UltimateOscillator(df['high'], df['low'], df['close']).ultimate_oscillator()
            
            # Awesome Oscillator
            new_features['ao'] = ta.momentum.AwesomeOscillatorIndicator(df['high'], df['low']).awesome_oscillator()
            
            # æ³¨ï¼šADXå·²åœ¨æŠ€æœ¯æŒ‡æ ‡ä¸­æ·»åŠ ï¼Œé¿å…é‡å¤
            
            # âœ… åŠ¨é‡åŠ é€Ÿåº¦ï¼ˆæ•æ‰åŠ¨é‡å˜åŒ–ï¼‰
            rsi_14 = ta.momentum.RSIIndicator(df['close'], window=14).rsi()
            new_features['rsi_acceleration'] = rsi_14 - rsi_14.shift(1)
            new_features['rsi_velocity'] = rsi_14.diff()
            
            # âœ… å¤šå‘¨æœŸåŠ¨é‡ä¸€è‡´æ€§ï¼ˆè¶‹åŠ¿ç¡®è®¤ï¼‰
            roc_5 = ta.momentum.ROCIndicator(df['close'], window=5).roc()
            roc_10 = ta.momentum.ROCIndicator(df['close'], window=10).roc()
            roc_20 = ta.momentum.ROCIndicator(df['close'], window=20).roc()
            # å¦‚æœå¤šä¸ªå‘¨æœŸéƒ½æ˜¯æ­£/è´Ÿï¼Œåˆ™è¶‹åŠ¿æ›´å¯é 
            new_features['momentum_alignment'] = ((roc_5 > 0).astype(int) + 
                                                  (roc_10 > 0).astype(int) + 
                                                  (roc_20 > 0).astype(int)) - 1.5  # -1.5 to 1.5
            
            # ä¸€æ¬¡æ€§æ·»åŠ æ‰€æœ‰ç‰¹å¾
            df = pd.concat([df, pd.DataFrame(new_features, index=df.index)], axis=1)
            
            return df
            
        except Exception as e:
            logger.error(f"æ·»åŠ åŠ¨é‡ç‰¹å¾å¤±è´¥: {e}")
            return df
    
    def _add_statistical_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """æ·»åŠ ç»Ÿè®¡ç‰¹å¾ - ä¼˜åŒ–æ€§èƒ½ï¼Œé¿å…DataFrameç¢ç‰‡åŒ–"""
        try:
            new_features = {}
            
            # æ»šåŠ¨ç»Ÿè®¡
            for period in [5, 10, 20, 50]:
                rolling = df['close'].rolling(period)
                new_features[f'close_mean_{period}'] = rolling.mean()
                new_features[f'close_std_{period}'] = rolling.std()
                new_features[f'close_skew_{period}'] = rolling.skew()
                new_features[f'close_kurt_{period}'] = rolling.kurt()
                
                # Z-score
                mean_col = new_features[f'close_mean_{period}']
                std_col = new_features[f'close_std_{period}']
                new_features[f'close_zscore_{period}'] = (df['close'] - mean_col) / std_col
            
            # åˆ†ä½æ•°
            for period in [20, 50]:
                rolling = df['close'].rolling(period)
                new_features[f'close_quantile_25_{period}'] = rolling.quantile(0.25)
                new_features[f'close_quantile_75_{period}'] = rolling.quantile(0.75)
                new_features[f'close_iqr_{period}'] = (
                    new_features[f'close_quantile_75_{period}'] - 
                    new_features[f'close_quantile_25_{period}']
                )
            
            # ä¸€æ¬¡æ€§æ·»åŠ æ‰€æœ‰ç‰¹å¾
            df = pd.concat([df, pd.DataFrame(new_features, index=df.index)], axis=1)
            
            return df
            
        except Exception as e:
            logger.error(f"æ·»åŠ ç»Ÿè®¡ç‰¹å¾å¤±è´¥: {e}")
            return df
    
    def _calculate_fractal_dimension(self, series: pd.Series, period: int) -> pd.Series:
        """è®¡ç®—åˆ†å½¢ç»´åº¦"""
        try:
            def fractal_dim(data):
                try:
                    data = np.array(data)
                    if len(data) < 10:
                        return np.nan
                    
                    # Higuchiæ–¹æ³•è®¡ç®—åˆ†å½¢ç»´åº¦
                    N = len(data)
                    L = []
                    x = []
                    
                    for k in range(1, min(N//2, 10)):
                        Lk = 0
                        for m in range(k):
                            Lmk = 0
                            for i in range(1, int((N-m)/k)):
                                Lmk += abs(data[m+i*k] - data[m+(i-1)*k])
                            if ((N-m)/k) * k > 0:
                                Lmk = Lmk * (N-1) / (((N-m)/k) * k)
                            Lk += Lmk
                        
                        if k > 0:
                            L.append(Lk/k)
                            x.append(1.0/k)
                    
                    if len(L) < 2:
                        return np.nan
                    
                    # çº¿æ€§å›å½’è®¡ç®—æ–œç‡
                    x = np.log(x)
                    y = np.log(L)
                    coeffs = np.polyfit(x, y, 1)
                    return coeffs[0]
                except:
                    return np.nan
            
            return series.rolling(period).apply(fractal_dim, raw=False)
            
        except Exception as e:
            logger.error(f"è®¡ç®—åˆ†å½¢ç»´åº¦å¤±è´¥: {e}")
            return pd.Series(np.nan, index=series.index)
    
    def _calculate_hurst_exponent(self, series: pd.Series, period: int) -> pd.Series:
        """è®¡ç®—HurstæŒ‡æ•°"""
        try:
            def hurst_exp(data):
                if len(data) < 10:
                    return np.nan
                
                # R/Såˆ†æè®¡ç®—HurstæŒ‡æ•°
                data = np.array(data)
                N = len(data)
                
                # è®¡ç®—ç´¯ç§¯åå·®
                mean_data = np.mean(data)
                cumulative_deviate = np.cumsum(data - mean_data)
                
                # è®¡ç®—èŒƒå›´
                R = np.max(cumulative_deviate) - np.min(cumulative_deviate)
                
                # è®¡ç®—æ ‡å‡†å·®
                S = np.std(data)
                
                if S == 0:
                    return np.nan
                
                # R/Sæ¯”ç‡
                rs = R / S
                
                if rs <= 0:
                    return np.nan
                
                # HurstæŒ‡æ•°
                return np.log(rs) / np.log(N)
            
            return series.rolling(period).apply(hurst_exp, raw=False)
            
        except Exception as e:
            logger.error(f"è®¡ç®—HurstæŒ‡æ•°å¤±è´¥: {e}")
            return pd.Series(np.nan, index=series.index)
    
    def _add_sentiment_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """æ·»åŠ å¸‚åœºæƒ…ç»ªç‰¹å¾ï¼ˆä¼˜åŒ–ç›®æ ‡ï¼šå‡†ç¡®ç‡+2-3%ï¼‰"""
        try:
            new_features = {}
            
            # 1. ææ…ŒæŒ‡æ•°ï¼ˆåŸºäºä»·æ ¼æ³¢åŠ¨ï¼‰
            close_for_returns = df['close'].replace(0, np.nan) if (df['close'] == 0).sum() > 0 else df['close']
            returns = close_for_returns.pct_change(fill_method=None)  # âœ… ä¿®å¤ï¼šæ˜ç¡®æŒ‡å®šfill_method=Noneé¿å…FutureWarning
            # âœ… ä¿®å¤ï¼šæ›¿æ¢infå€¼
            returns = returns.replace([np.inf, -np.inf], np.nan)
            short_vol = returns.rolling(20).std()
            long_vol = returns.rolling(100).std()
            new_features['fear_index'] = short_vol / (long_vol + 1e-10)
            
            # 2. ğŸ†• è¿ç»­æ¶¨è·Œå¤©æ•°ï¼ˆæ•æ‰è¶‹åŠ¿ç–²åŠ³ï¼‰
            up_days = (returns > 0).astype(int)
            down_days = (returns < 0).astype(int)
            new_features['consecutive_up'] = up_days.groupby((up_days != up_days.shift()).cumsum()).cumsum()
            new_features['consecutive_down'] = down_days.groupby((down_days != down_days.shift()).cumsum()).cumsum()
            
            # 3. ğŸ†• RSIè¡ç”Ÿæƒ…ç»ªæŒ‡æ ‡
            if 'rsi_14' in df.columns:
                rsi = df['rsi_14']
                new_features['extreme_overbought'] = (rsi > 70).astype(int)
                new_features['extreme_oversold'] = (rsi < 30).astype(int)
                new_features['rsi_momentum'] = rsi - rsi.shift(5)  # RSIåŠ¨é‡
                new_features['rsi_volatility'] = rsi.rolling(10).std()  # RSIæ³¢åŠ¨ç‡
            
            # 4. ğŸ†• ä»·æ ¼åŠ é€Ÿåº¦å¹…åº¦ï¼ˆæƒ…ç»ªè½¬å˜å¼ºåº¦ï¼‰
            close_for_price_change = df['close'].replace(0, np.nan) if (df['close'] == 0).sum() > 0 else df['close']
            price_change = close_for_price_change.pct_change(fill_method=None)  # âœ… ä¿®å¤ï¼šæ˜ç¡®æŒ‡å®šfill_method=Noneé¿å…FutureWarning
            # âœ… ä¿®å¤ï¼šæ›¿æ¢infå€¼
            price_change = price_change.replace([np.inf, -np.inf], np.nan)
            # æ³¨ï¼šprice_acceleration å·²åœ¨ä»·æ ¼ç‰¹å¾ä¸­å®šä¹‰ï¼Œè¿™é‡Œåªæ·»åŠ å¹…åº¦
            acceleration = price_change.diff()
            new_features['acceleration_magnitude'] = acceleration.abs()
            
            # 5. ğŸ†• æˆäº¤é‡æƒ…ç»ªï¼ˆåŸºäºæ”¾é‡/ç¼©é‡ï¼‰
            if 'volume' in df.columns:
                volume_ma = df['volume'].rolling(20).mean()
                new_features['volume_surge'] = (df['volume'] > volume_ma * 2).astype(int)  # æ”¾é‡
                new_features['volume_dry'] = (df['volume'] < volume_ma * 0.5).astype(int)  # ç¼©é‡
                
                # ä»·é‡èƒŒç¦»ï¼ˆä»·æ¶¨é‡è·Œ = çœ‹è·Œä¿¡å·ï¼‰
                price_trend = (price_change.rolling(5).mean() > 0).astype(int)
                volume_for_chg = df['volume'].replace(0, np.nan) if (df['volume'] == 0).sum() > 0 else df['volume']
                volume_chg = volume_for_chg.pct_change(fill_method=None)  # âœ… ä¿®å¤ï¼šæ˜ç¡®æŒ‡å®šfill_method=Noneé¿å…FutureWarning
                # âœ… ä¿®å¤ï¼šæ›¿æ¢infå€¼
                volume_chg = volume_chg.replace([np.inf, -np.inf], np.nan)
                volume_trend = (volume_chg.rolling(5).mean() > 0).astype(int)
                new_features['price_volume_divergence'] = (price_trend != volume_trend).astype(int)
            
            # 6. ğŸ†• å¸‚åœºæ³¢åŠ¨æƒ…ç»ª
            returns_abs = returns.abs()
            new_features['volatility_regime'] = returns_abs.rolling(20).mean() / returns_abs.rolling(100).mean()
            
            # 7. ğŸ†• è¶‹åŠ¿ä¸€è‡´æ€§ï¼ˆå¤šä¸ªå‡çº¿æ–¹å‘ä¸€è‡´åº¦ï¼‰
            if 'sma_5' in df.columns and 'sma_20' in df.columns and 'sma_50' in df.columns:
                sma5_up = (df['sma_5'] > df['sma_5'].shift(1)).astype(int)
                sma20_up = (df['sma_20'] > df['sma_20'].shift(1)).astype(int)
                sma50_up = (df['sma_50'] > df['sma_50'].shift(1)).astype(int)
                new_features['trend_alignment'] = (sma5_up + sma20_up + sma50_up) / 3  # 0-1ä¹‹é—´
            
            # 8. ğŸ†• å¸‚åœºæƒ…ç»ªç»¼åˆæŒ‡æ•°
            # ç»„åˆå¤šä¸ªæƒ…ç»ªæŒ‡æ ‡
            sentiment_score = 0
            if 'rsi_14' in df.columns:
                sentiment_score += ((df['rsi_14'] - 50) / 50)  # RSIè´¡çŒ®
            
            if 'macd_histogram' in df.columns:
                macd_norm = df['macd_histogram'] / (df['close'] * 0.01 + 1e-10)  # å½’ä¸€åŒ–
                sentiment_score += np.clip(macd_norm, -1, 1)  # MACDè´¡çŒ®
            
            sentiment_score += price_change.rolling(10).mean() * 100  # çŸ­æœŸåŠ¨é‡è´¡çŒ®
            new_features['sentiment_composite'] = sentiment_score / 3  # å¹³å‡
            
            # 9. ğŸ†• ä¹°å–å‹åŠ›æŒ‡æ ‡ï¼ˆåŸºäºKçº¿å½¢æ€ï¼‰
            # ä¹°å‹ = (æ”¶ç›˜-æœ€ä½)/(æœ€é«˜-æœ€ä½)ï¼Œå–å‹ = (æœ€é«˜-æ”¶ç›˜)/(æœ€é«˜-æœ€ä½)
            price_range = df['high'] - df['low']
            price_range = price_range.replace(0, np.nan)  # é¿å…é™¤ä»¥0
            new_features['buy_pressure'] = (df['close'] - df['low']) / price_range
            new_features['sell_pressure'] = (df['high'] - df['close']) / price_range
            new_features['pressure_diff'] = new_features['buy_pressure'] - new_features['sell_pressure']
            
            # ä¹°å–å‹åŠ›è¶‹åŠ¿ï¼ˆå¤šå‘¨æœŸå¹³å‡ï¼‰
            new_features['buy_pressure_ma5'] = new_features['buy_pressure'].rolling(5).mean()
            new_features['sell_pressure_ma5'] = new_features['sell_pressure'].rolling(5).mean()
            
            # 10. ğŸ†• æˆäº¤é‡åŠ æƒæƒ…ç»ª
            if 'volume' in df.columns:
                # æˆäº¤é‡åŠ æƒä»·æ ¼å˜åŒ–
                volume_weighted_return = price_change * df['volume']
                new_features['volume_weighted_sentiment'] = (
                    volume_weighted_return.rolling(10).sum() / 
                    (df['volume'].rolling(10).sum() + 1e-10)
                )
                
                # æˆäº¤é‡æƒ…ç»ªå¼ºåº¦ï¼ˆå¤§å•ä¸»å¯¼ç¨‹åº¦ï¼‰
                volume_std = df['volume'].rolling(20).std()
                new_features['volume_sentiment_strength'] = (
                    (df['volume'] - df['volume'].rolling(20).mean()) / 
                    (volume_std + 1e-10)
                )
            
            # 11. ğŸ†• å¸‚åœºå®½åº¦æŒ‡æ ‡ï¼ˆä»·æ ¼åˆ†å¸ƒï¼‰
            # ä»·æ ¼åç¦»ç¨‹åº¦ï¼ˆå½“å‰ä»· vs å¤šå‘¨æœŸå‡ä»·ï¼‰
            if 'sma_5' in df.columns and 'sma_20' in df.columns and 'sma_50' in df.columns:
                new_features['price_deviation_5'] = (df['close'] - df['sma_5']) / df['sma_5']
                new_features['price_deviation_20'] = (df['close'] - df['sma_20']) / df['sma_20']
                new_features['price_deviation_50'] = (df['close'] - df['sma_50']) / df['sma_50']
                
                # å¸‚åœºå®½åº¦ï¼šå¤šä¸ªå‡çº¿ä¹‹é—´çš„è·ç¦»
                new_features['market_breadth'] = (
                    (df['sma_5'] - df['sma_20']).abs() + 
                    (df['sma_20'] - df['sma_50']).abs()
                ) / df['close']
            
            # 12. ğŸ†• æç«¯æƒ…ç»ªæ£€æµ‹
            # æ£€æµ‹æç«¯ä¸Šæ¶¨/ä¸‹è·Œï¼ˆå¯èƒ½çš„åè½¬ä¿¡å·ï¼‰
            extreme_up = (price_change > price_change.rolling(50).mean() + 2 * price_change.rolling(50).std())
            extreme_down = (price_change < price_change.rolling(50).mean() - 2 * price_change.rolling(50).std())
            new_features['extreme_move'] = extreme_up.astype(int) - extreme_down.astype(int)  # +1=æç«¯ä¸Šæ¶¨, -1=æç«¯ä¸‹è·Œ
            
            # æç«¯ç§»åŠ¨åçš„åè½¬æ¦‚ç‡ï¼ˆå†å²ç»Ÿè®¡ï¼‰
            new_features['extreme_move_decay'] = new_features['extreme_move'].rolling(5).sum()  # è¿‘æœŸæç«¯æ¬¡æ•°
            
            # ä¸€æ¬¡æ€§æ·»åŠ æ‰€æœ‰ç‰¹å¾
            df = pd.concat([df, pd.DataFrame(new_features, index=df.index)], axis=1)
            
            
            return df
            
        except Exception as e:
            logger.error(f"âŒ æ·»åŠ å¸‚åœºæƒ…ç»ªç‰¹å¾å¤±è´¥: {e}")
            logger.error(traceback.format_exc())
            return df
    
    def _add_multi_timeframe_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """æ·»åŠ å¤šæ—¶é—´æ¡†æ¶ç‰¹å¾èåˆï¼ˆä¼˜åŒ–ç›®æ ‡ï¼šå‡†ç¡®ç‡+5-7%ï¼‰
        
        ç›®æ ‡ï¼šå°†é•¿å‘¨æœŸè¶‹åŠ¿ä¿¡æ¯èå…¥çŸ­å‘¨æœŸé¢„æµ‹ï¼Œå‡å°‘é€†åŠ¿äº¤æ˜“
        æ–¹æ³•ï¼šé€šè¿‡é‡é‡‡æ ·å½“å‰æ•°æ®æ¥æ¨¡æ‹Ÿæ›´é•¿å‘¨æœŸçš„ç‰¹å¾
        """
        try:
            new_features = {}
            
            # ç¡®ä¿æœ‰timestampåˆ—ç”¨äºé‡é‡‡æ ·
            if 'timestamp' not in df.columns:
                logger.warning("âš ï¸ ç¼ºå°‘timestampåˆ—ï¼Œè·³è¿‡å¤šæ—¶é—´æ¡†æ¶ç‰¹å¾")
                return df
            
            # è®¾ç½®timestampä¸ºç´¢å¼•ä»¥ä¾¿é‡é‡‡æ ·
            df_temp = df.set_index('timestamp')
            
            # 1. æ¨¡æ‹Ÿ1hæ•°æ®ï¼ˆé•¿å‘¨æœŸè¶‹åŠ¿å‚è€ƒï¼Œå¯¹3m/5m/15méƒ½æœ‰ç”¨ï¼‰
            # é‡é‡‡æ ·åˆ°1hå¹¶å‘å‰å¡«å……
            df_1h = df_temp.resample('1h').agg({
                'open': 'first',
                'high': 'max',
                'low': 'min',
                'close': 'last',
                'volume': 'sum'
            }).ffill()
            
            # è®¡ç®—1hçš„å…³é”®æŒ‡æ ‡
            close_1h = df_1h['close']
            sma_20_1h = close_1h.rolling(20).mean()
            sma_50_1h = close_1h.rolling(50).mean()
            rsi_1h = self._calculate_rsi(close_1h, 14)
            
            # 1hè¶‹åŠ¿æ–¹å‘ï¼ˆ1=ä¸Šæ¶¨ï¼Œ0=æ¨ªç›˜ï¼Œ-1=ä¸‹è·Œï¼‰
            trend_1h = pd.Series(0, index=df_1h.index)
            trend_1h[sma_20_1h > sma_50_1h] = 1  # å¤šå¤´
            trend_1h[sma_20_1h < sma_50_1h] = -1  # ç©ºå¤´
            
            # 1hæ³¢åŠ¨ç‡
            close_1h_safe = close_1h.replace(0, np.nan) if (close_1h == 0).sum() > 0 else close_1h
            returns_1h = close_1h_safe.pct_change(fill_method=None)  # âœ… ä¿®å¤ï¼šæ˜ç¡®æŒ‡å®šfill_method=Noneé¿å…FutureWarning
            # âœ… ä¿®å¤ï¼šæ›¿æ¢infå€¼
            returns_1h = returns_1h.replace([np.inf, -np.inf], np.nan)
            volatility_1h = returns_1h.rolling(20).std()
            
            # ğŸ”‘ ä¿®å¤æœªæ¥å‡½æ•°ï¼šshift(1)ç¡®ä¿åªä½¿ç”¨ä¸Šä¸€æ ¹å·²æ”¶ç›˜çš„1h Kçº¿æ•°æ®
            # å°†1hæ•°æ®å¯¹é½åˆ°åŸå§‹æ—¶é—´æ¡†æ¶ï¼ˆä½¿ç”¨shift(1)é¿å…æœªæ¥æ•°æ®æ³„éœ²ï¼‰
            trend_1h_shifted = trend_1h.shift(1)
            rsi_1h_shifted = rsi_1h.shift(1)
            volatility_1h_shifted = volatility_1h.shift(1)
            sma_20_1h_shifted = sma_20_1h.shift(1)
            sma_50_1h_shifted = sma_50_1h.shift(1)
            
            new_features['trend_1h'] = trend_1h_shifted.reindex(df_temp.index, method='ffill')
            new_features['rsi_1h'] = rsi_1h_shifted.reindex(df_temp.index, method='ffill')
            new_features['volatility_1h'] = volatility_1h_shifted.reindex(df_temp.index, method='ffill')
            new_features['sma_20_1h'] = sma_20_1h_shifted.reindex(df_temp.index, method='ffill')
            new_features['sma_50_1h'] = sma_50_1h_shifted.reindex(df_temp.index, method='ffill')
            
            # 2. æ¨¡æ‹Ÿ15mæ•°æ®ï¼ˆä¸­æœŸè¶‹åŠ¿å‚è€ƒï¼Œå¯¹3m/5mæœ‰ç”¨ï¼‰
            df_15m = df_temp.resample('15min').agg({
                'open': 'first',
                'high': 'max',
                'low': 'min',
                'close': 'last',
                'volume': 'sum'
            }).ffill()
            
            close_15m = df_15m['close']
            sma_20_15m = close_15m.rolling(20).mean()
            sma_50_15m = close_15m.rolling(50).mean()
            rsi_15m = self._calculate_rsi(close_15m, 14)
            
            # 15mè¶‹åŠ¿æ–¹å‘
            trend_15m = pd.Series(0, index=df_15m.index)
            trend_15m[sma_20_15m > sma_50_15m] = 1
            trend_15m[sma_20_15m < sma_50_15m] = -1
            
            # 15mæ³¢åŠ¨ç‡
            close_15m_safe = close_15m.replace(0, np.nan) if (close_15m == 0).sum() > 0 else close_15m
            returns_15m = close_15m_safe.pct_change(fill_method=None)  # âœ… ä¿®å¤ï¼šæ˜ç¡®æŒ‡å®šfill_method=Noneé¿å…FutureWarning
            # âœ… ä¿®å¤ï¼šæ›¿æ¢infå€¼
            returns_15m = returns_15m.replace([np.inf, -np.inf], np.nan)
            volatility_15m = returns_15m.rolling(20).std()
            
            # ğŸ”‘ ä¿®å¤æœªæ¥å‡½æ•°ï¼šshift(1)ç¡®ä¿åªä½¿ç”¨ä¸Šä¸€æ ¹å·²æ”¶ç›˜çš„15m Kçº¿æ•°æ®
            # å°†15mæ•°æ®å¯¹é½åˆ°åŸå§‹æ—¶é—´æ¡†æ¶ï¼ˆä½¿ç”¨shift(1)é¿å…æœªæ¥æ•°æ®æ³„éœ²ï¼‰
            trend_15m_shifted = trend_15m.shift(1)
            rsi_15m_shifted = rsi_15m.shift(1)
            volatility_15m_shifted = volatility_15m.shift(1)
            sma_20_15m_shifted = sma_20_15m.shift(1)
            sma_50_15m_shifted = sma_50_15m.shift(1)
            
            new_features['trend_15m'] = trend_15m_shifted.reindex(df_temp.index, method='ffill')
            new_features['rsi_15m'] = rsi_15m_shifted.reindex(df_temp.index, method='ffill')
            new_features['volatility_15m'] = volatility_15m_shifted.reindex(df_temp.index, method='ffill')
            new_features['sma_20_15m'] = sma_20_15m_shifted.reindex(df_temp.index, method='ffill')
            new_features['sma_50_15m'] = sma_50_15m_shifted.reindex(df_temp.index, method='ffill')
            
            # 3. è¶‹åŠ¿ä¸€è‡´æ€§ç‰¹å¾ï¼ˆçŸ­ä¸­é•¿å‘¨æœŸæ˜¯å¦ä¸€è‡´ï¼‰
            if 'sma_20' in df_temp.columns and 'sma_50' in df_temp.columns:
                # å½“å‰æ—¶é—´æ¡†æ¶çš„è¶‹åŠ¿ï¼ˆä½¿ç”¨df_tempé¿å…ç´¢å¼•ä¸åŒ¹é…ï¼‰
                trend_current = pd.Series(0, index=df_temp.index)
                trend_current[df_temp['sma_20'] > df_temp['sma_50']] = 1
                trend_current[df_temp['sma_20'] < df_temp['sma_50']] = -1
                
                # å¤šæ—¶é—´æ¡†æ¶è¶‹åŠ¿ä¸€è‡´æ€§
                new_features['trend_alignment_15m'] = (trend_current == new_features['trend_15m']).astype(int)
                new_features['trend_alignment_1h'] = (trend_current == new_features['trend_1h']).astype(int)
                new_features['trend_alignment_all'] = (
                    (new_features['trend_alignment_15m'] + new_features['trend_alignment_1h']) / 2
                )
            
            # 4. ç›¸å¯¹å¼ºå¼±ï¼ˆå½“å‰æ—¶é—´æ¡†æ¶ vs æ›´é•¿å‘¨æœŸï¼‰
            if 'rsi_14' in df_temp.columns:
                new_features['rsi_diff_15m'] = df_temp['rsi_14'] - new_features['rsi_15m']
                new_features['rsi_diff_1h'] = df_temp['rsi_14'] - new_features['rsi_1h']
            
            # 5. ä»·æ ¼ç›¸å¯¹ä½ç½®ï¼ˆç›¸å¯¹äºæ›´é•¿å‘¨æœŸå‡çº¿ï¼‰
            if 'close' in df_temp.columns:
                new_features['price_to_sma20_15m'] = (df_temp['close'] - new_features['sma_20_15m']) / new_features['sma_20_15m']
                new_features['price_to_sma50_15m'] = (df_temp['close'] - new_features['sma_50_15m']) / new_features['sma_50_15m']
                new_features['price_to_sma20_1h'] = (df_temp['close'] - new_features['sma_20_1h']) / new_features['sma_20_1h']
                new_features['price_to_sma50_1h'] = (df_temp['close'] - new_features['sma_50_1h']) / new_features['sma_50_1h']
            
            # å°†æ–°ç‰¹å¾æ·»åŠ åˆ°df_tempï¼ˆç¡®ä¿ç´¢å¼•ä¸€è‡´ï¼‰
            for col_name, col_data in new_features.items():
                df_temp[col_name] = col_data
            
            # æ¢å¤åŸå§‹DataFrameç»“æ„ï¼ˆreset timestampç´¢å¼•ï¼‰
            df = df_temp.reset_index()
            
            
            return df
            
        except Exception as e:
            logger.error(f"âŒ æ·»åŠ å¤šæ—¶é—´æ¡†æ¶ç‰¹å¾å¤±è´¥: {e}")
            logger.error(traceback.format_exc())
            return df
    
    def _calculate_rsi(self, prices: pd.Series, period: int = 14) -> pd.Series:
        """è®¡ç®—RSIæŒ‡æ ‡"""
        try:
            delta = prices.diff()
            gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()
            loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()
            rs = gain / (loss + 1e-10)
            rsi = 100 - (100 / (1 + rs))
            return rsi
        except:
            return pd.Series(50, index=prices.index)  # é»˜è®¤å€¼
    
    def get_feature_importance(self, df: pd.DataFrame) -> Dict[str, float]:
        """è·å–ç‰¹å¾é‡è¦æ€§ï¼ˆåŸºäºæ–¹å·®ï¼‰"""
        try:
            # æ’é™¤éç‰¹å¾åˆ—
            exclude_cols = ['timestamp', 'datetime', 'open', 'high', 'low', 'close', 'volume', 'quote_volume']
            feature_cols = [col for col in df.columns if col not in exclude_cols]
            
            # è®¡ç®—ç‰¹å¾æ–¹å·®
            feature_variance = {}
            for col in feature_cols:
                # âœ… ä½¿ç”¨pandasç±»å‹æ£€æŸ¥
                if pd.api.types.is_numeric_dtype(df[col]):
                    variance = df[col].var()
                    feature_variance[col] = variance if not np.isnan(variance) else 0
            
            # å½’ä¸€åŒ–
            total_variance = sum(feature_variance.values())
            if total_variance > 0:
                feature_importance = {k: v/total_variance for k, v in feature_variance.items()}
            else:
                feature_importance = feature_variance
            
            return dict(sorted(feature_importance.items(), key=lambda x: x[1], reverse=True))
            
        except Exception as e:
            logger.error(f"è®¡ç®—ç‰¹å¾é‡è¦æ€§å¤±è´¥: {e}")
            return {}
    
    def select_features(self, df: pd.DataFrame, top_n: int = 50) -> List[str]:
        """é€‰æ‹©é‡è¦ç‰¹å¾"""
        try:
            feature_importance = self.get_feature_importance(df)
            
            # é€‰æ‹©å‰Nä¸ªé‡è¦ç‰¹å¾
            selected_features = list(feature_importance.keys())[:top_n]
            
            logger.debug(f"é€‰æ‹©äº†{len(selected_features)}ä¸ªé‡è¦ç‰¹å¾")
            return selected_features
            
        except Exception as e:
            logger.error(f"ç‰¹å¾é€‰æ‹©å¤±è´¥: {e}")
            return []
    
    def _add_trend_strength_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """æ·»åŠ è¶‹åŠ¿å¼ºåº¦ç‰¹å¾ï¼ˆ~15ä¸ªç‰¹å¾ï¼‰"""
        try:
            new_features = {}
            
            # 1. ADXè¶‹åŠ¿å¼ºåº¦åˆ†çº§
            if 'adx' in df.columns:
                new_features['trend_weak'] = (df['adx'] < 20).astype(int)
                new_features['trend_moderate'] = ((df['adx'] >= 20) & (df['adx'] < 40)).astype(int)
                new_features['trend_strong'] = (df['adx'] >= 40).astype(int)
            
            # 2. çº¿æ€§å›å½’æ–œç‡ï¼ˆè¶‹åŠ¿æ–¹å‘ï¼‰
            for window in [5, 10, 20]:
                slopes = []
                for i in range(len(df)):
                    if i < window:
                        slopes.append(0)
                    else:
                        y = df['close'].iloc[i-window:i].values
                        x = np.arange(window)
                        slope = np.polyfit(x, y, 1)[0] / (df['close'].iloc[i] + 1e-10)
                        slopes.append(slope)
                new_features[f'trend_slope_{window}'] = slopes
            
            # 3. è¶‹åŠ¿ä¸€è‡´æ€§ï¼ˆå¤šå‘¨æœŸç¡®è®¤ï¼‰
            sma5 = df['close'].rolling(5).mean()
            sma10 = df['close'].rolling(10).mean()
            sma20 = df['close'].rolling(20).mean()
            
            new_features['trend_alignment'] = (
                ((df['close'] > sma5) & (sma5 > sma10) & (sma10 > sma20)).astype(int) -
                ((df['close'] < sma5) & (sma5 < sma10) & (sma10 < sma20)).astype(int)
            )
            
            # 4. EMAè¶‹åŠ¿å¼ºåº¦
            ema12 = df['close'].ewm(span=12).mean()
            ema26 = df['close'].ewm(span=26).mean()
            new_features['ema_trend_strength'] = (ema12 - ema26) / (df['close'] + 1e-10)
            
            return df.assign(**new_features)
            
        except Exception as e:
            logger.error(f"æ·»åŠ è¶‹åŠ¿å¼ºåº¦ç‰¹å¾å¤±è´¥: {e}")
            return df
    
    def _add_support_resistance_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """æ·»åŠ æ”¯æ’‘é˜»åŠ›ç‰¹å¾ï¼ˆ~18ä¸ªç‰¹å¾ï¼‰"""
        try:
            new_features = {}
            
            # 1. è¿‘æœŸé«˜ä½ç‚¹
            for window in [10, 20, 50]:
                new_features[f'high_{window}d'] = df['high'].rolling(window).max()
                new_features[f'low_{window}d'] = df['low'].rolling(window).min()
                
                # ä»·æ ¼è·ç¦»é«˜ä½ç‚¹çš„ç™¾åˆ†æ¯”
                new_features[f'dist_to_high_{window}'] = (
                    (df['close'] - new_features[f'high_{window}d']) / 
                    (new_features[f'high_{window}d'] + 1e-10)
                )
                new_features[f'dist_to_low_{window}'] = (
                    (df['close'] - new_features[f'low_{window}d']) / 
                    (new_features[f'low_{window}d'] + 1e-10)
                )
            
            # 2. æ”¯æ’‘é˜»åŠ›çªç ´
            for window in [20, 50]:
                # çªç ´å†å²é«˜ç‚¹
                new_features[f'breakout_high_{window}'] = (
                    df['close'] > df['high'].rolling(window).max().shift(1)
                ).astype(int)
                
                # è·Œç ´å†å²ä½ç‚¹
                new_features[f'breakdown_low_{window}'] = (
                    df['close'] < df['low'].rolling(window).min().shift(1)
                ).astype(int)
            
            return df.assign(**new_features)
            
        except Exception as e:
            logger.error(f"æ·»åŠ æ”¯æ’‘é˜»åŠ›ç‰¹å¾å¤±è´¥: {e}")
            return df
    
    def _add_advanced_momentum_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """æ·»åŠ é«˜çº§åŠ¨é‡æŒ‡æ ‡ï¼ˆ~15ä¸ªç‰¹å¾ï¼‰"""
        try:
            new_features = {}
            
            # 1. TSI (True Strength Index)
            price_change = df['close'].diff()
            pc_ema25 = price_change.ewm(span=25).mean()
            pc_ema13 = pc_ema25.ewm(span=13).mean()
            abs_pc_ema25 = price_change.abs().ewm(span=25).mean()
            abs_pc_ema13 = abs_pc_ema25.ewm(span=13).mean()
            new_features['tsi'] = 100 * pc_ema13 / (abs_pc_ema13 + 1e-10)
            new_features['tsi_signal'] = new_features['tsi'].ewm(span=7).mean()
            
            # 2. CMO (Chande Momentum Oscillator)
            for period in [9, 14]:
                price_diff = df['close'].diff()
                gain = price_diff.where(price_diff > 0, 0).rolling(period).sum()
                loss = -price_diff.where(price_diff < 0, 0).rolling(period).sum()
                new_features[f'cmo_{period}'] = 100 * (gain - loss) / (gain + loss + 1e-10)
            
            # 3. AroonæŒ‡æ ‡
            for period in [14, 25]:
                aroon_up = []
                aroon_down = []
                
                for i in range(len(df)):
                    if i < period:
                        aroon_up.append(50)
                        aroon_down.append(50)
                    else:
                        window_high = df['high'].iloc[i-period:i+1]
                        window_low = df['low'].iloc[i-period:i+1]
                        
                        days_since_high = period - window_high.argmax()
                        days_since_low = period - window_low.argmin()
                        
                        aroon_up.append((period - days_since_high) / period * 100)
                        aroon_down.append((period - days_since_low) / period * 100)
                
                new_features[f'aroon_up_{period}'] = aroon_up
                new_features[f'aroon_down_{period}'] = aroon_down
                new_features[f'aroon_osc_{period}'] = np.array(aroon_up) - np.array(aroon_down)
            
            return df.assign(**new_features)
            
        except Exception as e:
            logger.error(f"æ·»åŠ é«˜çº§åŠ¨é‡ç‰¹å¾å¤±è´¥: {e}")
            return df
    
    def _add_pattern_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """æ·»åŠ ä»·æ ¼å½¢æ€è¯†åˆ«ç‰¹å¾ï¼ˆ~14ä¸ªç‰¹å¾ï¼‰"""
        try:
            new_features = {}
            
            body = df['close'] - df['open']
            upper_shadow = df['high'] - df[['close', 'open']].max(axis=1)
            lower_shadow = df[['close', 'open']].min(axis=1) - df['low']
            
            # 1. é”¤å­çº¿ï¼ˆHammerï¼‰
            new_features['hammer'] = (
                (lower_shadow > body.abs() * 2) & 
                (upper_shadow < body.abs() * 0.5) &
                (body < 0)
            ).astype(int)
            
            # 2. ä¸ŠåŠçº¿ï¼ˆHanging Manï¼‰
            new_features['hanging_man'] = (
                (lower_shadow > body.abs() * 2) & 
                (upper_shadow < body.abs() * 0.5) &
                (body > 0)
            ).astype(int)
            
            # 3. æµæ˜Ÿçº¿ï¼ˆShooting Starï¼‰
            new_features['shooting_star'] = (
                (upper_shadow > body.abs() * 2) & 
                (lower_shadow < body.abs() * 0.5)
            ).astype(int)
            
            # 4. åå­—æ˜Ÿï¼ˆDojiï¼‰
            new_features['doji'] = (body.abs() < (df['high'] - df['low']) * 0.1).astype(int)
            
            # 5. åå™¬å½¢æ€
            prev_body = body.shift(1)
            
            # çœ‹æ¶¨åå™¬
            new_features['bullish_engulf'] = (
                (body > 0) & 
                (prev_body < 0) &
                (df['open'] <= df['close'].shift(1)) &
                (df['close'] >= df['open'].shift(1))
            ).astype(int)
            
            # çœ‹è·Œåå™¬
            new_features['bearish_engulf'] = (
                (body < 0) & 
                (prev_body > 0) &
                (df['open'] >= df['close'].shift(1)) &
                (df['close'] <= df['open'].shift(1))
            ).astype(int)
            
            # 6. ä¸‰åªä¹Œé¸¦
            new_features['three_black_crows'] = (
                (body < 0) &
                (body.shift(1) < 0) &
                (body.shift(2) < 0) &
                (df['close'] < df['close'].shift(1)) &
                (df['close'].shift(1) < df['close'].shift(2))
            ).astype(int)
            
            # 7. ä¸‰åªç™½å…µ
            new_features['three_white_soldiers'] = (
                (body > 0) &
                (body.shift(1) > 0) &
                (body.shift(2) > 0) &
                (df['close'] > df['close'].shift(1)) &
                (df['close'].shift(1) > df['close'].shift(2))
            ).astype(int)
            
            # 8. ç¼ºå£æ£€æµ‹
            new_features['gap_up'] = (df['low'] > df['high'].shift(1)).astype(int)
            new_features['gap_down'] = (df['high'] < df['low'].shift(1)).astype(int)
            new_features['gap_size'] = np.where(
                new_features['gap_up'] == 1,
                (df['low'] - df['high'].shift(1)) / (df['close'].shift(1) + 1e-10),
                np.where(
                    new_features['gap_down'] == 1,
                    (df['high'] - df['low'].shift(1)) / (df['close'].shift(1) + 1e-10),
                    0
                )
            )
            
            return df.assign(**new_features)
            
        except Exception as e:
            logger.error(f"æ·»åŠ ä»·æ ¼å½¢æ€ç‰¹å¾å¤±è´¥: {e}")
            return df
    
    def _add_order_flow_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """æ·»åŠ è®¢å•æµç‰¹å¾ï¼ˆ~10ä¸ªç‰¹å¾ï¼‰"""
        try:
            new_features = {}
            
            if 'taker_buy_base_volume' in df.columns and 'volume' in df.columns:
                # 1. ä¹°å–æ¯”ç‡
                taker_sell_volume = df['volume'] - df['taker_buy_base_volume']
                new_features['buy_sell_ratio'] = (
                    df['taker_buy_base_volume'] / (taker_sell_volume + 1e-10)
                )
                
                # 2. å‡€ä¹°å…¥å‹åŠ›
                new_features['net_buy_pressure'] = (
                    df['taker_buy_base_volume'] - taker_sell_volume
                ) / (df['volume'] + 1e-10)
                
                # 3. å¤§å•æ£€æµ‹
                buy_ratio = df['taker_buy_base_volume'] / (df['volume'] + 1e-10)
                buy_ratio_mean = buy_ratio.rolling(20).mean()
                buy_ratio_std = buy_ratio.rolling(20).std()
                
                new_features['large_buy_orders'] = (
                    buy_ratio > buy_ratio_mean + 2 * buy_ratio_std
                ).astype(int)
                
                new_features['large_sell_orders'] = (
                    buy_ratio < buy_ratio_mean - 2 * buy_ratio_std
                ).astype(int)
                
                # 4. ç´¯ç§¯ä¹°å–å‹åŠ›
                for window in [5, 10, 20]:
                    new_features[f'cumulative_buy_pressure_{window}'] = (
                        new_features['net_buy_pressure'].rolling(window).sum()
                    )
            
            return df.assign(**new_features)
            
        except Exception as e:
            logger.error(f"æ·»åŠ è®¢å•æµç‰¹å¾å¤±è´¥: {e}")
            return df
    
    def _add_swing_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """æ·»åŠ æ³¢æ®µè¯†åˆ«ç‰¹å¾ï¼ˆ~10ä¸ªç‰¹å¾ï¼‰"""
        try:
            new_features = {}
            
            # 1. Swing High/Lowæ£€æµ‹
            for window in [5, 10]:
                # Swing High
                rolling_max = df['high'].rolling(window*2+1, center=True).max()
                new_features[f'swing_high_{window}'] = (
                    df['high'] == rolling_max
                ).astype(int)
                
                # Swing Low
                rolling_min = df['low'].rolling(window*2+1, center=True).min()
                new_features[f'swing_low_{window}'] = (
                    df['low'] == rolling_min
                ).astype(int)
            
            # 2. ä»·æ ¼åœ¨æ³¢æ®µä¸­çš„ä½ç½®
            for window in [20, 50]:
                recent_high = df['high'].rolling(window).max()
                recent_low = df['low'].rolling(window).min()
                
                new_features[f'position_in_range_{window}'] = (
                    (df['close'] - recent_low) / (recent_high - recent_low + 1e-10)
                )
            
            # 3. æ³¢æ®µé¢‘ç‡
            if 'swing_high_5' in new_features:
                new_features['swing_frequency'] = new_features['swing_high_5'].rolling(50).sum()
            
            return df.assign(**new_features)
            
        except Exception as e:
            logger.error(f"æ·»åŠ æ³¢æ®µè¯†åˆ«ç‰¹å¾å¤±è´¥: {e}")
            return df

# å…¨å±€ç‰¹å¾å·¥ç¨‹å™¨å®ä¾‹
feature_engineer = FeatureEngineer()