# ğŸš€ é«˜çº§ä¼˜åŒ–å®æ–½æ–¹æ¡ˆ

**åˆ›å»ºæ—¶é—´**: 2025-10-21  
**é€‚ç”¨åœºæ™¯**: å½“å‰å‡†ç¡®ç‡42-47%ï¼Œéœ€è¦è¿›ä¸€æ­¥æå‡è‡³55%+

---

## âš ï¸ é‡è¦æ¾„æ¸…ï¼šHOLDæƒ©ç½šçš„ä½œç”¨

### ç”¨æˆ·ç–‘é—®
> "æ›´æ¿€è¿›çš„HOLDæƒ©ç½šï¼ˆ0.3-0.4ï¼‰æ˜¯ä¸æ˜¯ä»£è¡¨ç€ä¿¡å·è¶Šæ¥è¶Šå°‘ï¼Ÿ"

### âœ… æ­£ç¡®ç­”æ¡ˆï¼šæ°æ°ç›¸åï¼

**HOLDæƒ©ç½šæœºåˆ¶**:
```python
# æƒ©ç½šç³»æ•°åº”ç”¨
meta_hold_penalty = np.where(y == 1, 0.6, 1.0)
#                                    â†‘     â†‘
#                               HOLDæƒé‡  å…¶ä»–æƒé‡

# è®­ç»ƒæ—¶æ ·æœ¬æƒé‡
sample_weights = class_weights * hold_penalty

# HOLDæ ·æœ¬æƒé‡ = class_weight Ã— 0.6
# LONGæ ·æœ¬æƒé‡ = class_weight Ã— 1.0  
# SHORTæ ·æœ¬æƒé‡ = class_weight Ã— 1.0
```

**æ¨¡å‹å­¦ä¹ æ•ˆæœ**:

| HOLDæƒ©ç½šç³»æ•° | HOLDæ ·æœ¬é‡è¦æ€§ | æ¨¡å‹å€¾å‘ | é¢„æµ‹åˆ†å¸ƒ | ä¿¡å·æ•°é‡ |
|-------------|---------------|---------|---------|---------|
| **1.0ï¼ˆæ— æƒ©ç½šï¼‰** | 100% | è°¨æ…é¢„æµ‹HOLD | HOLD 60-80% | â¬‡ï¸â¬‡ï¸ **æå°‘** |
| **0.7ï¼ˆè½»åº¦ï¼‰** | 70% | åå‘HOLD | HOLD 45-55% | â¬‡ï¸ è¾ƒå°‘ |
| **0.6ï¼ˆä¸­ç­‰ï¼‰** | 60% | å¹³è¡¡ | HOLD 35-40% | â†’ æ­£å¸¸ |
| **0.5ï¼ˆè¾ƒé‡ï¼‰** | 50% | åå‘äº¤æ˜“ | HOLD 28-32% | â¬†ï¸ è¾ƒå¤š |
| **0.3ï¼ˆæ¿€è¿›ï¼‰** | 30% | æ¿€è¿›äº¤æ˜“ | HOLD 15-20% | â¬†ï¸â¬†ï¸ **å¾ˆå¤š** |

**ç¤ºä¾‹**:

```python
# æƒ©ç½š0.6ï¼ˆå½“å‰ï¼‰
é¢„æµ‹åˆ†å¸ƒ: SHORT 32%, HOLD 36%, LONG 32%
æ¯å¤©ä¿¡å·: çº¦5-8ä¸ª

# æƒ©ç½š0.3ï¼ˆæ¿€è¿›ï¼‰
é¢„æµ‹åˆ†å¸ƒ: SHORT 40%, HOLD 20%, LONG 40%
æ¯å¤©ä¿¡å·: çº¦15-25ä¸ª  â† ä¿¡å·å¢åŠ ï¼
```

### ğŸ¯ ç»“è®º

âœ… **æ›´æ¿€è¿›çš„HOLDæƒ©ç½šï¼ˆ0.3-0.4ï¼‰**:
- ä¿¡å·**æ›´å¤š**ï¼ˆä¸æ˜¯æ›´å°‘ï¼ï¼‰
- äº¤æ˜“**æ›´é¢‘ç¹**
- é€‚åˆ**é«˜é¢‘äº¤æ˜“ç­–ç•¥**

âš ï¸ **é£é™©**:
- å¯èƒ½å¢åŠ é”™è¯¯ä¿¡å·
- è¿‡åº¦äº¤æ˜“ï¼ˆæ‰‹ç»­è´¹å¢åŠ ï¼‰
- éœ€è¦æ›´é«˜çš„å‡†ç¡®ç‡æ”¯æ’‘ï¼ˆâ‰¥60%ï¼‰

**å»ºè®®**: 
- å½“å‰å‡†ç¡®ç‡33.77% â†’ å…ˆæå‡åˆ°50%+
- å†è€ƒè™‘æ¿€è¿›HOLDæƒ©ç½šï¼ˆ0.3-0.4ï¼‰
- ç›®å‰ä¿æŒ0.5-0.6æ˜¯åˆç†çš„

---

## ğŸ“Š 2. æ·»åŠ æ›´å¤šæŠ€æœ¯æŒ‡æ ‡ç‰¹å¾

### å½“å‰å·²æœ‰ç‰¹å¾ï¼ˆçº¦120ä¸ªï¼‰

**å·²å®ç°**:
- âœ… åŸºç¡€ä»·æ ¼ç‰¹å¾ï¼ˆSMA, EMA, ä»·æ ¼å˜åŒ–ï¼‰
- âœ… æŠ€æœ¯æŒ‡æ ‡ï¼ˆRSI, MACD, å¸ƒæ—å¸¦, KDJ, ATR, ADXï¼‰
- âœ… æˆäº¤é‡ç‰¹å¾ï¼ˆOBV, æˆäº¤é‡å˜åŒ–ï¼‰
- âœ… æ—¶é—´ç‰¹å¾ï¼ˆå°æ—¶ã€æ˜ŸæœŸã€æœˆä»½ï¼‰
- âœ… å¾®è§‚ç»“æ„ç‰¹å¾ï¼ˆKçº¿å½¢æ€ã€ä¹°å–å‹åŠ›ï¼‰
- âœ… æ³¢åŠ¨ç‡ç‰¹å¾ï¼ˆATR, å†å²æ³¢åŠ¨ç‡ï¼‰
- âœ… åŠ¨é‡ç‰¹å¾ï¼ˆROC, RSIï¼‰
- âœ… ç»Ÿè®¡ç‰¹å¾ï¼ˆååº¦ã€å³°åº¦ã€HurstæŒ‡æ•°ï¼‰
- âœ… æƒ…ç»ªç‰¹å¾ï¼ˆææ…ŒæŒ‡æ•°ã€ä»·é‡èƒŒç¦»ï¼‰

### å¯ä»¥æ–°å¢çš„é«˜çº§ç‰¹å¾

#### **ç±»åˆ«1: è¶‹åŠ¿å¼ºåº¦ç‰¹å¾**

```python
def _add_trend_strength_features(self, df: pd.DataFrame) -> pd.DataFrame:
    """æ·»åŠ è¶‹åŠ¿å¼ºåº¦ç‰¹å¾"""
    new_features = {}
    
    # 1. ADXè¶‹åŠ¿å¼ºåº¦åˆ†çº§
    if 'adx' in df.columns:
        new_features['trend_weak'] = (df['adx'] < 20).astype(int)      # å¼±è¶‹åŠ¿
        new_features['trend_moderate'] = (df['adx'] < 40).astype(int)  # ä¸­ç­‰
        new_features['trend_strong'] = (df['adx'] >= 40).astype(int)   # å¼ºè¶‹åŠ¿
    
    # 2. çº¿æ€§å›å½’æ–œç‡ï¼ˆè¿‘æœŸè¶‹åŠ¿æ–¹å‘ï¼‰
    for window in [5, 10, 20]:
        slopes = []
        for i in range(len(df)):
            if i < window:
                slopes.append(0)
            else:
                y = df['close'].iloc[i-window:i].values
                x = np.arange(window)
                slope = np.polyfit(x, y, 1)[0] / df['close'].iloc[i]
                slopes.append(slope)
        new_features[f'trend_slope_{window}'] = slopes
    
    # 3. RÂ²æ‹Ÿåˆåº¦ï¼ˆè¶‹åŠ¿å¯é æ€§ï¼‰
    for window in [10, 20]:
        r_squared = []
        for i in range(len(df)):
            if i < window:
                r_squared.append(0)
            else:
                y = df['close'].iloc[i-window:i].values
                x = np.arange(window)
                _, residuals, _, _, _ = np.polyfit(x, y, 1, full=True)
                ss_res = residuals[0] if len(residuals) > 0 else 0
                ss_tot = np.sum((y - np.mean(y))**2)
                r2 = 1 - (ss_res / (ss_tot + 1e-10))
                r_squared.append(r2)
        new_features[f'trend_r2_{window}'] = r_squared
    
    # 4. è¶‹åŠ¿ä¸€è‡´æ€§ï¼ˆå¤šå‘¨æœŸç¡®è®¤ï¼‰
    sma5 = df['close'].rolling(5).mean()
    sma10 = df['close'].rolling(10).mean()
    sma20 = df['close'].rolling(20).mean()
    
    new_features['trend_alignment'] = (
        ((df['close'] > sma5) & (sma5 > sma10) & (sma10 > sma20)).astype(int) -
        ((df['close'] < sma5) & (sma5 < sma10) & (sma10 < sma20)).astype(int)
    )
    
    return df.assign(**new_features)
```

**é¢„æœŸæ–°å¢**: 15ä¸ªç‰¹å¾  
**é¢„æœŸæå‡**: +1-2%å‡†ç¡®ç‡

---

#### **ç±»åˆ«2: æ”¯æ’‘é˜»åŠ›ç‰¹å¾**

```python
def _add_support_resistance_features(self, df: pd.DataFrame) -> pd.DataFrame:
    """æ·»åŠ æ”¯æ’‘é˜»åŠ›ç‰¹å¾"""
    new_features = {}
    
    # 1. è¿‘æœŸé«˜ä½ç‚¹
    for window in [10, 20, 50]:
        new_features[f'high_{window}d'] = df['high'].rolling(window).max()
        new_features[f'low_{window}d'] = df['low'].rolling(window).min()
        
        # ä»·æ ¼è·ç¦»é«˜ä½ç‚¹çš„ç™¾åˆ†æ¯”
        new_features[f'dist_to_high_{window}'] = (
            (df['close'] - new_features[f'high_{window}d']) / 
            (new_features[f'high_{window}d'] + 1e-10)
        )
        new_features[f'dist_to_low_{window}'] = (
            (df['close'] - new_features[f'low_{window}d']) / 
            (new_features[f'low_{window}d'] + 1e-10)
        )
    
    # 2. æ”¯æ’‘é˜»åŠ›çªç ´
    for window in [20, 50]:
        # çªç ´å†å²é«˜ç‚¹
        new_features[f'breakout_high_{window}'] = (
            df['close'] > df['high'].rolling(window).max().shift(1)
        ).astype(int)
        
        # è·Œç ´å†å²ä½ç‚¹
        new_features[f'breakdown_low_{window}'] = (
            df['close'] < df['low'].rolling(window).min().shift(1)
        ).astype(int)
    
    # 3. ä»·æ ¼ç›¸å¯¹ä½ç½®ï¼ˆ0-100ï¼‰
    for window in [20, 50]:
        high_n = df['high'].rolling(window).max()
        low_n = df['low'].rolling(window).min()
        new_features[f'price_position_{window}'] = (
            (df['close'] - low_n) / (high_n - low_n + 1e-10) * 100
        )
    
    return df.assign(**new_features)
```

**é¢„æœŸæ–°å¢**: 18ä¸ªç‰¹å¾  
**é¢„æœŸæå‡**: +2-3%å‡†ç¡®ç‡

---

#### **ç±»åˆ«3: é«˜çº§åŠ¨é‡æŒ‡æ ‡**

```python
def _add_advanced_momentum_features(self, df: pd.DataFrame) -> pd.DataFrame:
    """æ·»åŠ é«˜çº§åŠ¨é‡æŒ‡æ ‡"""
    new_features = {}
    
    # 1. TSI (True Strength Index)
    price_change = df['close'].diff()
    
    # åŒé‡å¹³æ»‘
    pc_ema25 = price_change.ewm(span=25).mean()
    pc_ema13 = pc_ema25.ewm(span=13).mean()
    
    abs_pc_ema25 = price_change.abs().ewm(span=25).mean()
    abs_pc_ema13 = abs_pc_ema25.ewm(span=13).mean()
    
    new_features['tsi'] = 100 * pc_ema13 / (abs_pc_ema13 + 1e-10)
    new_features['tsi_signal'] = new_features['tsi'].ewm(span=7).mean()
    
    # 2. CMO (Chande Momentum Oscillator)
    for period in [9, 14, 20]:
        price_diff = df['close'].diff()
        gain = price_diff.where(price_diff > 0, 0).rolling(period).sum()
        loss = -price_diff.where(price_diff < 0, 0).rolling(period).sum()
        
        new_features[f'cmo_{period}'] = 100 * (gain - loss) / (gain + loss + 1e-10)
    
    # 3. KST (Know Sure Thing)
    # ROCåŠ æƒç»„åˆ
    roc1 = ((df['close'] - df['close'].shift(10)) / df['close'].shift(10)) * 100
    roc2 = ((df['close'] - df['close'].shift(15)) / df['close'].shift(15)) * 100
    roc3 = ((df['close'] - df['close'].shift(20)) / df['close'].shift(20)) * 100
    roc4 = ((df['close'] - df['close'].shift(30)) / df['close'].shift(30)) * 100
    
    new_features['kst'] = (
        roc1.rolling(10).mean() * 1 +
        roc2.rolling(10).mean() * 2 +
        roc3.rolling(10).mean() * 3 +
        roc4.rolling(15).mean() * 4
    )
    new_features['kst_signal'] = new_features['kst'].rolling(9).mean()
    
    # 4. AroonæŒ‡æ ‡ï¼ˆè¶‹åŠ¿å˜åŒ–æ£€æµ‹ï¼‰
    for period in [14, 25]:
        aroon_up = []
        aroon_down = []
        
        for i in range(len(df)):
            if i < period:
                aroon_up.append(50)
                aroon_down.append(50)
            else:
                window_high = df['high'].iloc[i-period:i+1]
                window_low = df['low'].iloc[i-period:i+1]
                
                days_since_high = period - window_high.argmax()
                days_since_low = period - window_low.argmin()
                
                aroon_up.append((period - days_since_high) / period * 100)
                aroon_down.append((period - days_since_low) / period * 100)
        
        new_features[f'aroon_up_{period}'] = aroon_up
        new_features[f'aroon_down_{period}'] = aroon_down
        new_features[f'aroon_osc_{period}'] = np.array(aroon_up) - np.array(aroon_down)
    
    return df.assign(**new_features)
```

**é¢„æœŸæ–°å¢**: 15ä¸ªç‰¹å¾  
**é¢„æœŸæå‡**: +2-3%å‡†ç¡®ç‡

---

#### **ç±»åˆ«4: ä»·æ ¼å½¢æ€è¯†åˆ«**

```python
def _add_pattern_features(self, df: pd.DataFrame) -> pd.DataFrame:
    """æ·»åŠ ä»·æ ¼å½¢æ€è¯†åˆ«ç‰¹å¾"""
    new_features = {}
    
    # 1. ç»å…¸Kçº¿å½¢æ€
    body = df['close'] - df['open']
    upper_shadow = df['high'] - df[['close', 'open']].max(axis=1)
    lower_shadow = df[['close', 'open']].min(axis=1) - df['low']
    
    # é”¤å­çº¿ï¼ˆHammerï¼‰
    new_features['hammer'] = (
        (lower_shadow > body.abs() * 2) & 
        (upper_shadow < body.abs() * 0.5) &
        (body < 0)
    ).astype(int)
    
    # ä¸ŠåŠçº¿ï¼ˆHanging Manï¼‰
    new_features['hanging_man'] = (
        (lower_shadow > body.abs() * 2) & 
        (upper_shadow < body.abs() * 0.5) &
        (body > 0)
    ).astype(int)
    
    # æµæ˜Ÿçº¿ï¼ˆShooting Starï¼‰
    new_features['shooting_star'] = (
        (upper_shadow > body.abs() * 2) & 
        (lower_shadow < body.abs() * 0.5)
    ).astype(int)
    
    # åå­—æ˜Ÿï¼ˆDojiï¼‰
    new_features['doji'] = (body.abs() < (df['high'] - df['low']) * 0.1).astype(int)
    
    # 2. åå™¬å½¢æ€
    prev_body = body.shift(1)
    
    # çœ‹æ¶¨åå™¬
    new_features['bullish_engulf'] = (
        (body > 0) & 
        (prev_body < 0) &
        (df['open'] <= df['close'].shift(1)) &
        (df['close'] >= df['open'].shift(1))
    ).astype(int)
    
    # çœ‹è·Œåå™¬
    new_features['bearish_engulf'] = (
        (body < 0) & 
        (prev_body > 0) &
        (df['open'] >= df['close'].shift(1)) &
        (df['close'] <= df['open'].shift(1))
    ).astype(int)
    
    # 3. å¤šKçº¿å½¢æ€
    # ä¸‰åªä¹Œé¸¦ï¼ˆThree Black Crowsï¼‰
    new_features['three_black_crows'] = (
        (body < 0) &
        (body.shift(1) < 0) &
        (body.shift(2) < 0) &
        (df['close'] < df['close'].shift(1)) &
        (df['close'].shift(1) < df['close'].shift(2))
    ).astype(int)
    
    # ä¸‰åªç™½å…µï¼ˆThree White Soldiersï¼‰
    new_features['three_white_soldiers'] = (
        (body > 0) &
        (body.shift(1) > 0) &
        (body.shift(2) > 0) &
        (df['close'] > df['close'].shift(1)) &
        (df['close'].shift(1) > df['close'].shift(2))
    ).astype(int)
    
    # 4. ç¼ºå£æ£€æµ‹
    new_features['gap_up'] = (df['low'] > df['high'].shift(1)).astype(int)
    new_features['gap_down'] = (df['high'] < df['low'].shift(1)).astype(int)
    new_features['gap_size'] = np.where(
        new_features['gap_up'] == 1,
        (df['low'] - df['high'].shift(1)) / df['close'].shift(1),
        np.where(
            new_features['gap_down'] == 1,
            (df['high'] - df['low'].shift(1)) / df['close'].shift(1),
            0
        )
    )
    
    return df.assign(**new_features)
```

**é¢„æœŸæ–°å¢**: 14ä¸ªç‰¹å¾  
**é¢„æœŸæå‡**: +1-2%å‡†ç¡®ç‡

---

#### **ç±»åˆ«5: è®¢å•æµç‰¹å¾ï¼ˆé«˜çº§ï¼‰**

```python
def _add_order_flow_features(self, df: pd.DataFrame) -> pd.DataFrame:
    """æ·»åŠ è®¢å•æµç‰¹å¾ï¼ˆéœ€è¦ä¸»åŠ¨ä¹°å…¥é‡æ•°æ®ï¼‰"""
    new_features = {}
    
    if 'taker_buy_base_volume' in df.columns and 'volume' in df.columns:
        # 1. ä¹°å–æ¯”ç‡
        taker_sell_volume = df['volume'] - df['taker_buy_base_volume']
        new_features['buy_sell_ratio'] = (
            df['taker_buy_base_volume'] / (taker_sell_volume + 1e-10)
        )
        
        # 2. å‡€ä¹°å…¥å‹åŠ›
        new_features['net_buy_pressure'] = (
            df['taker_buy_base_volume'] - taker_sell_volume
        ) / df['volume']
        
        # 3. å¤§å•æ£€æµ‹ï¼ˆä¹°å…¥é‡å¼‚å¸¸é«˜ï¼‰
        buy_ratio = df['taker_buy_base_volume'] / df['volume']
        buy_ratio_mean = buy_ratio.rolling(20).mean()
        buy_ratio_std = buy_ratio.rolling(20).std()
        
        new_features['large_buy_orders'] = (
            buy_ratio > buy_ratio_mean + 2 * buy_ratio_std
        ).astype(int)
        
        new_features['large_sell_orders'] = (
            buy_ratio < buy_ratio_mean - 2 * buy_ratio_std
        ).astype(int)
        
        # 4. ç´¯ç§¯ä¹°å–å‹åŠ›
        for window in [5, 10, 20]:
            new_features[f'cumulative_buy_pressure_{window}'] = (
                new_features['net_buy_pressure'].rolling(window).sum()
            )
    
    return df.assign(**new_features)
```

**é¢„æœŸæ–°å¢**: 10ä¸ªç‰¹å¾  
**é¢„æœŸæå‡**: +2-3%å‡†ç¡®ç‡

---

#### **ç±»åˆ«6: æ³¢æ®µè¯†åˆ«ç‰¹å¾**

```python
def _add_swing_features(self, df: pd.DataFrame) -> pd.DataFrame:
    """æ·»åŠ æ³¢æ®µè¯†åˆ«ç‰¹å¾"""
    new_features = {}
    
    # 1. Swing High/Lowæ£€æµ‹
    for window in [5, 10]:
        # Swing High: å½“å‰æ˜¯Næ ¹Kçº¿ä¸­çš„æœ€é«˜ç‚¹
        new_features[f'swing_high_{window}'] = (
            df['high'] == df['high'].rolling(window*2+1, center=True).max()
        ).astype(int)
        
        # Swing Low: å½“å‰æ˜¯Næ ¹Kçº¿ä¸­çš„æœ€ä½ç‚¹
        new_features[f'swing_low_{window}'] = (
            df['low'] == df['low'].rolling(window*2+1, center=True).min()
        ).astype(int)
    
    # 2. æ³¢æ®µé•¿åº¦
    swing_high_5 = new_features['swing_high_5']
    swing_points = swing_high_5.rolling(50).sum()
    new_features['swing_frequency'] = swing_points  # æ³¢åŠ¨é¢‘ç‡
    
    # 3. ä»·æ ¼åœ¨æ³¢æ®µä¸­çš„ä½ç½®
    for window in [20, 50]:
        recent_high = df['high'].rolling(window).max()
        recent_low = df['low'].rolling(window).min()
        
        new_features[f'position_in_range_{window}'] = (
            (df['close'] - recent_low) / (recent_high - recent_low + 1e-10)
        )
    
    return df.assign(**new_features)
```

**é¢„æœŸæ–°å¢**: 10ä¸ªç‰¹å¾  
**é¢„æœŸæå‡**: +1-2%å‡†ç¡®ç‡

---

### ğŸ¯ ç‰¹å¾æ·»åŠ ç­–ç•¥

**æ¸è¿›å¼æ·»åŠ **:
```python
# Phase 1ï¼ˆæœ¬æ¬¡ï¼‰: éªŒè¯å½“å‰ä¼˜åŒ–æ•ˆæœ
# - ä¸åŠ æ–°ç‰¹å¾
# - å…ˆçœ‹CV+å…ƒç‰¹å¾+HOLDæƒ©ç½šèƒ½å¦è¾¾åˆ°50%

# Phase 2ï¼ˆå¦‚éœ€è¦ï¼‰: æ·»åŠ è¶‹åŠ¿å¼ºåº¦ + æ”¯æ’‘é˜»åŠ›
# - çº¦25ä¸ªæ–°ç‰¹å¾
# - é¢„æœŸ+3-5%

# Phase 3ï¼ˆå¦‚éœ€è¦ï¼‰: æ·»åŠ ä»·æ ¼å½¢æ€ + è®¢å•æµ
# - çº¦24ä¸ªæ–°ç‰¹å¾
# - é¢„æœŸ+3-5%

# Phase 4ï¼ˆå¦‚éœ€è¦ï¼‰: æ·»åŠ æ³¢æ®µè¯†åˆ«
# - çº¦10ä¸ªæ–°ç‰¹å¾
# - é¢„æœŸ+1-2%
```

**æ³¨æ„äº‹é¡¹**:
1. âœ… æ¯æ¬¡åªæ·»åŠ ä¸€ç±»ç‰¹å¾
2. âœ… å¯¹æ¯”å‰åå‡†ç¡®ç‡å˜åŒ–
3. âœ… æ£€æŸ¥ç‰¹å¾é‡è¦æ€§ï¼ˆåˆ é™¤æ— ç”¨ç‰¹å¾ï¼‰
4. âœ… æ§åˆ¶æ€»ç‰¹å¾æ•°<300ï¼ˆé˜²è¿‡æ‹Ÿåˆï¼‰
5. âœ… ä¿æŒæ ·æœ¬/ç‰¹å¾æ¯”>50:1

---

## ğŸ”§ 3. è¶…å‚æ•°è‡ªåŠ¨ä¼˜åŒ–ï¼ˆOptunaï¼‰

### å®æ–½æ–¹æ¡ˆ

#### **Step 1: å®‰è£…Optuna**

```bash
pip install optuna
```

#### **Step 2: å®šä¹‰ä¼˜åŒ–ç›®æ ‡**

```python
# backend/app/services/hyperparameter_optimizer.py

import optuna
from optuna.samplers import TPESampler
import lightgbm as lgb
from sklearn.model_selection import TimeSeriesSplit
from sklearn.metrics import accuracy_score

class HyperparameterOptimizer:
    """è¶…å‚æ•°è‡ªåŠ¨ä¼˜åŒ–å™¨ï¼ˆä½¿ç”¨Optunaï¼‰"""
    
    def __init__(self, X, y, timeframe: str):
        self.X = X
        self.y = y
        self.timeframe = timeframe
        self.best_params = None
        self.best_score = 0
    
    def objective(self, trial: optuna.Trial) -> float:
        """
        ä¼˜åŒ–ç›®æ ‡å‡½æ•°ï¼ˆ5æŠ˜æ—¶é—´åºåˆ—CVå‡†ç¡®ç‡ï¼‰
        
        Args:
            trial: Optunaè¯•éªŒå¯¹è±¡
        
        Returns:
            è´Ÿçš„CVå‡†ç¡®ç‡ï¼ˆOptunaé»˜è®¤æœ€å°åŒ–ï¼Œæ‰€ä»¥å–è´Ÿï¼‰
        """
        # å®šä¹‰æœç´¢ç©ºé—´
        params = {
            'n_estimators': trial.suggest_int('n_estimators', 100, 500),
            'max_depth': trial.suggest_int('max_depth', 3, 10),
            'num_leaves': trial.suggest_int('num_leaves', 15, 127),
            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),
            'min_child_samples': trial.suggest_int('min_child_samples', 10, 100),
            'subsample': trial.suggest_float('subsample', 0.5, 1.0),
            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),
            'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 1.0),
            'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 1.0),
            'random_state': 42,
            'verbose': -1
        }
        
        # æ—¶é—´åºåˆ—5æŠ˜äº¤å‰éªŒè¯
        tscv = TimeSeriesSplit(n_splits=5)
        cv_scores = []
        
        for train_idx, val_idx in tscv.split(self.X):
            X_train, X_val = self.X[train_idx], self.X[val_idx]
            y_train, y_val = self.y.iloc[train_idx], self.y.iloc[val_idx]
            
            # è®­ç»ƒæ¨¡å‹
            model = lgb.LGBMClassifier(**params)
            
            # HOLDæƒ©ç½š
            from sklearn.utils.class_weight import compute_sample_weight
            weights = compute_sample_weight('balanced', y_train)
            hold_penalty = np.where(y_train == 1, 0.6, 1.0)
            sample_weights = weights * hold_penalty
            
            model.fit(X_train, y_train, sample_weight=sample_weights)
            
            # è¯„ä¼°
            y_pred = model.predict(X_val)
            acc = accuracy_score(y_val, y_pred)
            cv_scores.append(acc)
        
        # è¿”å›å¹³å‡å‡†ç¡®ç‡ï¼ˆè´Ÿå€¼ï¼Œå› ä¸ºOptunaæœ€å°åŒ–ï¼‰
        return -np.mean(cv_scores)
    
    def optimize(self, n_trials: int = 100, timeout: int = 3600) -> dict:
        """
        æ‰§è¡Œè¶…å‚æ•°ä¼˜åŒ–
        
        Args:
            n_trials: è¯•éªŒæ¬¡æ•°ï¼ˆé»˜è®¤100æ¬¡ï¼‰
            timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼Œé»˜è®¤1å°æ—¶ï¼‰
        
        Returns:
            æœ€ä½³å‚æ•°å­—å…¸
        """
        # åˆ›å»ºstudy
        study = optuna.create_study(
            direction='minimize',  # æœ€å°åŒ–ç›®æ ‡å‡½æ•°ï¼ˆè´Ÿå‡†ç¡®ç‡ï¼‰
            sampler=TPESampler(seed=42)
        )
        
        # æ‰§è¡Œä¼˜åŒ–
        study.optimize(
            self.objective,
            n_trials=n_trials,
            timeout=timeout,
            show_progress_bar=True
        )
        
        # ä¿å­˜æœ€ä½³å‚æ•°
        self.best_params = study.best_params
        self.best_score = -study.best_value  # è½¬å›æ­£å‡†ç¡®ç‡
        
        logger.info(f"âœ… {self.timeframe} è¶…å‚æ•°ä¼˜åŒ–å®Œæˆ:")
        logger.info(f"   æœ€ä½³CVå‡†ç¡®ç‡: {self.best_score:.4f}")
        logger.info(f"   æœ€ä½³å‚æ•°: {self.best_params}")
        
        return self.best_params
```

#### **Step 3: é›†æˆåˆ°è®­ç»ƒæµç¨‹**

```python
# backend/app/services/ensemble_ml_service.py

async def _train_ensemble_single_timeframe_with_tuning(self, timeframe: str):
    """è®­ç»ƒå•ä¸ªæ—¶é—´æ¡†æ¶ï¼ˆå¸¦è¶…å‚æ•°ä¼˜åŒ–ï¼‰"""
    
    # 1. å‡†å¤‡æ•°æ®
    data_lgb = await self._prepare_training_data_for_timeframe(timeframe)
    data_lgb = self.feature_engineer.create_features(data_lgb)
    data_lgb = self._create_labels(data_lgb, timeframe=timeframe)
    X_lgb, y_lgb = self._prepare_features_labels(data_lgb, timeframe)
    X_lgb_scaled = self._scale_features(X_lgb, timeframe, fit=True)
    
    # 2. ğŸ†• è¶…å‚æ•°ä¼˜åŒ–ï¼ˆä»…LightGBMï¼Œå…¶ä»–ç”¨é»˜è®¤ï¼‰
    from app.services.hyperparameter_optimizer import HyperparameterOptimizer
    
    logger.info(f"ğŸ”§ {timeframe} å¼€å§‹è¶…å‚æ•°è‡ªåŠ¨ä¼˜åŒ–ï¼ˆ100æ¬¡è¯•éªŒï¼Œé¢„è®¡5-10åˆ†é’Ÿï¼‰...")
    
    optimizer = HyperparameterOptimizer(X_lgb_scaled, y_lgb, timeframe)
    best_params = optimizer.optimize(n_trials=100, timeout=600)  # 10åˆ†é’Ÿè¶…æ—¶
    
    # 3. ä½¿ç”¨æœ€ä½³å‚æ•°è®­ç»ƒLightGBM
    # ... åç»­æµç¨‹
```

---

### âš™ï¸ ä¼˜åŒ–é…ç½®å»ºè®®

**å¿«é€Ÿæ¨¡å¼**ï¼ˆå¼€å‘æµ‹è¯•ï¼‰:
```python
n_trials = 50       # 50æ¬¡è¯•éªŒ
timeout = 300       # 5åˆ†é’Ÿ
é¢„æœŸæå‡: +1-2%
è€—æ—¶: 5-10åˆ†é’Ÿ
```

**æ ‡å‡†æ¨¡å¼**ï¼ˆç”Ÿäº§ç¯å¢ƒï¼‰:
```python
n_trials = 100      # 100æ¬¡è¯•éªŒ
timeout = 1800      # 30åˆ†é’Ÿ
é¢„æœŸæå‡: +2-4%
è€—æ—¶: 20-30åˆ†é’Ÿ
```

**æ·±åº¦æ¨¡å¼**ï¼ˆç¦»çº¿ä¼˜åŒ–ï¼‰:
```python
n_trials = 300      # 300æ¬¡è¯•éªŒ
timeout = 7200      # 2å°æ—¶
é¢„æœŸæå‡: +3-5%
è€—æ—¶: 1-2å°æ—¶
```

---

### ğŸ“Š Optunaä¼˜åŒ–æµç¨‹

```
å¼€å§‹ä¼˜åŒ–
    â†“
Trial 1: {num_leaves: 63, lr: 0.05, ...}
    â†’ 5æŠ˜CV â†’ å‡†ç¡®ç‡: 0.42
    â†“
Trial 2: {num_leaves: 47, lr: 0.1, ...}
    â†’ 5æŠ˜CV â†’ å‡†ç¡®ç‡: 0.45  â† æ›´å¥½ï¼
    â†“
Trial 3: {num_leaves: 95, lr: 0.03, ...}
    â†’ 5æŠ˜CV â†’ å‡†ç¡®ç‡: 0.44
    â†“
... (100æ¬¡)
    â†“
æœ€ä½³å‚æ•°: {num_leaves: 87, lr: 0.08, ...}
æœ€ä½³CVå‡†ç¡®ç‡: 0.51  âœ…
```

---

### ğŸ¯ Optunaå¯è§†åŒ–

```python
# ä¼˜åŒ–ååˆ†æ
import optuna.visualization as vis

# 1. å‚æ•°é‡è¦æ€§
fig = vis.plot_param_importances(study)
fig.show()

# 2. ä¼˜åŒ–å†å²
fig = vis.plot_optimization_history(study)
fig.show()

# 3. å‚æ•°å…³ç³»
fig = vis.plot_parallel_coordinate(study)
fig.show()
```

---

## ğŸ“‹ å®Œæ•´å®æ–½è®¡åˆ’

### **Phase 1ï¼ˆå·²å®Œæˆï¼‰** âœ…
- æ ‡ç­¾é˜ˆå€¼ä¿®å¤
- æ—¶é—´åºåˆ—CV
- å…ƒç‰¹å¾å·¥ç¨‹
- åŠ¨æ€HOLDæƒ©ç½š

**é¢„æœŸ**: å‡†ç¡®ç‡ 42-47%

---

### **Phase 2ï¼ˆæ¡ä»¶è§¦å‘ï¼‰**

**å¦‚æœPhase 1å‡†ç¡®ç‡<50%**:

**2A. æ·»åŠ é«˜çº§æŠ€æœ¯æŒ‡æ ‡** (1-2å°æ—¶)
```
- è¶‹åŠ¿å¼ºåº¦ç‰¹å¾ï¼ˆ15ä¸ªï¼‰
- æ”¯æ’‘é˜»åŠ›ç‰¹å¾ï¼ˆ18ä¸ªï¼‰
- é«˜çº§åŠ¨é‡æŒ‡æ ‡ï¼ˆ15ä¸ªï¼‰
æ€»è®¡: +48ä¸ªç‰¹å¾
é¢„æœŸ: +4-7%å‡†ç¡®ç‡
```

**2B. è¶…å‚æ•°è‡ªåŠ¨ä¼˜åŒ–** (30åˆ†é’Ÿ-2å°æ—¶)
```
- ä½¿ç”¨Optunaä¼˜åŒ–LightGBM
- 100-300æ¬¡è¯•éªŒ
- 5æŠ˜CVè¯„ä¼°
é¢„æœŸ: +2-4%å‡†ç¡®ç‡
```

**ç»„åˆæ•ˆæœ**: å‡†ç¡®ç‡ â†’ **52-58%** â­

---

### **Phase 3ï¼ˆé«˜çº§ä¼˜åŒ–ï¼‰**

**å¦‚æœPhase 2ä»<55%**:

**3A. ä»·æ ¼å½¢æ€è¯†åˆ«** (1å°æ—¶)
```
- Kçº¿å½¢æ€ï¼ˆ14ä¸ªï¼‰
- è®¢å•æµç‰¹å¾ï¼ˆ10ä¸ªï¼‰
- æ³¢æ®µè¯†åˆ«ï¼ˆ10ä¸ªï¼‰
é¢„æœŸ: +3-5%å‡†ç¡®ç‡
```

**3B. ç¥ç»ç½‘ç»œæ¨¡å‹** (3-5å°æ—¶)
```
- LSTMæ—¶é—´åºåˆ—æ¨¡å‹
- æˆ–Transformeræ³¨æ„åŠ›æœºåˆ¶
- åŠ å…¥Stackingé›†æˆ
é¢„æœŸ: +3-6%å‡†ç¡®ç‡
```

**ç»„åˆæ•ˆæœ**: å‡†ç¡®ç‡ â†’ **58-65%** ğŸ†

---

## ğŸ¯ å®æ–½å»ºè®®

### **å½“å‰ç­–ç•¥ï¼ˆæ¨èï¼‰**

1. **å…ˆéªŒè¯Phase 1æ•ˆæœ**:
   ```bash
   # é‡å¯ç³»ç»Ÿï¼Œè§‚å¯Ÿè®­ç»ƒç»“æœ
   cd backend
   python main.py
   
   # ç­‰å¾…è®­ç»ƒå®Œæˆï¼ŒæŸ¥çœ‹æ—¥å¿—
   # å¦‚æœCVå‡†ç¡®ç‡â‰¥50% â†’ æˆåŠŸï¼
   # å¦‚æœCVå‡†ç¡®ç‡<50% â†’ ç»§ç»­Phase 2
   ```

2. **æ ¹æ®ç»“æœå†³å®šä¸‹ä¸€æ­¥**:
   ```
   å‡†ç¡®ç‡â‰¥55% â†’ å®Œæˆï¼Œè¿›å…¥å®ç›˜æµ‹è¯•
   å‡†ç¡®ç‡50-55% â†’ æ·»åŠ éƒ¨åˆ†æŠ€æœ¯æŒ‡æ ‡
   å‡†ç¡®ç‡45-50% â†’ å®æ–½è¶…å‚æ•°ä¼˜åŒ–
   å‡†ç¡®ç‡<45% â†’ å…¨é¢å®æ–½Phase 2+3
   ```

3. **é¿å…è¿‡åº¦ä¼˜åŒ–**:
   - âŒ ä¸è¦ä¸€æ¬¡æ€§åŠ å¤ªå¤šç‰¹å¾
   - âœ… æ¯æ¬¡åªåŠ ä¸€ç±»ï¼Œå¯¹æ¯”æ•ˆæœ
   - âœ… åˆ é™¤æ— æ•ˆç‰¹å¾ï¼ˆé‡è¦æ€§<é˜ˆå€¼ï¼‰

---

## ğŸ’° æˆæœ¬æ•ˆç›Šåˆ†æ

| ä¼˜åŒ–é¡¹ | å¼€å‘æ—¶é—´ | è®­ç»ƒæ—¶é—´ | é¢„æœŸæå‡ | ROI |
|--------|---------|---------|---------|-----|
| CV+å…ƒç‰¹å¾ï¼ˆå®Œæˆï¼‰ | 1å°æ—¶ | +5ç§’ | +8-13% | â­â­â­â­â­ |
| æŠ€æœ¯æŒ‡æ ‡ç‰¹å¾ | 2å°æ—¶ | +10ç§’ | +4-7% | â­â­â­â­ |
| è¶…å‚æ•°ä¼˜åŒ– | 1å°æ—¶ | +30åˆ†é’Ÿ | +2-4% | â­â­â­ |
| ç¥ç»ç½‘ç»œæ¨¡å‹ | 5å°æ—¶ | +5åˆ†é’Ÿ | +3-6% | â­â­ |

**å»ºè®®ä¼˜å…ˆçº§**: 
1. Phase 1ï¼ˆå·²å®Œæˆï¼‰ â†’ å…ˆçœ‹æ•ˆæœ
2. å¦‚éœ€è¦ â†’ æŠ€æœ¯æŒ‡æ ‡ > è¶…å‚æ•°ä¼˜åŒ– > ç¥ç»ç½‘ç»œ

---

**å‡†å¤‡å¥½äº†å—ï¼Ÿé‡å¯ç³»ç»Ÿï¼ŒéªŒè¯ä¼˜åŒ–æ•ˆæœï¼** ğŸš€

**è¯¦ç»†æ–‡æ¡£å·²åˆ›å»º**: `ADVANCED_OPTIMIZATION_PLAN.md`
